
title: SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training
authors: Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C. Bayan Bruss, Tom Goldstein
year: 2021
*tags:* #semi-supervised #self-learning #attention #transformer #row-attention
*status:* #ðŸ“¥
*related:*
- [[@vaswaniAttentionAllYou2017]]
- [[@huangTabTransformerTabularData2020]]
- [[@arikTabNetAttentiveInterpretable2020]]
- [[@grinsztajnWhyTreebasedModels]]