*title:* Feature Engineering and Selection: A Practical Approach for Predictive Models
*authors:* Max Kuhn, Kjell Johnson
*year:* 2020
*tags:* 
*status:* #üì¶ 
*related:*
*code:*
*review:*

## Notes üìç

## Annotations üìñ

# Annotations  
(20/12/2022, 08:36:27)

‚ÄúThis lack of performance may be due to a simple to explain, but difficult to pinpoint, cause: relevant predictors that were collected are represented in a way that models have trouble achieving good performance.‚Äù ([Kuhn and Johnson, 2020, p. xi](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=12&annotation=BDYJ6UMY))

‚ÄúKey relationships that are not directly available as predictors may be between the response and: ‚Ä¢ a transformation of a predictor, ‚Ä¢ an interaction of two or more predictors such as a product or ratio, ‚Ä¢ a functional relationship among predictors, or ‚Ä¢ an equivalent re-representation of a predictor. Adjusting and reworking the predictors to enable models to better uncover predictorresponse relationships has been termed feature engineering.‚Äù ([Kuhn and Johnson, 2020, p. xi](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=12&annotation=BB5LWIY5))

‚ÄúA simple logtransformation, or more complex Box-Cox or Yeo-Johnson transformation (Section 6.1), can be used to place the data on a scale where the distribution is approximately symmetric, thus removing the appearance of outliers in the data (Figure 2.2b). This kind of transformation makes sense for measurements that increase exponentially.‚Äù ([Kuhn and Johnson, 2020, p. 24](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=41&annotation=4ZAMR34C))

‚ÄúDoes this replace the test set (or, analogously, the assessment set)? No. Since the validation data are guiding the training process, they can‚Äôt be used for a fair assessment for how well the modelling process is working‚Äù ([Kuhn and Johnson, 2020, p. 53](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=70&annotation=LS9RXH34))

‚ÄúA Box-Cox transformation (Box and Cox, 1964) was used to estimate this transformation. The Box-Cox procedure, originally intended as a transformation of a model‚Äôs outcome, uses maximum likelihood estimation to estimate a transformation parameter Œª in the equation x‚àó = { xŒª‚àí1 Œª ÃÉ xŒª‚àí1 , Œª 6= 0 ÃÉ x log x, Œª = 0 where ÃÉ x is the geometric mean of the predictor data. In this procedure, Œª is estimated from the data. Because the parameter of interest is in the exponent, this type of transformation is called a power transformation. Some values of Œª map to common transformations, such as Œª = 1 (no transformation), Œª = 0 (log), Œª = 0.5 (square root), and Œª = ‚àí1 (inverse). As you can see, the Box-Cox transformation is quite flexible in its ability to address many different data distributions.‚Äù ([Kuhn and Johnson, 2020, p. 122](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=139&annotation=9VZPYP9U))

‚ÄúAlso, note that both transformations are unsupervised since, in this application, the outcome is not used in the computations. While the transformation might improve the predictor distribution, it has no guarantee of improving the model. However, there are a variety of parametric models that utilise polynomial calculations on the predictor data, such as most linear models, neural networks, and support vector machines. In these situations, a skewed predictor distribution can have a harmful effect on these models since the tails of the distribution can dominate the underlying calculations.‚Äù ([Kuhn and Johnson, 2020, p. 123](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=140&annotation=SZMYELQK))

‚ÄúIt should be noted that the Box-Cox transformation was originally used as a supervised transformation of the outcome. A simple linear model would be fit to the data and the transformation would be estimated from the model residuals. The outcome variable would be transformed using the results of the Box-Cox method. Here, th‚Äù ([Kuhn and Johnson, 2020, p. 123](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=140&annotation=GYFPVAXR))

‚Äú124 Chapter 6. Engineering Numeric Predictors method has been appropriated to be independently applied to each predictor and uses their data, instead of the residuals, to determine an appropriate transformation.‚Äù ([Kuhn and Johnson, 2020, p. 124](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=141&annotation=ML8239Q2))

‚ÄúAnother common technique for modifying the scale of a predictor is to standardise its value in order to have specific properties. Centring a predictor is a common technique. The predictor‚Äôs training set average is subtracted from the predictor‚Äôs individual values. When this is applied separately to each variable, the collection of variables would have a common mean value (i.e., zero). Similarly, scaling is the process of dividing a variable by the corresponding training set‚Äôs standard deviation. This ensures that that variables have a standard deviation of one. Alternatively, range scaling uses the training set minimum and maximum values to translate the data to be within an arbitrary range (usually zero and one). Again, it is emphasised that the statistics required for the transformation (e.g., the mean) are estimated from the training set and are applied to all data sets (e.g., the test set or new samples).‚Äù ([Kuhn and Johnson, 2020, p. 124](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=141&annotation=6FJ3MVXI))

‚ÄúThese transformations are mostly innocuous and are typically needed when the model requires the predictors to be in common units. For example, when the distance or dot products between predictors are used (such as K -nearest neighbours or support vector machines) or when the variables are required to be a common scale in order to apply a penalty (e.g., the lasso or ridge regression described in Section 7.3), a standardisation procedure is essential.‚Äù ([Kuhn and Johnson, 2020, p. 124](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=141&annotation=R8WY2MTS))

‚ÄúThere are a few apparent reasons for subjecting the data to such a transformation: ‚Ä¢ Some feel that it simplifies the analysis and/or interpretation of the results. Suppose that a person‚Äôs age was a predictor and this was binned by whether someone was above 40 years old or not. One might be able to make a statement that there is a 25% increase in the probability of the event between younger and older people. There is no discussion of per-unit increases in the response. ‚Ä¢ Binning may avoid the problem of having to specify the relationship between the predictor and outcome. A set of bins can be perceived as being able t‚Äù ([Kuhn and Johnson, 2020, p. 130](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=147&annotation=H4WJPIRR))

‚Äú6.2. 1:Many Transformations 131 model more patterns without having to visualise or think about the underlying pattern. ‚Ä¢ Using qualitative versions of the predictors may give the perception that it reduces the variation in the data. This is discussed at length below.‚Äù ([Kuhn and Johnson, 2020, p. 131](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=148&annotation=5NWSQIAH))

‚ÄúThere are a number of problematic issues with turning continuous data categorical. First, it is extremely unlikely that the underlying trend is consistent with the new model. Secondly, when a real trend exists, discretizing the data is most likely making it harder for the model to do an effective job since all of the nuance in the data has been removed. Third, there is probably no objective rationale for a specific cut-point. Quarter, when there is no relationship between the outcome and the predictor, there is a substantial increase in the probability that an erroneous trend will be ‚Äúdiscovered‚Äù. This has been widely researched and verified. See Altman (1991), Altman et al. (1994), and the references therein.‚Äù ([Kuhn and Johnson, 2020, p. 131](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=148&annotation=AEJTQVKV))

‚ÄúAnother approach to handling missing values is to impute or estimate them. Missing value imputation has a long history in statistics and has been thoroughly researched. Good places to start are Little and Rubin (2014), Van Buuren (2012) and Allison (2001). In essence, imputation uses information and relationships among the nonmissing predictors to provide an estimate to fill in the missing value.‚Äù ([Kuhn and Johnson, 2020, p. 198](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=215&annotation=4XBW3SL9))

‚ÄúHistorically, statistical methods for missing data have been concerned with the impact on inferential models. In this situation, the characteristics and quality of the imputation strategy have focused on the test statistics that are produced by the model. The goal of these techniques is to ensure that the statistical distributions are tractable and of good enough quality to support subsequent hypothesis testing. The primary approach in this scenario is to use multiple imputations; several variations of the data set are created with different estimates of the missing values. The variations of the data sets are then used as inputs to models and the test statistic replicates are computed for each imputed data set. From these replicate statistics, appropriate hypothesis tests can be constructed and used for decision making.‚Äù ([Kuhn and Johnson, 2020, p. 198](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=215&annotation=GMYI6GYC))

‚ÄúIn many predictive models, there is no notion of distributional assumptions (or they are often intractable). For example, when constructing most treebased models, the algorithm does not require any specification of a probability distribution to the predictors. As such, many predictive models are incapable of producing inferential results even if that were a primary goal.73 Given this, traditional multiple imputation methods may not have relevance for these models‚Äù ([Kuhn and Johnson, 2020, p. 198](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=215&annotation=CVD9IB9J))

‚ÄúSince predictive models are judged on their ability to accurately predict yet-tobe-seen samples (including the test set and new unknown samples), as opposed 72A perhaps more difficult situation would be explaining to the consumers of the model that ‚ÄúWe know that this is important but we don‚Äôt know why!‚Äù 73Obviously, there are exceptions such as linear and logistic regression, Naive Bayes models, etc‚Äù ([Kuhn and Johnson, 2020, p. 198](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=215&annotation=GUBYHKC3))

‚Äú8.5. Imputation Methods 199 to statistical appropriateness, it is critical that the imputed values be as close as possible to their true (unobserved) values.‚Äù ([Kuhn and Johnson, 2020, p. 199](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=216&annotation=HD2ETPMB))

‚ÄúThe last point underscores the main objective of imputation with machine learning models: produce the most accurate prediction of the missing data point. Some other important characteristics that a predictive imputation method should have are: ‚Ä¢ Within a sample data point, other variables may also be missing. For this reason, an imputation method should be tolerant of other missing data. ‚Ä¢ Imputation creates a model embedded within another model. There is a prediction equation associated with every predictor in the training set that might have missing data. It is desirable for the imputation method to be fast and have a compact prediction equation. ‚Ä¢ Many data sets often contain both numeric and qualitative predictors. Rather than generating dummy variables for qualitative predictors, a useful imputation method would be able to use predictors of various types as inputs. ‚Ä¢ The model for predicting missing values should be relatively (numerically) stable and not be overly influenced by outlying data points.‚Äù ([Kuhn and Johnson, 2020, p. 199](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=216&annotation=7DPYXSIW))

‚ÄúIt is also important to consider that imputation is probably the first step in any preprocessing sequence. Imputing qualitative predictors prior to creating indicator variables so that the binary nature of the resulting imputations can be preserved is a good idea. Also, imputation should usually occur prior to other steps that involve parameter estimation. For example, if centring and scaling is performed on data prior to imputation, the resulting means and standard deviations will inherit the potential biases and issues incurred from data deletion.‚Äù ([Kuhn and Johnson, 2020, p. 199](zotero://select/library/items/3D9SK3D2)) ([pdf](zotero://open-pdf/library/items/WIWDCH5M?page=216&annotation=L4KKBVDU))