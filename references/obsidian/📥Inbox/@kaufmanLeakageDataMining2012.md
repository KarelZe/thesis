*title:* Leakage in data mining: Formulation, detection, and avoidance
*authors:* Shachar Kaufman, Saharon Rosset, Claudia Perlich, Ori Stitelman
*year:* 2012
*tags:* #data-preprocessing #data-leakage #eda #train-test-split 
*status:* #üì¶ 
*related:*
*code:*
*review:*

## Notes üìç

## Annotations üìñ
‚ÄúWhat little has been said turns out not to be broad enough to cover more complex cases of leakage, such as those where the classical independently and identically distributed (i.i.d.) assumption is violated, that have been recently documented‚Äù ([Kaufman et al., 2012, p. 151](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=1&annotation=H72QD32F))

‚ÄúDeemed ‚Äúone of the top ten data mining mistakes‚Äù [Nisbet et al. 2009], leakage in data mining (henceforth, leakage) is the introduction of information about the target of a data mining problem that should not be legitimately available to mine from.‚Äù ([Kaufman et al., 2012, p. 151](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=1&annotation=XL8NEAWL))

‚ÄúLeakage is undesirable as it may lead a modeller, someone trying to solve the problem, to learn a suboptimal solution, which would in fact be S. Kaufman and S. Rosset were partially supported by grant 1227/09 from the Israeli Science Foundation, and S. Kaufman was supported by a fellowship from the Edmond J. Safra Centre for Bioinformatics at Tel-Aviv University. Authors‚Äô addresses: S. Kaufman and S. Rosset, Tel Aviv University, P.O. Box 39040, Tel Aviv 69978, Israel; C. Perlich and O. Stitelman, m6d. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honoured. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org. c ¬© 2012 ACM 1556-4681/2012/12-ART15 $15.00 DOI 10.1145/2382577.2382579 http://doi.acm.org/10.1145/2382577.2382579 ACM Transactions on Knowledge Discovery from Data, Vol. 6, No. 4, Article 15, Publication date: December 2012‚Äù ([Kaufman et al., 2012, p. 151](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=1&annotation=Q8ZW7GAJ))

‚Äú15:2 S. Kaufman et al. outperformed in deployment by a leakage-free model that could have otherwise been built. At the very least leakage leads to overestimation of the model‚Äôs performance.‚Äù ([Kaufman et al., 2012, p. 152](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=2&annotation=9TBKUGR6))

‚ÄúWe assume the reader is familiar with these concepts. For a complete reference see Hastie et al. [2009]. Let us just lay out our notation and say that in our framework we receive from an axiomatic data preparation stage an ordered set of multivariate observations W = (X , y). y is the outcome or target ordered set with individual elements y. Similarly, X and X are the feature-vector ordered set and element, respectively. Components of feature vectors are individual features, denoted x (ordered set) and x (element). Target and feature-vector elements y and X pertaining to the same element of W are said to be W-associated. The modeller‚Äôs goal is to infer the value of a target element, from its associated feature-vector element and from a separate group of observations, called the training examples Wtr. The solution to this problem is a model ÀÜ y = M(X , Wtr). We say that the model‚Äôs observational inputs for inferring ÀÜ y are X and Wtr, and this relation between the various entities in the framework is the base for our discussion.‚Äù ([Kaufman et al., 2012, p. 158](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=8&annotation=U3YNBGP5))

‚ÄúLeaking features are then covered by a simple condition for the absence of leakage: ‚àÄx component of X , x ‚àà legit{y}. (2) That is, any feature made available by the data preparation process is deemed legitimate by the precise formulation of the modelling problem at hand, element by element with respect to its matching target. The prevailing example for this type of leakage is what we call the no-time-machine requirement. In the context of predictive modelling, it is implicitly required that a legitimate model only build on features with information from a time earlier (or sometimes, no later) than that of the target. Formally, X and y, are defined over some time axis t (not necessarily physical time). Prediction is required by the client for a target element y at time t{y}. Each feature x (one of the components of X) associated with an observation is unobservable to the client until t{x} from then on it is observable. Let t{y} denote the ordered set resulting from element-wise application of the operator t{y} on the ordered set y. Similarly define the ordered set t{x }. We then have: t{x } < t{y}‚áîx ‚àà legit{y}. (3) Such a rule should be read as: A legitimate feature is an ordered set whose every element is observable to the client earlier than its W-associated target element. Note that the different definitions of the ‚Äútimestamping‚Äù operator t for features and targets is crucial. A good example for its necessity is leakage in the financial world, which relates to the date when information becomes public, and thus observable to the client using a hypothetical financial model (assuming the client is not a rogue inside trader). Specifically, stock-price prediction models would be highly ‚Äúsuccessful‚Äù should they use quarterly data assuming they are available a day after the quarter ends, whereas in reality they are usually publicly known only about three weeks later. We therefore define leakage legitimacy in the predictive modelling case using the concept of observability time of the features and prediction time of the target. While the simple no-time-machine requirement is indeed the most common case, one could think of additional scenarios which are still covered by condition (2).‚Äù ([Kaufman et al., 2012, p. 159](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=9&annotation=MQKPNTGG))

‚Äúor modelling problems where the usual ‚Äúi.i.d. elements‚Äù assumption is valid, and when without loss of generality considering all information specific to the element being predicted as features rather than examples, condition (9) simply reduces to condition (2) since irrelevant observations can always be considered legitimate. In contrast, when dealing with problems exhibiting nonstationarity, otherwise known as concept drift [Widmer and Kubat 1996], and more specifically the case when samples of the target are not mutually independent, condition (9) cannot be reduced to condition (2).‚Äù ([Kaufman et al., 2012, p. 161](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=11&annotation=DPRMPZTV))

‚ÄúAs a final point on legitimacy, let us mention that once it has been clearly defined for a problem, the major challenge becomes preparing the data in such a way that ensures models built on this data would be leakage free. Alternatively, when we do not have full control over data collection or when they are simply given to us, a methodology for detecting when a large number of seemingly innocent pieces of information are in fact plagued with leakage is required. This shall be the focus of the following two sections.‚Äù ([Kaufman et al., 2012, p. 162](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=12&annotation=PI5T38FM))

‚ÄúExploratory Data Analysis (EDA) can be a powerful tool for identifying leakage. EDA [Tukey 1977] is the good practise of getting more intimate with the raw data, examining it through basic and interpretable visualisation or statistical tools. Prejudice free and methodological, this kind of examination can expose leakage as patterns in the data that are surprising.‚Äù ([Kaufman et al., 2012, p. 165](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=15&annotation=SKZNY2K8))

‚ÄúOn the very practical side, a good starting point for EDA is to look for any form of unexpected data properties. Common giveaways are found in identifiers, matching (or inconsistent matching) of identifiers (i.e., sample selection biases), surprises in distributions (spikes in densities of continuous values), and finally suspicious order in supposedly random data.‚Äù ([Kaufman et al., 2012, p. 165](zotero://select/library/items/RAQ5MV79)) ([pdf](zotero://open-pdf/library/items/BXGVASY6?page=15&annotation=EV8J324D))