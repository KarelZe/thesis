- paper visiting pre-training objectives  [[@rubachevRevisitingPretrainingObjectives2022]]
- Published in [[@gorishniyRevisitingDeepLearning2021]]
- Authors use unsupervised pretraining and supervised finetuning. They also try out techniques like pseudo labelling from [[@leePseudolabelSimpleEfficient]] for semi supervised learning among others.
- For implementation see https://nn.labml.ai/transformers/mlm/index.html

