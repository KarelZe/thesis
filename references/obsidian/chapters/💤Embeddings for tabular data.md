#transformer #embeddings #numerical #continous #categorical #tabular


1. Recall from chapter (...), that tabular data contains both categorical and continuous data
2. many sota approaches are transformer based are built around the idea of embedding
3. Repeat what an embedding is?
4. embeddings generally lead to a better performance.
5. embeddings for tabular architectures are different from token embeddings.
6. Why do we want to learn embeddings instead of just using scalars?
7. Different architectures implement embeddings to different degree. Present them afterwards.
8. One-hot-encoding of categoricals with high cardinality leads to sparse matrices, high number of parameters. Label enconding would lead to poor results. Situation is different for numerical data. Here embedding numerical data increases the parameter count.
9. Explain what is different for embedding continuous / categoricals?

- [[@gorishniyEmbeddingsNumericalFeatures2022]]
- [[@hancockSurveyCategoricalData2020]]


## Notes
[[ðŸ’¤Embeddings for tabular data notes]]


