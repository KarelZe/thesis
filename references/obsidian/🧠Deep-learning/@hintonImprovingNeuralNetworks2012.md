*title:* Improving neural networks by preventing co-adaptation of feature detectors
*authors:* Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R. Salakhutdinov
*year:* 2011
*tags:* 
*status:* #ğŸ“¥
*related:*

## Notes ğŸ“

- Dropout is similar to Bagging [[@breimanBaggingPredictors1996]] as in each wehight update we train a different sub-model by ommitting some hidden units. Dropout is however different in a sense that all sub-models share the same weights. Whereas in Bagging bootstrap samples differ. (found in [[Semi-supervised Learning/@leePseudolabelSimpleEfficient]])


## Annotations ğŸ“–