{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "170uxVS5gwZl"
      },
      "source": [
        "Run `pip install .` first to install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc0zs5GkiZS2",
        "outputId": "1f3feaad-6217-445f-de8f-4264adfaaf38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gcsfs==2022.10.0\n",
            "  Downloading gcsfs-2022.10.0-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/lib/python3/dist-packages (from gcsfs==2022.10.0) (1.5.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 2.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-2.7.0-py2.py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 62.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib in /usr/lib/python3/dist-packages (from gcsfs==2022.10.0) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from gcsfs==2022.10.0) (2.22.0)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/lib/python3/dist-packages (from gcsfs==2022.10.0) (4.4.2)\n",
            "Collecting fsspec==2022.10.0\n",
            "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 63.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "\u001b[K     |████████████████████████████████| 262 kB 52.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 63.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (19.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 60.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
            "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media>=2.3.2\n",
            "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 21.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 62.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (2.8)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 62.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 62.5 MB/s eta 0:00:01\n",
            "\u001b[?25h\u001b[31mERROR: google-api-core 2.11.0 has requirement google-auth<3.0dev,>=2.14.1, but you'll have google-auth 1.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-core 2.3.2 has requirement google-auth<3.0dev,>=1.25.0, but you'll have google-auth 1.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-storage 2.7.0 has requirement google-auth<3.0dev,>=1.25.0, but you'll have google-auth 1.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: multidict, yarl, frozenlist, aiosignal, charset-normalizer, async-timeout, aiohttp, protobuf, googleapis-common-protos, google-api-core, google-cloud-core, google-crc32c, google-resumable-media, google-cloud-storage, fsspec, gcsfs\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.11.4\n",
            "    Not uninstalling protobuf at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
            "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-2.1.1 frozenlist-1.3.3 fsspec-2022.10.0 gcsfs-2022.10.0 google-api-core-2.11.0 google-cloud-core-2.3.2 google-cloud-storage-2.7.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 googleapis-common-protos-1.57.0 multidict-6.0.3 protobuf-4.21.12 yarl-1.8.2\n",
            "Collecting wandb==0.13.4\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 1.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb==0.13.4) (1.14.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting psutil>=5.0.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 66.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.4) (4.21.12)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 66.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting Click!=8.0.0,>=7.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 17.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting promise<3,>=2.0\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb==0.13.4) (45.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb==0.13.4) (2.22.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 56.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 57.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 4.4 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb==0.13.4) (2019.11.28)\n",
            "Collecting urllib3>=1.26.11; python_version >= \"3.6\"\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 60.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools, promise\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=e4b41f62891493086d0a38bab376c4c6992ad27f7723fba782f5e11cfb7f280a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21493 sha256=3ce8ff6da4122982e679ccfe36f78b2c88336de7031a8f884c411a6cae89d423\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
            "Successfully built pathtools promise\n",
            "Installing collected packages: shortuuid, psutil, PyYAML, pathtools, Click, setproctitle, promise, docker-pycreds, smmap, gitdb, GitPython, urllib3, sentry-sdk, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.8\n",
            "    Not uninstalling urllib3 at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
            "Successfully installed Click-8.1.3 GitPython-3.1.29 PyYAML-6.0 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 promise-2.3 psutil-5.9.4 sentry-sdk-1.12.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 urllib3-1.26.13 wandb-0.13.4\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2022.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 1.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting numpy>=1.20.3\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 60.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from fastparquet) (2022.10.0)\n",
            "Collecting pandas>=1.5.0\n",
            "  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 59.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from fastparquet) (20.3)\n",
            "Collecting cramjam>=2.3\n",
            "  Downloading cramjam-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 38.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
            "\u001b[K     |████████████████████████████████| 498 kB 43.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.14.0)\n",
            "Installing collected packages: numpy, pytz, pandas, cramjam, fastparquet\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.17.4\n",
            "    Not uninstalling numpy at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2019.3\n",
            "    Not uninstalling pytz at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pytz'. No files were found to uninstall.\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 0.25.3\n",
            "    Not uninstalling pandas at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pandas'. No files were found to uninstall.\n",
            "Successfully installed cramjam-2.6.2 fastparquet-2022.12.0 numpy-1.23.5 pandas-1.5.2 pytz-2022.6\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 156 kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/lib/python3/dist-packages (from catboost) (1.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from catboost) (3.1.2)\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 56.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost) (1.14.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.5.2)\n",
            "Collecting graphviz\n",
            "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 10.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.23.5)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
            "Successfully installed catboost-1.1.1 graphviz-0.20.1 plotly-5.11.0 tenacity-8.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gcsfs==2022.10.0\n",
        "!pip install wandb==0.13.4\n",
        "!pip install fastparquet\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7WXF7w4VyVgG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier, Pool\n",
        "import numpy as np\n",
        "\n",
        "import gcsfs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import wandb\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KftC_bFhgwZt",
        "outputId": "67b2e2e9-4025-47fa-f42f-8b5ca225582a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkarelze\u001b[0m (\u001b[33mfbv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.7 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/thesis/notebooks/wandb/run-20221217_160951-nxla232g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/fbv/thesis/runs/nxla232g\" target=\"_blank\">colorful-meadow-542</a></strong> to <a href=\"https://wandb.ai/fbv/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "name = \"classical_size_features_accuracy_branch\"\n",
        "\n",
        "# connect to weights and biases\n",
        "run = wandb.init(project=\"thesis\", job_type=\"dataset-creation\", entity=\"fbv\")\n",
        "\n",
        "dataset = wandb.Artifact(name=name, type=\"preprocessed_data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xk8VWtSQces7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        }
      ],
      "source": [
        "# import google.auth\n",
        "# from google.colab import auth\n",
        "# # connect to google cloud storage\n",
        "# auth.authenticate_user()\n",
        "# credentials, _ = google.auth.default()\n",
        "fs = gcsfs.GCSFileSystem(project=\"thesis\")\n",
        "#fs = gcsfs.GCSFileSystem(project=\"thesis\", credentials=credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yJViJH1yl_S7"
      },
      "outputs": [],
      "source": [
        "# reduce number of imported cols due to memory issues\n",
        "columns = [\n",
        "    \"QUOTE_DATETIME\",\n",
        "    \"ROOT\",\n",
        "    \"EXPIRATION\",\n",
        "    \"STRK_PRC\",\n",
        "    \"OPTION_TYPE\",\n",
        "    \"TRADE_SIZE\",\n",
        "    \"TRADE_PRICE\",\n",
        "    \"BEST_BID\",\n",
        "    \"BEST_ASK\",\n",
        "    \"ask_ex\",\n",
        "    \"bid_ex\",\n",
        "    \"bid_size_ex\",\n",
        "    \"ask_size_ex\",\n",
        "    \"price_all_lead\",\n",
        "    \"price_all_lag\",\n",
        "    \"price_ex_lead\",\n",
        "    \"price_ex_lag\",\n",
        "    \"buy_sell\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "WmXtH-PEqyQE"
      },
      "outputs": [],
      "source": [
        "train = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/train_set_extended_60.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        "    columns=columns,\n",
        ").sample(frac=0.1)\n",
        "val = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/val_set_extended_20.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        "    columns=columns,\n",
        ").sample(frac=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "otufqJlha7aV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler#QuantileTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-f1NBeZNcXpY"
      },
      "outputs": [],
      "source": [
        "# oe_option_type = OrdinalEncoder(\n",
        "#     unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
        "# )\n",
        "# oe_root = OrdinalEncoder(\n",
        "#     unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
        "# )\n",
        "# oe_issue_type = OrdinalEncoder(\n",
        "#     unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
        "# )\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=[-1, 1])\n",
        "# scaler = QuantileTransformer(n_quantiles=256)\n",
        "\n",
        "def transform(data: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    # # date features\n",
        "    x = pd.DataFrame(data={\"TRADE_PRICE\": data[\"TRADE_PRICE\"]}, index=data.index)\n",
        "\n",
        "    # log transformed features\n",
        "    x[\n",
        "         [\n",
        "             \"ask_ex\",\n",
        "             \"bid_ex\",\n",
        "             \"BEST_ASK\",\n",
        "             \"BEST_BID\",\n",
        "             \"TRADE_PRICE\",\n",
        "             \"price_all_lag\",\n",
        "             \"price_all_lead\",\n",
        "             \"price_ex_lag\",\n",
        "             \"price_ex_lead\",\n",
        "             \"TRADE_SIZE\", \n",
        "             \"bid_size_ex\", \n",
        "             \"ask_size_ex\",\n",
        "         ]\n",
        "     ] = data[\n",
        "         [\n",
        "             \"ask_ex\",\n",
        "             \"bid_ex\",\n",
        "             \"BEST_ASK\",\n",
        "             \"BEST_BID\",\n",
        "             \"TRADE_PRICE\",\n",
        "             \"price_all_lag\",\n",
        "             \"price_all_lead\",\n",
        "             \"price_ex_lag\",\n",
        "             \"price_ex_lead\",\n",
        "             \"TRADE_SIZE\", \n",
        "             \"bid_size_ex\", \n",
        "             \"ask_size_ex\"\n",
        "         ]\n",
        "     ]\n",
        "    \n",
        "\n",
        "    # TODO: speak with caroline\n",
        "    # x[\"bid_ex\"].replace({0.0:np.NaN}, inplace=True)\n",
        "    # x[\"ask_ex\"].replace({0.0:np.NaN}, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # size features\n",
        "    x[\"bid_ask_size_ratio_ex\"] = x[\"bid_size_ex\"] / x[\"ask_size_ex\"]\n",
        "    x[\"rel_bid_size_ex\"] = x[\"TRADE_SIZE\"] / x[\"bid_size_ex\"]\n",
        "    x[\"rel_ask_size_ex\"] = x[\"TRADE_SIZE\"] / x[\"ask_size_ex\"]\n",
        "    x[\"depth_ex\"] = x[\"bid_size_ex\"] - x[\"ask_size_ex\"]\n",
        "    \n",
        "    # classical\n",
        "    mid_ex = 0.5 * (x[\"ask_ex\"] + x[\"bid_ex\"])\n",
        "    mid_best = 0.5 * (x[\"BEST_ASK\"] + x[\"BEST_BID\"])\n",
        "    spread_ex = (x[\"ask_ex\"] - x[\"bid_ex\"])\n",
        "    spread_best = (x[\"BEST_ASK\"] - x[\"BEST_BID\"])\n",
        "    \n",
        "    x[\"prox_ex\"] = (data[\"TRADE_PRICE\"] - mid_ex) / (0.5 * spread_ex) # , (data[\"TRADE_PRICE\"] - mid_ex) / (0.5 * spread))  # combines rel. ask ex and bid ex \n",
        "    x[\"prox_best\"] = (data[\"TRADE_PRICE\"] - mid_best) / (0.5 * spread_best) #, (data[\"TRADE_PRICE\"]- mid_best) / (0.5 * spread))    \n",
        "\n",
        "\n",
        "\n",
        "    # x[\"BEST_rel_bid\"] = (data[\"TRADE_PRICE\"] - mid_best) / (data[\"BEST_ASK\"] - mid_best)\n",
        "    # x[\"BEST_rel_ask\"] = (mid_best - data[\"TRADE_PRICE\"]) / (mid_best - data[\"BEST_BID\"])\n",
        "\n",
        "    \n",
        "    # x[\"prox_ex\"].clip(-10,10, inplace=True)\n",
        "    # x[\"prox_best\"].clip(-10,10, inplace=True)\n",
        "    \n",
        "    # some uncovered comparsions\n",
        "    # x[\"ask_ex_best_ratio\"] = x[\"ask_ex\"]  / x[\"BEST_ASK\"]\n",
        "    # x[\"bid_ex_best_ratio\"] = x[\"bid_ex\"]  / x[\"BEST_BID\"]\n",
        "    # x[\"mid_ex_best_ratio\"] = mid_ex  / mid_best\n",
        "    \n",
        "    # x[\"ex_no_trade\"] = (x[\"ask_ex\"]==0) | (x[\"bid_ex\"]==0)\n",
        "    \n",
        "    x[\"spread_ex\"] = spread_ex\n",
        "    x[\"spread_best\"] = spread_best\n",
        "\n",
        "    x[\"bid_ask_ratio_ex\"] = x[\"bid_ex\"] / x[\"ask_ex\"]\n",
        "    # x[\"price_norm_size\"] = data[\"TRADE_PRICE\"] / data[\"TRADE_SIZE\"]\n",
        "    x[\"price_rel_nbb\"] = (x[\"BEST_ASK\"] - data[\"TRADE_PRICE\"]) / (x[\"BEST_ASK\"] - mid_best)\n",
        "    x[\"price_rel_nbo\"] = (data[\"TRADE_PRICE\"] - x[\"BEST_BID\"]) / (mid_best - x[\"BEST_BID\"])\n",
        "    \n",
        "    # x[\"price_eq_ask_eq_bid\"] = (data[\"TRADE_PRICE\"] == data[\"ask_ex\"]) & (data[\"TRADE_PRICE\"] == data[\"bid_ex\"])\n",
        "    \n",
        "    # calculate change\n",
        "    x[\"chg_ex_lead\"] = data[\"TRADE_PRICE\"] - data[\"price_ex_lead\"]\n",
        "    x[\"chg_ex_lag\"] = data[\"TRADE_PRICE\"] - data[\"price_ex_lag\"]\n",
        "    x[\"chg_all_lead\"] = data[\"TRADE_PRICE\"] - data[\"price_all_lead\"]\n",
        "    x[\"chg_all_lag\"] = data[\"TRADE_PRICE\"] - data[\"price_all_lag\"]\n",
        "\n",
        "    # calculate change own creation\n",
        "    #x[\"chg_ex_lag_lead\"] = data[\"price_ex_lag\"] - data[\"price_ex_lead\"]\n",
        "    #x[\"chg_all_lag_lead\"] = data[\"price_all_lag\"] - data[\"price_all_lead\"]\n",
        "\n",
        "    # impute with zeros\n",
        "    x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    x.fillna(-1, inplace=True)\n",
        "\n",
        "    # # scale to [-1, 1]\n",
        "    # if not hasattr(scaler, \"n_features_in_\"):\n",
        "    #     scaler.fit(x)\n",
        "    # x[x.columns] = scaler.transform(x)\n",
        "\n",
        "    # https://stackoverflow.com/questions/70727291/how-do-i-know-whether-a-sklearn-scaler-is-already-fitted-or-not\n",
        "\n",
        "    # if not hasattr(oe_option_type, \"n_features_in_\"):\n",
        "    #     oe_option_type.fit(data[\"OPTION_TYPE\"].astype(str).values.reshape(-1, 1))\n",
        "    # x[\"bin_option_type\"] = oe_option_type.transform(\n",
        "    #     data[\"OPTION_TYPE\"].astype(str).values.reshape(-1, 1)\n",
        "    # )\n",
        "\n",
        "    # if not hasattr(oe_root, \"n_features_in_\"):\n",
        "    #     oe_root.fit(data[\"ROOT\"].astype(str).values.reshape(-1, 1))\n",
        "    # x[\"bin_root\"] = oe_root.transform(data[\"ROOT\"].astype(str).values.reshape(-1, 1))\n",
        "\n",
        "    # if not hasattr(oe_issue_type, \"n_features_in_\"):\n",
        "    #     oe_issue_type.fit(data[\"issue_type\"].astype(str).values.reshape(-1, 1))\n",
        "    # x[\"bin_issue_type\"] = oe_issue_type.transform(\n",
        "    #     data[\"issue_type\"].astype(str).values.reshape(-1, 1)\n",
        "    # )\n",
        "\n",
        "    # x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    x[\"buy_sell\"] = data[\"buy_sell\"]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "v4rfdI7Sjgi9"
      },
      "outputs": [],
      "source": [
        "X_train = transform(train)\n",
        "y_train = X_train.buy_sell\n",
        "X_train.drop(columns=[\"buy_sell\"], inplace=True)\n",
        "\n",
        "del train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-kWMoN7W3Htf"
      },
      "outputs": [],
      "source": [
        "X_val = transform(val)\n",
        "y_val = X_val.buy_sell\n",
        "X_val.drop(columns=[\"buy_sell\"], inplace=True)\n",
        "del val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "fJ71ORhw3Hqe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7470994777178253\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "        \"od_type\": \"Iter\",\n",
        "        \"logging_level\": \"Silent\",\n",
        "        \"loss_function\": \"Logloss\",\n",
        "        \"task_type\": \"GPU\",\n",
        "        \"cat_features\": None,\n",
        "        \"random_seed\": 42,\n",
        "        \"eval_metric\":\"Accuracy\",\n",
        "        \"iterations\":10000,\n",
        "        \"early_stopping_rounds\":100,\n",
        "        \"grow_policy\":\"Lossguide\",\n",
        "        \"border_count\": 254,\n",
        "}\n",
        "\n",
        "model = CatBoostClassifier(**params)\n",
        "train_pool = Pool(X_train, y_train,weight = X_train.index.values, timestamp=X_train.index.values)\n",
        "model.fit(train_pool, eval_set=(X_val,y_val))\n",
        "\n",
        "print(model.score(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature Id</th>\n",
              "      <th>Importances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bid_ask_size_ratio_ex</td>\n",
              "      <td>13.889803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prox_ex</td>\n",
              "      <td>13.877295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ask_size_ex</td>\n",
              "      <td>13.739829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bid_size_ex</td>\n",
              "      <td>12.508500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>price_rel_nbb</td>\n",
              "      <td>10.276937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rel_bid_size_ex</td>\n",
              "      <td>5.201390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>price_rel_nbo</td>\n",
              "      <td>4.946160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>rel_ask_size_ex</td>\n",
              "      <td>3.670201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spread_ex</td>\n",
              "      <td>3.580061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>prox_best</td>\n",
              "      <td>3.530099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TRADE_SIZE</td>\n",
              "      <td>3.321077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spread_best</td>\n",
              "      <td>2.720105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>depth_ex</td>\n",
              "      <td>1.190069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bid_ask_ratio_ex</td>\n",
              "      <td>1.051355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>chg_all_lead</td>\n",
              "      <td>0.958735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>chg_all_lag</td>\n",
              "      <td>0.896839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TRADE_PRICE</td>\n",
              "      <td>0.774210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>price_all_lead</td>\n",
              "      <td>0.709650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bid_ex</td>\n",
              "      <td>0.524861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>chg_ex_lead</td>\n",
              "      <td>0.488101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>chg_ex_lag</td>\n",
              "      <td>0.413980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>price_ex_lead</td>\n",
              "      <td>0.399229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ask_ex</td>\n",
              "      <td>0.391625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>BEST_BID</td>\n",
              "      <td>0.319890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>price_ex_lag</td>\n",
              "      <td>0.310524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>BEST_ASK</td>\n",
              "      <td>0.167145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>price_all_lag</td>\n",
              "      <td>0.142331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Feature Id  Importances\n",
              "0   bid_ask_size_ratio_ex    13.889803\n",
              "1                 prox_ex    13.877295\n",
              "2             ask_size_ex    13.739829\n",
              "3             bid_size_ex    12.508500\n",
              "4           price_rel_nbb    10.276937\n",
              "5         rel_bid_size_ex     5.201390\n",
              "6           price_rel_nbo     4.946160\n",
              "7         rel_ask_size_ex     3.670201\n",
              "8               spread_ex     3.580061\n",
              "9               prox_best     3.530099\n",
              "10             TRADE_SIZE     3.321077\n",
              "11            spread_best     2.720105\n",
              "12               depth_ex     1.190069\n",
              "13       bid_ask_ratio_ex     1.051355\n",
              "14           chg_all_lead     0.958735\n",
              "15            chg_all_lag     0.896839\n",
              "16            TRADE_PRICE     0.774210\n",
              "17         price_all_lead     0.709650\n",
              "18                 bid_ex     0.524861\n",
              "19            chg_ex_lead     0.488101\n",
              "20             chg_ex_lag     0.413980\n",
              "21          price_ex_lead     0.399229\n",
              "22                 ask_ex     0.391625\n",
              "23               BEST_BID     0.319890\n",
              "24           price_ex_lag     0.310524\n",
              "25               BEST_ASK     0.167145\n",
              "26          price_all_lag     0.142331"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_importance = model.get_feature_importance(prettified=True)\n",
        "feature_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.7333797810178145 (logs applied) to     x[\"bid_ask_size_ratio_ex\"] x[\"rel_bid_size_ex\"]   x[\"rel_ask_size_ex\"] \n",
        "# 0.7331946683482763 (all from above + log returns)\n",
        "# 0.734859665271541 (all above + compare mids, ask, and bid at exchange with nation wide)\n",
        "# 0.7349013664773161 (all above + trade_price == bid_ex == ask_ex)\n",
        "# 0.7351464881990674 (price normed size)\n",
        "# 0.7352807457396116 (all above +  x[\"price_rel_nbo\"] +  x[\"price_rel_nbb\"])\n",
        "# 0.74296292 (some removed, see above, max. iterations reached. Actually there is no reason to stop ensemble)\n",
        "# 0.745053067 convert some ratios to percentages (all other things the same as above)\n",
        "# 0.7434765583282902 without any scaler, zero imputer, symmetric tree\n",
        "# 0.7445394305242655 \"grow_policy\" = \"Lossguide\" -> trained for 5000 iterations\n",
        "# 0.7450428963013065 impute with -999 instead of 0 -> trained for 5000 iterations\n",
        "# 0.7436240382023729 TODO: ask Caroline: What happens with LR if bid_ex = 0 or ask_ex is?   x[\"bid_ex\"].replace({0.0:np.NaN}, inplace=True) and  x[\"ask_ex\"].replace({0.0:np.NaN}, inplace=True)\n",
        "# 0.7447164063731647 chg from previous trade to successive trade\n",
        "# 0.7445821488326205 chg from previous trade + no trade indicator\n",
        "# 0.7476558328290199 \"spread\" feature ex\n",
        "# 0.747136093410701 \"spread\" feature best ex + fixed typo\n",
        "# 0.7475317463142745 removed features with low importance + impute with -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCs4uyjKVX8L"
      },
      "source": [
        "## Sanity Check against `lightgbm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrMmNJHcFkPB",
        "outputId": "961c05e6-930e-406d-f6c8-27be5bc528ff"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "C-am9nv7GpgH"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5U4QJeVlFuW1"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "lgb_params = {\n",
        "                    'objective':'binary',\n",
        "                    'boosting_type':'gbdt',\n",
        "                    'metric':None,\n",
        "                    'n_jobs':-1,\n",
        "                    'learning_rate':0.01,\n",
        "                    'num_leaves': 2**8,\n",
        "                    'max_depth':-1,\n",
        "                    'tree_learner':'serial',\n",
        "                    'colsample_bytree': 0.7,\n",
        "                    'subsample_freq':1,\n",
        "                    'subsample':0.7,\n",
        "                    'n_estimators':200,\n",
        "                    'max_bin':255,\n",
        "                    'verbose':-1,\n",
        "                    'seed': 42,\n",
        "                    'eval_metric':'accuracy',\n",
        "                    \"device\": \"cpu\",\n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FmChQhURHSLv"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "# create dataset for lightgbm\n",
        "# if you want to re-use data, remember to set free_raw_data=False\n",
        "lgb_train = lgb.Dataset(X_train, y_train,weight=X_train.index.values, free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, free_raw_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3So6hg2GfOl",
        "outputId": "3c999a72-5b4b-4fd4-d679-181d6262ba84"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "bst = lgb.LGBMClassifier(**lgb_params)\n",
        "bst = lgb.train(lgb_params,\n",
        "                train_set=lgb_train,\n",
        "                valid_sets=lgb_eval,\n",
        "                early_stopping_rounds=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoEhMRLg3HZF",
        "outputId": "fc8df7eb-9e39-423d-b670-094979e7850f"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "pred = bst.predict(X_val)\n",
        "pred = np.rint(pred)\n",
        "pred[pred==0]=-1\n",
        "print((y_val == pred).mean())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
