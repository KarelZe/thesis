{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WXF7w4VyVgG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import gcsfs\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials, _ = google.auth.default()\n",
    "fs = gcsfs.GCSFileSystem(project=\"thesis\", token=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "KftC_bFhgwZt",
    "outputId": "933d7b6d-400b-4f98-fa1f-a9cae72bb733",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect to weights and biases\n",
    "run = wandb.init(project=\"thesis\", job_type=\"dataset-creation\", entity=\"fbv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set here globally\n",
    "seed = 42\n",
    "\n",
    "exchange = \"ise\"  # \"ise\"  # \"cboe\"\n",
    "strategy = \"supervised\"  # \"supervised\" #\"unsupervised\" # \"supervised\"  # \"transfer\" # \"unsupervised\"\n",
    "mode = \"none\"  # \"none\" # \"log_standardized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xk8VWtSQces7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = f\"fbv/thesis/{exchange}_{strategy}_raw:latest\"\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# load unscaled data\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJViJH1yl_S7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reduce number of imported cols due to memory issues\n",
    "columns = [\n",
    "    \"QUOTE_DATETIME\",\n",
    "    \"ROOT\",\n",
    "    \"EXPIRATION\",\n",
    "    \"STRK_PRC\",\n",
    "    \"OPTION_TYPE\",\n",
    "    \"issue_type\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"TRADE_PRICE\",\n",
    "    \"BEST_BID\",\n",
    "    \"BEST_ASK\",\n",
    "    \"ask_ex\",\n",
    "    \"bid_ex\",\n",
    "    \"bid_size_ex\",\n",
    "    \"ask_size_ex\",\n",
    "    \"price_all_lead\",\n",
    "    \"price_all_lag\",\n",
    "    \"price_ex_lead\",\n",
    "    \"price_ex_lag\",\n",
    "    \"buy_sell\",\n",
    "    \"day_vol\",\n",
    "    \"myn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE",
    "outputId": "8c68b54f-0331-444a-d3d8-83a6e2a9e7c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if strategy == \"supervised\":\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    val = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "\n",
    "elif strategy == \"unsupervised\":\n",
    "    # load unlabelled training set\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "\n",
    "elif strategy == \"transfer\":\n",
    "    # load test set\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZoGJyq_ivfG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    \"STRK_PRC\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"TRADE_PRICE\",\n",
    "    \"BEST_BID\",\n",
    "    \"BEST_ASK\",\n",
    "    \"ask_ex\",\n",
    "    \"bid_ex\",\n",
    "    \"bid_size_ex\",\n",
    "    \"ask_size_ex\",\n",
    "    \"price_all_lead\",\n",
    "    \"price_all_lag\",\n",
    "    \"price_ex_lead\",\n",
    "    \"price_ex_lag\",\n",
    "    \"day_vol\",\n",
    "    \"myn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3_ot886ivfK"
   },
   "source": [
    "## Box Cox Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0MseONFivfL",
    "outputId": "3a3cf373-d246-4c42-cb9d-13c41570f7d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "train[num_features].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owNjZgepivfN",
    "outputId": "2535b4d5-88ec-47ac-e0c6-310d12a0a6b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "box_cox = PowerTransformer(method=\"box-cox\")\n",
    "# add constant as box cox works only on positive data\n",
    "box_cox.fit(train[num_features] + 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfV5iVfuivfN",
    "outputId": "60a15dc2-6eac-45ef-e520-74208d0182a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "lambdas = pd.Series(data=box_cox.lambdas_, index=num_features)\n",
    "lambdas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7gne62JXAMc"
   },
   "source": [
    "Use smallest possible constant for Box-Cox test. All $\\lambda \\approx 0 \\implies \\log(\\cdot)$ for price, size, and quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f1NBeZNcXpY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if strategy == \"supervised\":\n",
    "    scaler = StandardScaler()\n",
    "    oe_option_type = OrdinalEncoder(\n",
    "        unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
    "    )\n",
    "    oe_root = OrdinalEncoder(\n",
    "        unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
    "    )\n",
    "    oe_issue_type = OrdinalEncoder(\n",
    "        unknown_value=-1, dtype=int, handle_unknown=\"use_encoded_value\"\n",
    "    )\n",
    "else:\n",
    "    # if mode transfer or mode unsupervised -> use scaler from ise supervised dataset\n",
    "    # if mode supervised -> fit scaler on ise / cboe training set and apply on validation and test set\n",
    "\n",
    "    # TODO: Fix if I get unlabelled CBOE dataset\n",
    "    artifact = run.use_artifact(f\"fbv/thesis/ise_supervised_{mode}_scaler:latest\")\n",
    "    scaler_dir = artifact.download()\n",
    "    scalers = pickle.load(open(Path(scaler_dir, \"scalers.sklearn\"), \"rb\"))\n",
    "\n",
    "    # set fitted scalers\n",
    "    scaler = scalers[\"scaler\"]\n",
    "    oe_option_type = scalers[\"oe_option_type\"]\n",
    "    oe_root = scalers[\"oe_root\"]\n",
    "    oe_issue_type = scalers[\"oe_issue_type\"]\n",
    "\n",
    "\n",
    "def transform(\n",
    "    data: pd.DataFrame,\n",
    "    mode: Literal[\"log_standarized\", \"none\"] = \"log_standardized\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create features, impute, and scale.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): input data frame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: updated data frame.\n",
    "    \"\"\"\n",
    "    # set up df, overwrite later\n",
    "    x = pd.DataFrame(data={\"TRADE_PRICE\": data[\"TRADE_PRICE\"]}, index=data.index)\n",
    "\n",
    "    # size features\n",
    "    x[\"bid_ask_size_ratio_ex\"] = data[\"bid_size_ex\"] / data[\"ask_size_ex\"]\n",
    "    x[\"rel_bid_size_ex\"] = data[\"TRADE_SIZE\"] / data[\"bid_size_ex\"]\n",
    "    x[\"rel_ask_size_ex\"] = data[\"TRADE_SIZE\"] / data[\"ask_size_ex\"]\n",
    "    x[\"depth_ex\"] = data[\"bid_size_ex\"] - data[\"ask_size_ex\"]\n",
    "\n",
    "    # classical\n",
    "    cond_ex = data[\"ask_ex\"] >= data[\"bid_ex\"]\n",
    "    cond_best = data[\"BEST_ASK\"] >= data[\"BEST_BID\"]\n",
    "\n",
    "    # assume positive spread\n",
    "    mid_ex = np.where(cond_ex, 0.5 * (data[\"ask_ex\"] + data[\"bid_ex\"]), np.nan)\n",
    "    mid_best = np.where(cond_best, 0.5 * (data[\"BEST_ASK\"] + data[\"BEST_BID\"]), np.nan)\n",
    "\n",
    "    spread_ex = np.where(cond_ex, data[\"ask_ex\"] - data[\"bid_ex\"], np.nan)\n",
    "    spread_best = np.where(cond_best, data[\"BEST_ASK\"] - data[\"BEST_BID\"], np.nan)\n",
    "\n",
    "    x[\"prox_ex\"] = (data[\"TRADE_PRICE\"] - mid_ex) / (0.5 * spread_ex)\n",
    "    x[\"prox_best\"] = (data[\"TRADE_PRICE\"] - mid_best) / (0.5 * spread_best)\n",
    "\n",
    "    # custom features\n",
    "    x[\"spread_ex\"] = spread_ex\n",
    "    x[\"spread_best\"] = spread_best\n",
    "    x[\"bid_ask_ratio_ex\"] = data[\"bid_ex\"] / data[\"ask_ex\"]\n",
    "\n",
    "    # calculate change\n",
    "    x[\"chg_ex_lead\"] = data[\"TRADE_PRICE\"] - data[\"price_ex_lead\"]\n",
    "    x[\"chg_ex_lag\"] = data[\"TRADE_PRICE\"] - data[\"price_ex_lag\"]\n",
    "    x[\"chg_all_lead\"] = data[\"TRADE_PRICE\"] - data[\"price_all_lead\"]\n",
    "    x[\"chg_all_lag\"] = data[\"TRADE_PRICE\"] - data[\"price_all_lag\"]\n",
    "\n",
    "    if \"clip\" in mode:\n",
    "        print(\"clipping...\")\n",
    "        # apply clipping, avoids exploding / vanishing gradients\n",
    "        to_clip = [\n",
    "            \"chg_ex_lead\",\n",
    "            \"chg_ex_lag\",\n",
    "            \"chg_all_lead\",\n",
    "            \"chg_all_lag\",\n",
    "            \"prox_ex\",\n",
    "            \"prox_best\",\n",
    "            \"bid_ask_size_ratio_ex\",\n",
    "            \"rel_bid_size_ex\",\n",
    "            \"rel_ask_size_ex\",\n",
    "            \"depth_ex\",\n",
    "        ]\n",
    "        x[to_clip] = x[to_clip].clip(-3, 3)\n",
    "\n",
    "    if \"log\" in mode:\n",
    "        print(\"log transform...\")\n",
    "        # log transformed features\n",
    "        x[\n",
    "            [\n",
    "                \"ask_ex\",\n",
    "                \"bid_ex\",\n",
    "                \"BEST_ASK\",\n",
    "                \"BEST_BID\",\n",
    "                \"TRADE_PRICE\",\n",
    "                \"price_all_lag\",\n",
    "                \"price_all_lead\",\n",
    "                \"price_ex_lag\",\n",
    "                \"price_ex_lead\",\n",
    "                \"TRADE_SIZE\",\n",
    "                \"bid_size_ex\",\n",
    "                \"ask_size_ex\",\n",
    "                \"day_vol\",\n",
    "                \"myn\",\n",
    "                \"STRK_PRC\",\n",
    "            ]\n",
    "        ] = np.log1p(\n",
    "            data[\n",
    "                [\n",
    "                    \"ask_ex\",\n",
    "                    \"bid_ex\",\n",
    "                    \"BEST_ASK\",\n",
    "                    \"BEST_BID\",\n",
    "                    \"TRADE_PRICE\",\n",
    "                    \"price_all_lag\",\n",
    "                    \"price_all_lead\",\n",
    "                    \"price_ex_lag\",\n",
    "                    \"price_ex_lead\",\n",
    "                    \"TRADE_SIZE\",\n",
    "                    \"bid_size_ex\",\n",
    "                    \"ask_size_ex\",\n",
    "                    \"day_vol\",\n",
    "                    \"myn\",\n",
    "                    \"STRK_PRC\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        x[\"mid_ex\"] = np.log1p(mid_ex)\n",
    "        x[\"mid_best\"] = np.log1p(mid_best)\n",
    "\n",
    "        x[\"ttm\"] = (\n",
    "            data[\"EXPIRATION\"].dt.to_period(\"M\")\n",
    "            - data[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
    "        ).apply(lambda x: x.n)\n",
    "\n",
    "        # save num columns for scaler\n",
    "        num_cols = x.columns.tolist()\n",
    "\n",
    "        # impute with zeros\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        x.fillna(0, inplace=True)\n",
    "\n",
    "        # standardize continous columns (w/o date features)\n",
    "        # bin encode categorical features\n",
    "        try:\n",
    "            x[num_cols] = scaler.transform(x[num_cols])\n",
    "            x[\"option_type\"] = oe_option_type.transform(\n",
    "                data[\"OPTION_TYPE\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            x[\"issue_type\"] = oe_issue_type.transform(\n",
    "                data[\"issue_type\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            x[\"root\"] = oe_root.transform(\n",
    "                data[\"ROOT\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            print(\"transform (val + test)\")\n",
    "        except NotFittedError:\n",
    "            x[num_cols] = scaler.fit_transform(x[num_cols])\n",
    "            x[\"option_type\"] = oe_option_type.fit_transform(\n",
    "                data[\"OPTION_TYPE\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            x[\"issue_type\"] = oe_issue_type.fit_transform(\n",
    "                data[\"issue_type\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            x[\"root\"] = oe_root.fit_transform(\n",
    "                data[\"ROOT\"].astype(str).values.reshape(-1, 1)\n",
    "            )\n",
    "            print(\"fit_transform (train)\")\n",
    "    if mode == \"none\":\n",
    "        x[\n",
    "            [\n",
    "                \"ask_ex\",\n",
    "                \"bid_ex\",\n",
    "                \"BEST_ASK\",\n",
    "                \"BEST_BID\",\n",
    "                \"TRADE_PRICE\",\n",
    "                \"price_all_lag\",\n",
    "                \"price_all_lead\",\n",
    "                \"price_ex_lag\",\n",
    "                \"price_ex_lead\",\n",
    "                \"TRADE_SIZE\",\n",
    "                \"bid_size_ex\",\n",
    "                \"ask_size_ex\",\n",
    "                \"day_vol\",\n",
    "                \"myn\",\n",
    "                \"STRK_PRC\",\n",
    "            ]\n",
    "        ] = data[\n",
    "            [\n",
    "                \"ask_ex\",\n",
    "                \"bid_ex\",\n",
    "                \"BEST_ASK\",\n",
    "                \"BEST_BID\",\n",
    "                \"TRADE_PRICE\",\n",
    "                \"price_all_lag\",\n",
    "                \"price_all_lead\",\n",
    "                \"price_ex_lag\",\n",
    "                \"price_ex_lead\",\n",
    "                \"TRADE_SIZE\",\n",
    "                \"bid_size_ex\",\n",
    "                \"ask_size_ex\",\n",
    "                \"day_vol\",\n",
    "                \"myn\",\n",
    "                \"STRK_PRC\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        x[\"mid_ex\"] = mid_ex\n",
    "        x[\"mid_best\"] = mid_best\n",
    "\n",
    "        x[\"ttm\"] = (\n",
    "            data[\"EXPIRATION\"].dt.to_period(\"M\")\n",
    "            - data[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
    "        ).apply(lambda x: x.n)\n",
    "\n",
    "        # save num columns for scaler\n",
    "        num_cols = x.columns.tolist()\n",
    "\n",
    "        # impute with zeros\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        # x.fillna(0, inplace=True)\n",
    "\n",
    "        # just copy\n",
    "        x[\"option_type\"] = data[\"OPTION_TYPE\"]\n",
    "        x[\"issue_type\"] = data[\"issue_type\"]\n",
    "        x[\"root\"] = data[\"ROOT\"]\n",
    "\n",
    "    x[\"buy_sell\"] = data[\"buy_sell\"].astype(\"int8\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gKBgTbBivfS"
   },
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b-3AOjcivfT",
    "outputId": "241094f0-0cda-44a8-e377-d5809d6ca1bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = f\"{exchange}_{strategy}_{mode}\"\n",
    "\n",
    "dataset = wandb.Artifact(name=name, type=\"preprocessed_data\")\n",
    "\n",
    "if strategy == \"supervised\" or strategy == \"unsupervised\":\n",
    "    output_path = f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/{name}/train_set.parquet\"\n",
    "    train = transform(train, mode)\n",
    "    train.to_parquet(output_path)\n",
    "    del train\n",
    "    gc.collect()\n",
    "\n",
    "    dataset.add_reference(output_path)\n",
    "\n",
    "if strategy == \"supervised\":\n",
    "    output_path = f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/{name}/val_set.parquet\"\n",
    "    val = transform(val, mode)\n",
    "    val.to_parquet(output_path)\n",
    "    del val\n",
    "    gc.collect()\n",
    "    dataset.add_reference(output_path)\n",
    "\n",
    "if strategy == \"supervised\" or strategy == \"transfer\":\n",
    "    output_path = f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/{name}/test_set.parquet\"\n",
    "\n",
    "    test = transform(test, mode)\n",
    "    test.to_parquet(output_path)\n",
    "    del test\n",
    "    gc.collect()\n",
    "    dataset.add_reference(output_path)\n",
    "\n",
    "run.log_artifact(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save scaler to pickle\n",
    "\n",
    "if strategy == \"supervised\":\n",
    "    scalers = {\n",
    "        \"scaler\": scaler,\n",
    "        \"oe_option_type\": oe_option_type,\n",
    "        \"oe_root\": oe_root,\n",
    "        \"oe_issue_type\": oe_issue_type,\n",
    "    }\n",
    "    uri_scalers = f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/{name}/scalers.sklearn\"\n",
    "    with fs.open(uri_scalers, \"wb\") as f:\n",
    "        pickle.dump(scalers, f, protocol=4)\n",
    "\n",
    "    # log scaler to wandb\n",
    "    scaler = wandb.Artifact(name=f\"{name}_scaler\", type=\"scaler\")\n",
    "    scaler.add_reference(uri_scalers)\n",
    "    run.log_artifact(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8u4au_6XAMx"
   },
   "source": [
    "## Adversarial Validation\n",
    "> Adversarial Validation is a technique allowing you to easily estimate the degree of difference between your training and test data. This technique was long rumored among Kaggle participants and transmitted from team to team until it emerged publicly thanks to a post by Zygmunt Zając (https://www.kaggle.com/zygmunt) on his FastML blog. (adapted from Banchawicz et. al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_classical = [\n",
    "    \"TRADE_PRICE\",\n",
    "    \"bid_ex\",\n",
    "    \"ask_ex\",\n",
    "    \"BEST_ASK\",\n",
    "    \"BEST_BID\",\n",
    "    \"price_ex_lag\",\n",
    "    \"price_ex_lead\",\n",
    "    \"price_all_lag\",\n",
    "    \"price_all_lead\",\n",
    "    \"chg_ex_lead\",\n",
    "    \"chg_ex_lag\",\n",
    "    \"chg_all_lead\",\n",
    "    \"chg_all_lag\",\n",
    "    \"prox_ex\",\n",
    "    \"prox_best\",\n",
    "]\n",
    "\n",
    "features_size = [\n",
    "    \"bid_ask_size_ratio_ex\",\n",
    "    \"rel_bid_size_ex\",\n",
    "    \"rel_ask_size_ex\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"bid_size_ex\",\n",
    "    \"ask_size_ex\",\n",
    "    \"depth_ex\",\n",
    "]\n",
    "\n",
    "features_classical_size = [\n",
    "    *features_classical,\n",
    "    *features_size,\n",
    "    \"buy_sell\",  # add here and remove later\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"gs://thesis-bucket-option-trade-classification/data/ise_log_standardized/train_set_60.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    "    columns=features_classical_size,\n",
    ")\n",
    "val = pd.read_parquet(\n",
    "    \"gs://thesis-bucket-option-trade-classification/data/ise_log_standardized/val_set_20.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    "    columns=features_classical_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKpvTE4EXAM0",
    "outputId": "222f6a61-548f-4f1c-8064-caffcdfe637e"
   },
   "outputs": [],
   "source": [
    "X = pd.concat([train, val])\n",
    "X.drop(columns=[\"buy_sell\"], inplace=True)\n",
    "# assign zeros to train set and ones to test set\n",
    "y = [0] * len(train) + [1] * len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tperioc56aCt"
   },
   "outputs": [],
   "source": [
    "# perform cv with catboost classifier\n",
    "clf = CatBoostClassifier(\n",
    "    task_type=\"GPU\",\n",
    "    logging_level=\"Silent\",\n",
    "    random_seed=42,\n",
    "    eval_metric=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "clf.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mcc as data is imbalanced 3/4 train set, 1/4 val set\n",
    "print(matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = clf.get_feature_importance(\n",
    "    prettified=True, type=\"FeatureImportance\"\n",
    ")\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_csv(\"feature_importance_gbm_classical_size.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "cols = train.columns.tolist()\n",
    "# cols.remove(\"buy_sell\")\n",
    "results = []\n",
    "\n",
    "for col in cols:\n",
    "    res = ks_2samp(train[col], val[col])\n",
    "\n",
    "    results.append({\"col\": col, \"static\": res.statistic, \"pvalue\": res.pvalue})\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(\"kolmogorov_smirnov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = transform(train, mode=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "from otc.features.build_features import features_classical_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train[features_classical_size].head(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_clearname = [\n",
    "    \"trade price\",\n",
    "    \"bid (ex)\",\n",
    "    \"ask (ex)\",\n",
    "    \"ask (best)\",\n",
    "    \"bid (best)\",\n",
    "    \"price lag (ex)\",\n",
    "    \"price lead (ex)\",\n",
    "    \"price lag (all)\",\n",
    "    \"price lead (all)\",\n",
    "    \"price chg. lead (ex)\",\n",
    "    \"price chg. lag (ex)\",\n",
    "    \"price chg. lead (all)\",\n",
    "    \"price chg. lag (all)\",\n",
    "    \"prox (ex)\",\n",
    "    \"prox (best)\",\n",
    "    \"bid ask size ratio (ex)\",\n",
    "    \"rel. bid size (ex)\",\n",
    "    \"rel. ask size (ex)\",\n",
    "    \"trade size\",\n",
    "    \"bid size (ex)\",\n",
    "    \"ask size (ex)\",\n",
    "    \"depth (ex)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cols_clearname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(zip(cols, cols_clearname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pgf.texsystem\": \"xelatex\",\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"font.serif\": [],\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.sans-serif\": [],\n",
    "    \"axes.labelsize\": 11,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "plt.rc(\"text.latex\", preamble=r\"\\usepackage{amsmath}\\usepackage[utf8]{inputenc}\")\n",
    "\n",
    "cmap = mpl.colormaps.get_cmap(\"plasma\")\n",
    "\n",
    "\n",
    "# https://ranocha.de/blog/colors/\n",
    "# Standard SciencePlots color cycle\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(\n",
    "    \"color\", [\"0C5DA5\", \"00B945\", \"FF9500\", \"FF2C00\", \"845B97\", \"474747\", \"9e9e9e\"]\n",
    ")\n",
    "\n",
    "# line cyclers adapted to colourblind people\n",
    "from cycler import cycler\n",
    "\n",
    "line_cycler = (\n",
    "    cycler(\n",
    "        color=[\n",
    "            \"#E69F00\",\n",
    "            \"#56B4E9\",\n",
    "            \"#009E73\",\n",
    "            \"#0072B2\",\n",
    "            \"#D55E00\",\n",
    "            \"#CC79A7\",\n",
    "            \"#F0E442\",\n",
    "        ]\n",
    "    )  #  + cycler(linestyle=[\"-\", \"--\", \"-.\", \":\", \"-\", \"--\", \"-.\"])\n",
    ")\n",
    "marker_cycler = (\n",
    "    cycler(\n",
    "        color=[\n",
    "            \"#E69F00\",\n",
    "            \"#56B4E9\",\n",
    "            \"#009E73\",\n",
    "            \"#0072B2\",\n",
    "            \"#D55E00\",\n",
    "            \"#CC79A7\",\n",
    "            \"#F0E442\",\n",
    "        ]\n",
    "    )\n",
    "    + cycler(linestyle=[\"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\"])\n",
    "    + cycler(marker=[\"4\", \"2\", \"3\", \"1\", \"+\", \"x\", \".\"])\n",
    ")\n",
    "\n",
    "plt.rc(\"axes\", prop_cycle=line_cycler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cols.remove(\"buy_sell\")\n",
    "print(cols)\n",
    "\n",
    "CM = 1 / 2.54\n",
    "\n",
    "(fig, ax) = plt.subplots(\n",
    "    nrows=(len(cols) // 4) + 1,\n",
    "    ncols=4,\n",
    "    sharey=True,\n",
    "    constrained_layout=True,\n",
    "    figsize=(14 * CM, 14 * CM),\n",
    ")\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i, col in tqdm(enumerate(cols)):\n",
    "    r = i // 4\n",
    "    c = i % 4\n",
    "\n",
    "    ax[r][c].acorr(X[col].astype(float), usevlines=True, normed=True, maxlags=20, lw=1)\n",
    "    ax[r][c].set_title(cols_clearname[index])\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# remove empty plots\n",
    "fig.delaxes(ax[5][2])\n",
    "fig.delaxes(ax[5][3])\n",
    "\n",
    "plt.savefig(\n",
    "    \"../reports/Graphs/auto_corr_features.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
