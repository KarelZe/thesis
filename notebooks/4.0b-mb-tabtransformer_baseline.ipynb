{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarelZe/thesis/blob/intermediate-results/notebooks/4.0b-mb-tabtransformer_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost==1.1\n",
        "!pip install gcsfs==2022.10.0\n",
        "!pip install ipywidgets==8.0.2\n",
        "!pip install numpy==1.23.4\n",
        "!pip install pandas==1.5.1\n",
        "!pip install scikit-learn==1.1.3\n",
        "!pip install fastparquet\n",
        "!pip install wandb\n",
        "!pip install einops\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nxXvpIDU2_t7",
        "outputId": "20e093b2-5f74-4918-978a-d88f93658246"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost==1.1\n",
            "  Downloading catboost-1.1-cp38-none-manylinux1_x86_64.whl (76.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.7 MB 7.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost==1.1) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost==1.1) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost==1.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost==1.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost==1.1) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost==1.1) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost==1.1) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gcsfs==2022.10.0\n",
            "  Downloading gcsfs-2022.10.0-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (3.8.3)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (2.14.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (0.4.6)\n",
            "Collecting fsspec==2022.10.0\n",
            "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 18.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs==2022.10.0) (4.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (4.0.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs==2022.10.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs==2022.10.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs==2022.10.0) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs==2022.10.0) (1.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2022.10.0) (0.4.8)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2022.10.0) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib->gcsfs==2022.10.0) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2022.10.0) (3.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gcsfs==2022.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->gcsfs==2022.10.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gcsfs==2022.10.0) (1.24.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage->gcsfs==2022.10.0) (2.3.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage->gcsfs==2022.10.0) (2.8.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-storage->gcsfs==2022.10.0) (2.4.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2022.10.0) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2022.10.0) (1.57.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs==2022.10.0) (1.5.0)\n",
            "Installing collected packages: fsspec, gcsfs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2022.11.0\n",
            "    Uninstalling fsspec-2022.11.0:\n",
            "      Successfully uninstalled fsspec-2022.11.0\n",
            "Successfully installed fsspec-2022.10.0 gcsfs-2022.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipywidgets==8.0.2\n",
            "  Downloading ipywidgets-8.0.2-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets==8.0.2) (5.3.4)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets==8.0.2) (7.9.0)\n",
            "Collecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 73.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets==8.0.2) (5.1.1)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets==8.0.2) (3.0.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.2) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.2) (6.0.4)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.2) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets==8.0.2) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.0.2) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.0.2) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2) (4.11.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==8.0.2) (23.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=6.1.0->ipywidgets==8.0.2) (0.7.0)\n",
            "Installing collected packages: jedi, widgetsnbextension, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.1\n",
            "    Uninstalling widgetsnbextension-3.6.1:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.1\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed ipywidgets-8.0.2 jedi-0.18.2 widgetsnbextension-4.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.4\n",
            "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 15.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.4 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.23.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.5.1\n",
            "  Downloading pandas-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.1) (1.23.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.1) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.1) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "Successfully installed pandas-1.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==1.1.3\n",
            "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3) (1.23.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.3) (1.2.0)\n",
            "Collecting numpy>=1.17.3\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.9 MB 57.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.4\n",
            "    Uninstalling numpy-1.23.4:\n",
            "      Successfully uninstalled numpy-1.23.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed numpy-1.22.4 scikit-learn-1.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2022.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from fastparquet) (2022.10.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from fastparquet) (1.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastparquet) (21.3)\n",
            "Collecting cramjam>=2.3\n",
            "  Downloading cramjam-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from fastparquet) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.5.0->fastparquet) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastparquet) (3.0.9)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.6.2 fastparquet-2022.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 15.2 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 85.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 80.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 85.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 86.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 69.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 82.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 87.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 87.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=947c40c3abde276522e82c64f3886b16c594769333bf77afc7521a7aeec40a28\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 518 kB/s \n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtz4jE9f2en7"
      },
      "source": [
        "Run `pip install .` first to install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7WXF7w4VyVgG"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "import gcsfs\n",
        "import google.auth\n",
        "from google.colab import auth, output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import wandb\n",
        "\n",
        "from typing import List, Optional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to google cloud storage\n",
        "auth.authenticate_user()\n",
        "credentials, _ = google.auth.default()\n",
        "fs = gcsfs.GCSFileSystem(project=\"thesis\", token=credentials)\n",
        "fs_prefix = \"gs://\""
      ],
      "metadata": {
        "id": "DMpV9NTt25pj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_classical_size = [\n",
        "    'TRADE_PRICE', 'bid_ask_size_ratio_ex', 'rel_bid_size_ex',\n",
        "       'rel_ask_size_ex', 'TRADE_SIZE', 'bid_size_ex', 'ask_size_ex',\n",
        "       'rel_ask_ex', 'rel_bid_ex', 'BEST_rel_bid', 'BEST_rel_ask',\n",
        "       'bid_ask_ratio_ex', 'chg_ex_lead', 'chg_ex_lag', 'chg_all_lead',\n",
        "       'chg_all_lag', 'ask_ex', 'bid_ex', 'BEST_ASK', 'BEST_BID',\n",
        "       'price_all_lag', 'price_all_lead', 'price_ex_lag', 'price_ex_lead'\n",
        "]"
      ],
      "metadata": {
        "id": "vFMHPh-nTcSI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
        "# for refs\n",
        "\n",
        "run = wandb.init(project=\"thesis\",entity=\"fbv\")\n",
        "\n",
        "dataset = \"fbv/thesis/classical_size_features_log_normalized:v0\"\n",
        "artifact = run.use_artifact(dataset)\n",
        "data_dir = artifact.download()\n",
        "\n",
        "model = \"fbv/thesis/3lfsbuby_TabTransformer_default_trial_82.pth:v0\"\n",
        "artifact = run.use_artifact(model)\n",
        "model_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ah1dofx3TdDj",
        "outputId": "fb566d1a-ccae-4ba5-c113-6eb2f30e1c49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221207_103323-377hiy7j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/fbv/thesis/runs/377hiy7j\" target=\"_blank\">feasible-pine-385</a></strong> to <a href=\"https://wandb.ai/fbv/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact classical_size_features_log_normalized:v0, 2564.04MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:1:6.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WmXtH-PEqyQE"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_parquet(Path(data_dir, \"test_set_20.parquet\"), engine=\"fastparquet\")\n",
        "\n",
        "y_test = X_test[\"buy_sell\"]\n",
        "X_test = X_test[features_classical_size]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ypC-A70pYQ7z",
        "outputId": "69af7468-67d4-4901-882e-33eab47a5b8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          TRADE_PRICE  bid_ask_size_ratio_ex  rel_bid_size_ex  \\\n",
              "39342171    -0.886605              -0.999944        -0.999978   \n",
              "39342172    -0.398830              -0.999980        -0.999660   \n",
              "39342173    -0.060248              -0.999980        -0.999660   \n",
              "39342174    -0.675788              -0.999980        -0.999966   \n",
              "39342175    -0.727221              -0.999980        -0.999966   \n",
              "\n",
              "          rel_ask_size_ex  TRADE_SIZE  bid_size_ex  ask_size_ex  rel_ask_ex  \\\n",
              "39342171        -0.999959   -0.920668    -0.397940    -0.568327   -0.450753   \n",
              "39342172        -0.999773   -1.000000    -0.879588    -0.879588   -0.449826   \n",
              "39342173        -0.999773   -1.000000    -0.879588    -0.879588   -0.450689   \n",
              "39342174        -0.999977   -1.000000    -0.583443    -0.583443   -0.448436   \n",
              "39342175        -0.999977   -1.000000    -0.583443    -0.583443   -0.450753   \n",
              "\n",
              "          rel_bid_ex  BEST_rel_bid  ...  chg_all_lead  chg_all_lag    ask_ex  \\\n",
              "39342171    0.450753     -0.222609  ...      0.979614     0.887864 -0.869878   \n",
              "39342172    0.449826     -0.221914  ...      0.979609     0.887724 -0.387113   \n",
              "39342173    0.450689     -0.222561  ...      0.979589     0.887492 -0.031559   \n",
              "39342174    0.448436     -0.220290  ...      0.979647     0.887998 -0.673685   \n",
              "39342175    0.450753     -0.222609  ...      0.979636     0.887758 -0.700498   \n",
              "\n",
              "            bid_ex  BEST_ASK  BEST_BID  price_all_lag  price_all_lead  \\\n",
              "39342171 -0.883935 -0.922989 -0.883936      -0.917824       -0.921640   \n",
              "39342172 -0.403539 -0.637270 -0.403545      -0.511138       -0.615242   \n",
              "39342173 -0.059053 -0.426840 -0.059063      -0.248786       -0.402171   \n",
              "39342174 -0.709687 -0.811995 -0.709690      -0.802774       -0.914062   \n",
              "39342175 -0.724674 -0.822743 -0.724677      -0.747425       -0.913006   \n",
              "\n",
              "          price_ex_lag  price_ex_lead  \n",
              "39342171     -0.897066      -0.875702  \n",
              "39342172     -0.380144      -0.521084  \n",
              "39342173     -0.057769      -0.080426  \n",
              "39342174     -1.000000      -1.000000  \n",
              "39342175     -1.000000      -1.000000  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ed5114f-71e2-4040-9759-84bb25b4a4c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRADE_PRICE</th>\n",
              "      <th>bid_ask_size_ratio_ex</th>\n",
              "      <th>rel_bid_size_ex</th>\n",
              "      <th>rel_ask_size_ex</th>\n",
              "      <th>TRADE_SIZE</th>\n",
              "      <th>bid_size_ex</th>\n",
              "      <th>ask_size_ex</th>\n",
              "      <th>rel_ask_ex</th>\n",
              "      <th>rel_bid_ex</th>\n",
              "      <th>BEST_rel_bid</th>\n",
              "      <th>...</th>\n",
              "      <th>chg_all_lead</th>\n",
              "      <th>chg_all_lag</th>\n",
              "      <th>ask_ex</th>\n",
              "      <th>bid_ex</th>\n",
              "      <th>BEST_ASK</th>\n",
              "      <th>BEST_BID</th>\n",
              "      <th>price_all_lag</th>\n",
              "      <th>price_all_lead</th>\n",
              "      <th>price_ex_lag</th>\n",
              "      <th>price_ex_lead</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39342171</th>\n",
              "      <td>-0.886605</td>\n",
              "      <td>-0.999944</td>\n",
              "      <td>-0.999978</td>\n",
              "      <td>-0.999959</td>\n",
              "      <td>-0.920668</td>\n",
              "      <td>-0.397940</td>\n",
              "      <td>-0.568327</td>\n",
              "      <td>-0.450753</td>\n",
              "      <td>0.450753</td>\n",
              "      <td>-0.222609</td>\n",
              "      <td>...</td>\n",
              "      <td>0.979614</td>\n",
              "      <td>0.887864</td>\n",
              "      <td>-0.869878</td>\n",
              "      <td>-0.883935</td>\n",
              "      <td>-0.922989</td>\n",
              "      <td>-0.883936</td>\n",
              "      <td>-0.917824</td>\n",
              "      <td>-0.921640</td>\n",
              "      <td>-0.897066</td>\n",
              "      <td>-0.875702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39342172</th>\n",
              "      <td>-0.398830</td>\n",
              "      <td>-0.999980</td>\n",
              "      <td>-0.999660</td>\n",
              "      <td>-0.999773</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.879588</td>\n",
              "      <td>-0.879588</td>\n",
              "      <td>-0.449826</td>\n",
              "      <td>0.449826</td>\n",
              "      <td>-0.221914</td>\n",
              "      <td>...</td>\n",
              "      <td>0.979609</td>\n",
              "      <td>0.887724</td>\n",
              "      <td>-0.387113</td>\n",
              "      <td>-0.403539</td>\n",
              "      <td>-0.637270</td>\n",
              "      <td>-0.403545</td>\n",
              "      <td>-0.511138</td>\n",
              "      <td>-0.615242</td>\n",
              "      <td>-0.380144</td>\n",
              "      <td>-0.521084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39342173</th>\n",
              "      <td>-0.060248</td>\n",
              "      <td>-0.999980</td>\n",
              "      <td>-0.999660</td>\n",
              "      <td>-0.999773</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.879588</td>\n",
              "      <td>-0.879588</td>\n",
              "      <td>-0.450689</td>\n",
              "      <td>0.450689</td>\n",
              "      <td>-0.222561</td>\n",
              "      <td>...</td>\n",
              "      <td>0.979589</td>\n",
              "      <td>0.887492</td>\n",
              "      <td>-0.031559</td>\n",
              "      <td>-0.059053</td>\n",
              "      <td>-0.426840</td>\n",
              "      <td>-0.059063</td>\n",
              "      <td>-0.248786</td>\n",
              "      <td>-0.402171</td>\n",
              "      <td>-0.057769</td>\n",
              "      <td>-0.080426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39342174</th>\n",
              "      <td>-0.675788</td>\n",
              "      <td>-0.999980</td>\n",
              "      <td>-0.999966</td>\n",
              "      <td>-0.999977</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.583443</td>\n",
              "      <td>-0.583443</td>\n",
              "      <td>-0.448436</td>\n",
              "      <td>0.448436</td>\n",
              "      <td>-0.220290</td>\n",
              "      <td>...</td>\n",
              "      <td>0.979647</td>\n",
              "      <td>0.887998</td>\n",
              "      <td>-0.673685</td>\n",
              "      <td>-0.709687</td>\n",
              "      <td>-0.811995</td>\n",
              "      <td>-0.709690</td>\n",
              "      <td>-0.802774</td>\n",
              "      <td>-0.914062</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39342175</th>\n",
              "      <td>-0.727221</td>\n",
              "      <td>-0.999980</td>\n",
              "      <td>-0.999966</td>\n",
              "      <td>-0.999977</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.583443</td>\n",
              "      <td>-0.583443</td>\n",
              "      <td>-0.450753</td>\n",
              "      <td>0.450753</td>\n",
              "      <td>-0.222609</td>\n",
              "      <td>...</td>\n",
              "      <td>0.979636</td>\n",
              "      <td>0.887758</td>\n",
              "      <td>-0.700498</td>\n",
              "      <td>-0.724674</td>\n",
              "      <td>-0.822743</td>\n",
              "      <td>-0.724677</td>\n",
              "      <td>-0.747425</td>\n",
              "      <td>-0.913006</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ed5114f-71e2-4040-9759-84bb25b4a4c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ed5114f-71e2-4040-9759-84bb25b4a4c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ed5114f-71e2-4040-9759-84bb25b4a4c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIOV1jA_ImH"
      },
      "source": [
        "## TabTransformer Baseline 🦾"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementation of a TabTransformer.\n",
        "Based on paper:\n",
        "https://arxiv.org/abs/2012.06678\n",
        "Implementation adapted from: https://github.com/lucidrains/tab-transformer-pytorch\n",
        "and https://github.com/kathrinse/TabSurvey/blob/main/models/tabtransformer.py\n",
        "Also see: https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Callable\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "from torch import einsum, nn\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of residual connections.\n",
        "    Args:\n",
        "        nn (nn.Module): module\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fn: nn.Module):\n",
        "        \"\"\"\n",
        "        Residual connection.\n",
        "        Args:\n",
        "            fn (nn.Module): network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of residual connections.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of pre-normalization.\n",
        "    Args:\n",
        "        nn (nn.module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, fn: nn.Module):\n",
        "        \"\"\"\n",
        "        Pre-normalization.\n",
        "        Consists of layer for layer normalization followed by another network.\n",
        "        Args:\n",
        "            dim (int): Number of dimensions of normalized shape.\n",
        "            fn (nn.Module): network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of pre-normalization layers.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    r\"\"\"\n",
        "    Implementation of the GeGLU activation function.\n",
        "    Given by:\n",
        "    $\\operatorname{GeGLU}(x, W, V, b, c)=\\operatorname{GELU}(x W+b) \\otimes(x V+c)$\n",
        "    Proposed in https://arxiv.org/pdf/2002.05202v1.pdf.\n",
        "    Args:\n",
        "        nn (torch.Tensor): module\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of GeGlU activation.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        x, gates = x.chunk(2, dim=-1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of feed forward network.\n",
        "    Args:\n",
        "        nn (nn.module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, mult: int = 4, dropout: float = 0.0):\n",
        "        \"\"\"\n",
        "        Feed forward network.\n",
        "        Network consists of input layer, GEGLU activation, dropout layer,\n",
        "        and output layer.\n",
        "        Args:\n",
        "            dim (int): dimension of input and output layer.\n",
        "            mult (int, optional): Scaling factor for output dimension of input layer or\n",
        "            input dimension of output layer. Defaults to 4.\n",
        "            dropout (float, optional): Degree of dropout. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GEGLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim * mult, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of feed forward network.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch implementation of attention.\n",
        "    Args:\n",
        "        nn (nn.Module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dim: int, heads: int = 8, dim_head: int = 16, dropout: float = 0.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Attention.\n",
        "        Args:\n",
        "            dim (int): Number of dimensions.\n",
        "            heads (int, optional): Number of attention heads. Defaults to 8.\n",
        "            dim_head (int, optional): Dimension of attention heads. Defaults to 16.\n",
        "            dropout (float, optional): Degree of dropout. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head**-0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of attention module.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        h = self.heads\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=h), (q, k, v))\n",
        "        sim = einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
        "\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\", h=h)\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer.\n",
        "    Based on paper:\n",
        "    https://arxiv.org/abs/1706.03762\n",
        "    Args:\n",
        "        nn (nn.Module): Module with transformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens: int,\n",
        "        dim: int,\n",
        "        depth: int,\n",
        "        heads: int,\n",
        "        dim_head: int,\n",
        "        attn_dropout: float,\n",
        "        ff_dropout: float,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Classical transformer.\n",
        "        Args:\n",
        "            num_tokens (int): Number of tokens i. e., unique classes + special tokens.\n",
        "            dim (int): Number of dimensions.\n",
        "            depth (int): Depth of encoder / decoder.\n",
        "            heads (int): Number of attention heads.\n",
        "            dim_head (int): Dimensions of attention heads.\n",
        "            attn_dropout (float): Degree of dropout in attention.\n",
        "            ff_dropout (float): Degree of dropout in feed-forward network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Embedding(num_tokens, dim)  # (Embed the categorical features.)\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(\n",
        "                nn.ModuleList(\n",
        "                    [\n",
        "                        Residual(\n",
        "                            PreNorm(\n",
        "                                dim,\n",
        "                                Attention(\n",
        "                                    dim,\n",
        "                                    heads=heads,\n",
        "                                    dim_head=dim_head,\n",
        "                                    dropout=attn_dropout,\n",
        "                                ),\n",
        "                            )\n",
        "                        ),\n",
        "                        Residual(PreNorm(dim, FeedForward(dim, dropout=ff_dropout))),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of transformer.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        x = self.embeds(x)\n",
        "\n",
        "        for attn, ff in self.layers:  # type: ignore\n",
        "            x = attn(x)\n",
        "            x = ff(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch model of a vanilla multi-layer perceptron.\n",
        "    Args:\n",
        "        nn (nn.Module): module with implementation of MLP.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dims: list[int], act: str | Callable[..., nn.Module]):\n",
        "        \"\"\"\n",
        "        Multilayer perceptron.\n",
        "        Depth of network is given by `len(dims)`. Capacity is given by entries\n",
        "        of `dim`. Activation function is used after each linear layer. There is\n",
        "        no activation function for the final linear layer, as it is sometimes part\n",
        "        of the loss function already e. g., `nn.BCEWithLogitsLoss()`.\n",
        "        Args:\n",
        "            dims (List[int]): List with dimensions of layers.\n",
        "            act (str | Callable[..., nn.Module]): Activation function of each linear\n",
        "            layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
        "        layers = []\n",
        "        for dim_in, dim_out in dims_pairs:\n",
        "            linear = nn.Linear(dim_in, dim_out)\n",
        "            layers.append(linear)\n",
        "            layers.append(act)\n",
        "\n",
        "        # drop last layer, as a sigmoid layer is included from BCELogitLoss\n",
        "        del layers[-1]\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagate tensor through MLP.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "class TabTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch model of TabTransformer.\n",
        "    Based on paper:\n",
        "    https://arxiv.org/abs/2012.06678\n",
        "    Args:\n",
        "        nn (nn.Module): Module with implementation of TabTransformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        categories: tuple[int, ...] | tuple[()],\n",
        "        num_continuous: int,\n",
        "        dim: int = 32,\n",
        "        depth: int = 4,\n",
        "        heads: int = 8,\n",
        "        dim_head: int = 16,\n",
        "        dim_out: int = 1,\n",
        "        mlp_hidden_mults: tuple[(int, int)] = (4, 2),\n",
        "        mlp_act: str | Callable[..., nn.Module] = nn.ReLU,\n",
        "        num_special_tokens: int = 2,\n",
        "        continuous_mean_std: torch.Tensor | None = None,\n",
        "        attn_dropout: float = 0.0,\n",
        "        ff_dropout: float = 0.0,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        TabTransformer.\n",
        "        Originally introduced in https://arxiv.org/abs/2012.06678.\n",
        "        Args:\n",
        "            categories ([List[int] | Tuple[()]): List with number of categories\n",
        "            for each categorical feature. If no categorical variables are present,\n",
        "            use empty tuple. For categorical variables e. g., option type ('C' or 'P'),\n",
        "            the list would be `[1]`.\n",
        "            num_continuous (int): Number of continous features.\n",
        "            dim (int, optional): Dimensionality of transformer. Defaults to 32.\n",
        "            depth (int, optional): Depth of encoder / decoder of transformer.\n",
        "            Defaults to 4.\n",
        "            heads (int, optional): Number of attention heads. Defaults to 8.\n",
        "            dim_head (int, optional): Dimensionality of attention head. Defaults to 16.\n",
        "            dim_out (int, optional): Dimension of output layer of MLP. Set to one for\n",
        "            binary classification. Defaults to 1.\n",
        "            mlp_hidden_mults (Tuple[(int, int)], optional): multipliers for dimensions\n",
        "            of hidden layer in MLP. Defaults to (4, 2).\n",
        "            mlp_act (str | Callable[..., nn.Module], optional): Activation function used\n",
        "            in MLP. Defaults to nn.ReLU().\n",
        "            num_special_tokens (int, optional): Number of special tokens in transformer.\n",
        "            Defaults to 2.\n",
        "            continuous_mean_std (Optional[torch.Tensor]): List with mean and\n",
        "            std deviation of each continous feature. Shape eq. `[num_continous x 2]`.\n",
        "            Defaults to None.\n",
        "            attn_dropout (float, optional): Degree of attention dropout used in\n",
        "            transformer. Defaults to 0.0.\n",
        "            ff_dropout (float, optional): Dropout in feed forward net. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert all(\n",
        "            map(lambda n: n > 0, categories)\n",
        "        ), \"number of each category must be positive\"\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position\n",
        "        #  in the categories embedding table\n",
        "\n",
        "        categories_offset = F.pad(\n",
        "            torch.tensor(list(categories)), (1, 0), value=num_special_tokens\n",
        "        )  # Prepend num_special_tokens.\n",
        "        categories_offset = categories_offset.cumsum(dim=-1)[:-1]\n",
        "        self.register_buffer(\"categories_offset\", categories_offset)\n",
        "\n",
        "        # continuous\n",
        "\n",
        "        if continuous_mean_std is not None:\n",
        "            assert continuous_mean_std.shape == (num_continuous, 2,), (\n",
        "                f\"continuous_mean_std must have a shape of ({num_continuous}, 2)\"\n",
        "                f\"where the last dimension contains the mean and variance respectively\"\n",
        "            )\n",
        "        self.register_buffer(\"continuous_mean_std\", continuous_mean_std)\n",
        "\n",
        "        self.norm = nn.LayerNorm(num_continuous)\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        # transformer\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            num_tokens=total_tokens,\n",
        "            dim=dim,\n",
        "            depth=depth,\n",
        "            heads=heads,\n",
        "            dim_head=dim_head,\n",
        "            attn_dropout=attn_dropout,\n",
        "            ff_dropout=ff_dropout,\n",
        "        )\n",
        "\n",
        "        # mlp to logits\n",
        "\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "        j = input_size // 8\n",
        "\n",
        "        hidden_dimensions = list(map(lambda t: j * t, mlp_hidden_mults))\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "\n",
        "        self.mlp = MLP(all_dimensions, act=mlp_act)\n",
        "\n",
        "    def forward(self, x_categ: torch.Tensor, x_cont: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of TabTransformer.\n",
        "        Args:\n",
        "            x_categ (torch.Tensor): tensor with categorical data.\n",
        "            x_cont (torch.Tensor): tensor with continous data.\n",
        "        Returns:\n",
        "            torch.Tensor: predictions with shape [batch, 1]\n",
        "        \"\"\"\n",
        "        # Adaptation to work without categorical data\n",
        "        if x_categ is not None:\n",
        "            assert x_categ.shape[-1] == self.num_categories, (\n",
        "                f\"you must pass in {self.num_categories} \"\n",
        "                f\"values for your categories input\"\n",
        "            )\n",
        "            x_categ += self.categories_offset\n",
        "            x = self.transformer(x_categ)\n",
        "            flat_categ = x.flatten(1)\n",
        "\n",
        "        assert x_cont.shape[1] == self.num_continuous, (\n",
        "            f\"you must pass in {self.num_continuous} \"\n",
        "            f\"values for your continuous input\"\n",
        "        )\n",
        "\n",
        "        if self.continuous_mean_std is not None:\n",
        "            mean, std = self.continuous_mean_std.unbind(dim=-1)  # type: ignore\n",
        "            x_cont = (x_cont - mean) / std\n",
        "\n",
        "        normed_cont = self.norm(x_cont)\n",
        "\n",
        "        # Adaptation to work without categorical data\n",
        "        x = (\n",
        "            torch.cat((flat_categ, normed_cont), dim=-1)\n",
        "            if x_categ is not None\n",
        "            else normed_cont\n",
        "        )\n",
        "\n",
        "        return self.mlp(x)"
      ],
      "metadata": {
        "id": "qDOyrmhdIT87"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementation of a dataset for tabular data.\n",
        "Supports both categorical and continous data.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for tabular data.\n",
        "    Args:\n",
        "        Dataset (Dataset): dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        x: pd.DataFrame,\n",
        "        y: pd.Series,\n",
        "        cat_features: list[str] | None = None,\n",
        "        cat_unique_counts: tuple[int, ...] | None = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Tabular data set holding data for the model.\n",
        "        Args:\n",
        "            x (pd.DataFrame): feature matrix.\n",
        "            y (pd.Series): target.\n",
        "            cat_features (Optional[List[str]], optional): List with categorical columns.\n",
        "            Defaults to None.\n",
        "            cat_unique_counts (Optional[Tuple[int]], optional): Number of categories per\n",
        "            categorical feature. Defaults to None.\n",
        "        \"\"\"\n",
        "        self._cat_unique_counts = () if not cat_unique_counts else cat_unique_counts\n",
        "\n",
        "        # calculate cat indices\n",
        "        features = x.columns.tolist()\n",
        "        cat_features = [] if not cat_features else cat_features\n",
        "        self._cat_idx = [features.index(i) for i in cat_features if i in features]\n",
        "\n",
        "        # calculate cont indices\n",
        "        cont_features = [f for f in features if f not in cat_features]\n",
        "        self._cont_idx = [features.index(i) for i in cont_features if i in features]\n",
        "\n",
        "        assert (\n",
        "            x.shape[0] == y.shape[0]\n",
        "        ), \"Length of feature matrix must match length of target.\"\n",
        "        assert len(cat_features) == len(\n",
        "            self._cat_unique_counts\n",
        "        ), \"For all categorical features the number of unique entries must be provided.\"\n",
        "\n",
        "        # adjust target to be either 0 or 1\n",
        "        self.y = torch.tensor(y.values).float()\n",
        "        self.y[self.y < 0] = 0\n",
        "\n",
        "        # cut into continous and categorical tensor\n",
        "        self.x_cat: torch.Tensor | None = None\n",
        "        if len(self._cat_idx) > 0:\n",
        "            self.x_cat = torch.tensor(x.iloc[:, self._cat_idx].values).int()\n",
        "        self.x_cont = torch.tensor(x.iloc[:, self._cont_idx].values).float()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Length of dataset.\n",
        "        Returns:\n",
        "            int: length\n",
        "        \"\"\"\n",
        "        return len(self.x_cont)\n",
        "\n",
        "    def __getitem__(\n",
        "        self, idx: int\n",
        "    ) -> tuple[torch.Tensor | None, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Get sample for model.\n",
        "        Args:\n",
        "            idx (int): _description_\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor | None, torch.Tensor, torch.Tensor]:\n",
        "            x_cat (if present if present otherwise None), x_cont and y.\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self.x_cat[idx] if self.x_cat else None,\n",
        "            self.x_cont[idx],\n",
        "            self.y[idx],\n",
        "        )"
      ],
      "metadata": {
        "id": "RHqIrTyeInVr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A fast dataloader-like object to load batches of tabular data sets.\n",
        "Adapted from here:\n",
        "https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class TabDataLoader:\n",
        "    \"\"\"\n",
        "    PyTorch Implementation of a dataloader for tabular data.\n",
        "    Due to a chunk-wise reading or several rows at once it is preferred\n",
        "    over the standard dataloader that reads row-wise.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *tensors: torch.Tensor | None,\n",
        "        batch_size: int = 4096,\n",
        "        shuffle: bool = False,\n",
        "        device: str = \"cpu\",\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        TabDataLoader.\n",
        "        Tensors can be None e. g., if there is no categorical data.\n",
        "        Args:\n",
        "            batch_size (int, optional): size of batch. Defaults to 4096.\n",
        "            shuffle (bool, optional): shuffle data. Defaults to False.\n",
        "            device (str, optional): device where. Defaults to \"cpu\".\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        # check for tensors that are None\n",
        "        self.none_mask = tuple(t is None for t in tensors)\n",
        "        # filter if for not none tensors\n",
        "        self.tensors = tuple(t for t in tensors if t is not None)\n",
        "\n",
        "        # check if all tensors have same length\n",
        "        assert all(t.shape[0] == self.tensors[0].shape[0] for t in self.tensors)\n",
        "\n",
        "        self.dataset_len = self.tensors[0].shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Calculate # batches\n",
        "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
        "        if remainder > 0:\n",
        "            n_batches += 1\n",
        "        self.n_batches = n_batches\n",
        "\n",
        "    def __iter__(self) -> TabDataLoader:\n",
        "        \"\"\"\n",
        "        Return itself.\n",
        "        Returns:\n",
        "            TabDataLoader: TabDataLoader\n",
        "        \"\"\"\n",
        "        if self.shuffle:\n",
        "            r = torch.randperm(self.dataset_len)\n",
        "            self.tensors = tuple(t[r] for t in self.tensors if t)\n",
        "        # reset counter on new iteration\n",
        "        self.i = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self) -> tuple[torch.Tensor | None, ...]:\n",
        "        \"\"\"\n",
        "        Generate next batch with size of 'batch_size'.\n",
        "        Batches can be underful.\n",
        "        Raises:\n",
        "            StopIteration: stopping criterion.\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor | None, torch.Tensor, torch.Tensor]: (X_cat), X_cont, y\n",
        "        \"\"\"\n",
        "        if self.i >= self.dataset_len:\n",
        "            raise StopIteration\n",
        "        mixed_batch: list[torch.Tensor | None] = [\n",
        "            t[self.i : self.i + self.batch_size].to(self.device) for t in self.tensors\n",
        "        ]\n",
        "        self.i += self.batch_size\n",
        "\n",
        "        # tensors + nones if input tensors contained none\n",
        "        for i, is_none in enumerate(self.none_mask):\n",
        "            if is_none:\n",
        "                mixed_batch.insert(i, None)\n",
        "\n",
        "        return tuple(mixed_batch)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Get number of full and partial batches in data set.\n",
        "        Returns:\n",
        "            int: number of batches.\n",
        "        \"\"\"\n",
        "        return self.n_batches"
      ],
      "metadata": {
        "id": "jHhZzbyOIvUN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://wandb.ai/fbv/thesis/runs/4fmccjm7/files/wandb-summary.json\n",
        "# https://wandb.ai/fbv/thesis/artifacts/model/3lfsbuby_TabTransformer_default_trial_82.pth/3a1937a3e6ec748d45a3/metadata\n",
        "params = {  \"dim\": 32,\n",
        "  \"depth\": 3,\n",
        "  \"heads\": 2,\n",
        "  \"weight_decay\": 0.00835620489462654,\n",
        "  \"lr\": 0.0015514372468568292,\n",
        "  \"dropout\": 0.1,\n",
        "  \"batch_size\": 32768}\n",
        "\n",
        "training_data = TabDataset(X_test, y_test, [], [])\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")        \n",
        "\n",
        "# differentiate between continous features only and mixed.\n",
        "test_loader = TabDataLoader(\n",
        "training_data.x_cat, training_data.x_cont, training_data.y, batch_size=params['batch_size'], device=device\n",
        ")\n",
        "\n",
        "       \n",
        "model = TabTransformer(\n",
        "            categories=[],\n",
        "            num_continuous=len(features_classical_size),\n",
        "            dim_out=1,\n",
        "            mlp_act=nn.ReLU(),\n",
        "            dim=params[\"dim\"],\n",
        "            depth=params[\"depth\"],\n",
        "            heads=params[\"heads\"],\n",
        "            attn_dropout=params[\"dropout\"],\n",
        "            ff_dropout=params[\"dropout\"],\n",
        "            mlp_hidden_mults=(4, 2),\n",
        "        ).to(device)\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(Path(model_dir,\"3lfsbuby_TabTransformer_default_trial_82.pth\")))\n",
        "model.eval()\n",
        "\n",
        "y_pred, y_true = [], []\n",
        "\n",
        "for x_cat, x_cont, targets in test_loader:\n",
        "  output = model(x_cat, x_cont)\n",
        "\n",
        "  # map between zero and one, sigmoid is otherwise included in loss already\n",
        "  # https://stackoverflow.com/a/66910866/5755604\n",
        "  output = torch.sigmoid(output.squeeze())\n",
        "  y_pred.append(output.detach().cpu().numpy())\n",
        "  y_true.append(targets.detach().cpu().numpy())  # type: ignore\n",
        "\n",
        "# round prediction to nearest int\n",
        "y_pred = np.rint(np.concatenate(y_pred))\n",
        "y_true = np.concatenate(y_true)\n",
        "\n",
        "# map zeros back to -1\n",
        "y_pred[y_pred == 0] = -1\n",
        "y_true[y_true == 0] = -1"
      ],
      "metadata": {
        "id": "_QQ7sa9OJA2X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "xD8uTBuBN9ai",
        "outputId": "de97533b-2724-43b1-98d5-d2e724893f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.672905426069829"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load default data to use unscaled version with all possible columns\n",
        "test_orig = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/test_set_extended_20.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        ")"
      ],
      "metadata": {
        "id": "AMoxcj4YZXOs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3evMG-KVA2eX"
      },
      "outputs": [],
      "source": [
        "# Copy unscaled columns\n",
        "X_print = test_orig.copy()\n",
        "\n",
        "# add baseline results\n",
        "X_print[\"rule\"] = \"Baseline\"\n",
        "X_print[\"buy_sell_predicted\"] = y_pred\n",
        "\n",
        "# prepare columns for printing\n",
        "X_print[\"ttm\"] = (\n",
        "    X_print[\"EXPIRATION\"].dt.to_period(\"M\")\n",
        "    - X_print[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
        ").apply(lambda x: x.n)\n",
        "X_print[\"year\"] = X_print[\"QUOTE_DATETIME\"].dt.year\n",
        "\n",
        "bins_tradesize = [-np.inf, 1, 3, 5, 11, np.inf]\n",
        "trade_size_labels = [\"(0,1]\", \"(1,3]\", \"(3,5]\", \"(5,11]\", \">11\"]\n",
        "X_print[\"TRADE_SIZE_binned\"] = pd.cut(\n",
        "    X_print[\"TRADE_SIZE\"], bins_tradesize, labels=trade_size_labels\n",
        ")\n",
        "\n",
        "bins_years = [2004, 2007, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
        "year_labels = [\n",
        "    \"2005-2007\",\n",
        "    \"2008-2010\",\n",
        "    \"2011\",\n",
        "    \"2012\",\n",
        "    \"2013\",\n",
        "    \"2014\",\n",
        "    \"2015\",\n",
        "    \"2016\",\n",
        "    \"2017\",\n",
        "]\n",
        "X_print[\"year_binned\"] = pd.cut(X_print[\"year\"], bins_years, labels=year_labels)\n",
        "\n",
        "bins_ttm = [-np.inf, 1, 2, 3, 6, 12, np.inf]\n",
        "ttm_labels = [\n",
        "    \"ttm <= 1 month\",\n",
        "    \"ttm (1-2] month\",\n",
        "    \"ttm (2-3] month\",\n",
        "    \"ttm (3-6] month\",\n",
        "    \"ttm (6-12] month\",\n",
        "    \"ttm > 12 month\",\n",
        "]\n",
        "X_print[\"ttm_binned\"] = pd.cut(X_print[\"ttm\"], bins_ttm, labels=ttm_labels)\n",
        "\n",
        "\n",
        "bins_myn = [-np.inf, 0.7, 0.9, 1.1, 1.3, np.inf]\n",
        "myn_labels = [\n",
        "    \"mny <=0.7\",\n",
        "    \"mny (0.7-0.9]\",\n",
        "    \"mny (0.9-1.1]\",\n",
        "    \"mny (1.1-1.3]\",\n",
        "    \"mny > 1.3\",\n",
        "]\n",
        "X_print[\"myn_binned\"] = pd.cut(X_print[\"myn\"], bins_myn, labels=myn_labels)\n",
        "\n",
        "X_print[\"issue_type_binned\"] = X_print[\"issue_type\"].replace(\n",
        "    {\"0\": 'Stock options', 'A': 'Index options', '7': 'Others',\n",
        "     'F': 'Others', '%': 'Others', ' ': 'Others'})\n",
        "\n",
        "\n",
        "# TODO: time from previous trade; same underlying or any?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "clDZ4Z95_0jj"
      },
      "outputs": [],
      "source": [
        "def check_robustness(criterion: str = \"year_binned\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Check robustness of rules by calculating the accuracy for a given\n",
        "    criterion and rules.\n",
        "\n",
        "    Example:\n",
        "    rule\t\tBaseline\n",
        "    TRADE_SIZE_binned\n",
        "    (0,1]\t  0.710966\n",
        "    (1,3]\t  0.717664\n",
        "    (3,5]\t  0.715195\n",
        "    (5,11]\t0.699428\n",
        "    >11\t  \t0.688348\n",
        "\n",
        "    Args:\n",
        "        criterion (str, optional): criterion to check robustness for.\n",
        "        Defaults to \"year_binned\".\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with accuracy of rules. Rule in columns and\n",
        "        criterion values in rows.\n",
        "    \"\"\"\n",
        "\n",
        "    # fill others randomly with equal weight for every class.\n",
        "    X_print[\"buy_sell_predicted\"] = X_print[\"buy_sell_predicted\"].map(\n",
        "        lambda l: l if not np.isnan(l) else np.random.choice([-1, 1])\n",
        "    )\n",
        "\n",
        "    # cuculate average over columns if multiple subsets are combined\n",
        "    results = (\n",
        "        X_print.groupby([\"rule\", criterion])[[\"buy_sell\", \"buy_sell_predicted\"]]\n",
        "        .apply(lambda x: accuracy_score(x[\"buy_sell\"], x[\"buy_sell_predicted\"]))\n",
        "        .unstack(level=0)\n",
        "        .assign(avg=lambda x: x.mean(axis=1))\n",
        "    )\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4KRw_J0IJiFU",
        "outputId": "374fac9f-97cb-4338-bf79-b289332a0b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule         Baseline       avg\n",
              "year_binned                    \n",
              "2015         0.645190  0.645190\n",
              "2016         0.676413  0.676413\n",
              "2017         0.674097  0.674097"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-142d4b0c-1a16-4751-a297-f9a135ea9582\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year_binned</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>0.645190</td>\n",
              "      <td>0.645190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>0.676413</td>\n",
              "      <td>0.676413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>0.674097</td>\n",
              "      <td>0.674097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-142d4b0c-1a16-4751-a297-f9a135ea9582')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-142d4b0c-1a16-4751-a297-f9a135ea9582 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-142d4b0c-1a16-4751-a297-f9a135ea9582');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fCey7G_tE6zt",
        "outputId": "95762483-bc9e-406c-9024-ee7d8b968e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule         Baseline       avg\n",
              "OPTION_TYPE                    \n",
              "C            0.675753  0.675753\n",
              "P            0.669654  0.669654"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2568050d-7a4a-4a98-9dee-cc0214226e94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OPTION_TYPE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>0.675753</td>\n",
              "      <td>0.675753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P</th>\n",
              "      <td>0.669654</td>\n",
              "      <td>0.669654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2568050d-7a4a-4a98-9dee-cc0214226e94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2568050d-7a4a-4a98-9dee-cc0214226e94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2568050d-7a4a-4a98-9dee-cc0214226e94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "check_robustness(\"OPTION_TYPE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_robustness(\"issue_type_binned\")"
      ],
      "metadata": {
        "id": "AGbchxWfds_Y",
        "outputId": "6b5646cb-65e4-4e59-979a-febc33b9be67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule               Baseline       avg\n",
              "issue_type_binned                    \n",
              "Index options      0.524634  0.524634\n",
              "Others             0.702792  0.702792\n",
              "Stock options      0.663093  0.663093"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75df8636-637c-493f-9812-73747be0ce5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>issue_type_binned</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Index options</th>\n",
              "      <td>0.524634</td>\n",
              "      <td>0.524634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Others</th>\n",
              "      <td>0.702792</td>\n",
              "      <td>0.702792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stock options</th>\n",
              "      <td>0.663093</td>\n",
              "      <td>0.663093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75df8636-637c-493f-9812-73747be0ce5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75df8636-637c-493f-9812-73747be0ce5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75df8636-637c-493f-9812-73747be0ce5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Zpg1yY2MEGFa",
        "outputId": "63d6b69b-4238-4831-a6a1-8cfc9f4ec39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule               Baseline       avg\n",
              "TRADE_SIZE_binned                    \n",
              "(0,1]              0.683563  0.683563\n",
              "(1,3]              0.690546  0.690546\n",
              "(3,5]              0.688925  0.688925\n",
              "(5,11]             0.653614  0.653614\n",
              ">11                0.634339  0.634339"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b7ffa85-233a-480e-b649-5c3b35a9ef0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TRADE_SIZE_binned</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(0,1]</th>\n",
              "      <td>0.683563</td>\n",
              "      <td>0.683563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1,3]</th>\n",
              "      <td>0.690546</td>\n",
              "      <td>0.690546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(3,5]</th>\n",
              "      <td>0.688925</td>\n",
              "      <td>0.688925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(5,11]</th>\n",
              "      <td>0.653614</td>\n",
              "      <td>0.653614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&gt;11</th>\n",
              "      <td>0.634339</td>\n",
              "      <td>0.634339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b7ffa85-233a-480e-b649-5c3b35a9ef0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b7ffa85-233a-480e-b649-5c3b35a9ef0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b7ffa85-233a-480e-b649-5c3b35a9ef0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "check_robustness(\"TRADE_SIZE_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8624JR8wEN4D",
        "outputId": "e7037e24-d07d-485f-a393-d513cbc07143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule              Baseline       avg\n",
              "ttm_binned                          \n",
              "ttm <= 1 month    0.669447  0.669447\n",
              "ttm (1-2] month   0.691056  0.691056\n",
              "ttm (2-3] month   0.681317  0.681317\n",
              "ttm (3-6] month   0.675536  0.675536\n",
              "ttm (6-12] month  0.675719  0.675719\n",
              "ttm > 12 month    0.665156  0.665156"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86d5e470-291f-44b7-8922-0f7a638cedcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm_binned</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ttm &lt;= 1 month</th>\n",
              "      <td>0.669447</td>\n",
              "      <td>0.669447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm (1-2] month</th>\n",
              "      <td>0.691056</td>\n",
              "      <td>0.691056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm (2-3] month</th>\n",
              "      <td>0.681317</td>\n",
              "      <td>0.681317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm (3-6] month</th>\n",
              "      <td>0.675536</td>\n",
              "      <td>0.675536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm (6-12] month</th>\n",
              "      <td>0.675719</td>\n",
              "      <td>0.675719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ttm &gt; 12 month</th>\n",
              "      <td>0.665156</td>\n",
              "      <td>0.665156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86d5e470-291f-44b7-8922-0f7a638cedcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86d5e470-291f-44b7-8922-0f7a638cedcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86d5e470-291f-44b7-8922-0f7a638cedcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "check_robustness(\"ttm_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_robustness(\"myn_binned\")\n"
      ],
      "metadata": {
        "id": "Z7Vn96hibEvM",
        "outputId": "4034575f-4c21-4f91-e621-817db6f3b332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rule           Baseline       avg\n",
              "myn_binned                       \n",
              "mny <=0.7      0.665539  0.665539\n",
              "mny (0.7-0.9]  0.665949  0.665949\n",
              "mny (0.9-1.1]  0.683752  0.683752\n",
              "mny (1.1-1.3]  0.626057  0.626057\n",
              "mny > 1.3      0.603918  0.603918"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3057ab08-688d-4d04-a577-5093f0457ea6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rule</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>myn_binned</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mny &lt;=0.7</th>\n",
              "      <td>0.665539</td>\n",
              "      <td>0.665539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mny (0.7-0.9]</th>\n",
              "      <td>0.665949</td>\n",
              "      <td>0.665949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mny (0.9-1.1]</th>\n",
              "      <td>0.683752</td>\n",
              "      <td>0.683752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mny (1.1-1.3]</th>\n",
              "      <td>0.626057</td>\n",
              "      <td>0.626057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mny &gt; 1.3</th>\n",
              "      <td>0.603918</td>\n",
              "      <td>0.603918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3057ab08-688d-4d04-a577-5093f0457ea6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3057ab08-688d-4d04-a577-5093f0457ea6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3057ab08-688d-4d04-a577-5093f0457ea6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
