{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pgf.texsystem\": \"xelatex\",\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"font.serif\": [],\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.sans-serif\": [],\n",
    "    \"axes.labelsize\": 11,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}\\usepackage[utf8]{inputenc}')\n",
    "\n",
    "CM = 1 / 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set project name. Required to access files and artefacts\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# see w&b\n",
    "model = \"2h81aiow_TransformerClassifier_default.pkl:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "artifact = run.use_artifact(model)\n",
    "model_dir = artifact.download()\n",
    "    \n",
    "with open(Path(model_dir, model_name), 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "embeddings = model.clf.feature_tokenizer.cat_tokenizer.embeddings.weight.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# as done https://github.com/pytorch/pytorch/issues/51445\n",
    "f = open(\"tensors.tsv\", mode=\"a\")\n",
    "for x in embeddings: \n",
    "    x = [str(i.item()) for i in x] \n",
    "    f.write('\\t'.join(x) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import this file (f) into embedding visualizer to generate t-SNE.\n",
    "# https://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate t-sne projection using save to bookmark feature https://projector.tensorflow.org/\n",
    "with open('../models/state.txt') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_projections = pd.DataFrame(d[0]['projections'])\n",
    "# get labels from scalers\n",
    "label = pd.read_csv('../models/metadata.tsv', sep='\\t', header=None).rename({0:\"label\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cos_dist_norm(matrix_of_vectors: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the cosine distance ([0, 2]) between two vectors that have been normalized to unit norm.\n",
    "    \"\"\"\n",
    "    return 1 - matrix_of_vectors @ matrix_of_vectors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cos_sim(matrix_of_vectors: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes cosine similarities for between all vectors, extremely useful for comparing\n",
    "    similarities between embeddings when doing deep embedding learning.\n",
    "\n",
    "    Adapted from: https://github.com/dalisson/pairwise_cosine_distance_pytorch/blob/master/pairwise_cosine_similarity.py\n",
    "\n",
    "    and:\n",
    "    https://github.com/tensorflow/tensorboard/blob/00eeb7adcbf341ec25b49c37abee1cfe395ea1f9/tensorboard/plugins/projector/vz_projector/vz-projector-inspector-panel.ts#L398\n",
    "    https://github.com/tensorflow/tensorboard/blob/00eeb7adcbf341ec25b49c37abee1cfe395ea1f9/tensorboard/plugins/projector/vz_projector/vector.ts#L64\n",
    "    \n",
    "    input:\n",
    "        matrix_of_vectors: tensor with shape (n_vectors, vector_size)\n",
    "\n",
    "    output:\n",
    "        similarities : tensor with shape (n_vector, n_vectors)\n",
    "    Each row[i, j] is the similarity of the ith element against the jth vector, eg,\n",
    "    row[0,0] is 1 and row[0,42] is the similarity between the first\n",
    "    element in the input and the 43th element in the input.\n",
    "    \"\"\"\n",
    "\n",
    "    dot_product = matrix_of_vectors @ matrix_of_vectors.t()\n",
    "    norms = torch.sqrt(torch.einsum(\"ii->i\", dot_product))\n",
    "    similarities = dot_product / (norms[None] * norms[..., None])\n",
    "    # similarities = dot_product / (norms[:, None] * norms[None, :])\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cos_dist(matrix_of_vectors: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the cosine distance ([0, 2]) between two vectors.\n",
    "    \"\"\"\n",
    "    return 1 - cos_sim(matrix_of_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"XOM\"\n",
    "idx = label.index[label[\"label\"] == key].tolist()[0]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities = cosine_similarity(embeddings)\n",
    "distances = cos_dist(embeddings)\n",
    "idx_distances = distances[idx].tolist()\n",
    "idx_distances = np.array(idx_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zorder = [int(o * 1000) for o in idx_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(idx_distances, index=label[\"label\"].tolist())\n",
    "results.sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for 10 most similar underlyings\n",
    "idx_labels = np.argpartition(idx_distances, 11)[:11]\n",
    "mask = np.zeros(len(idx_distances), dtype=bool)\n",
    "mask[idx_labels] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12 * CM, 8 * CM))\n",
    "\n",
    "# all non-near points in white-grey\n",
    "ax.scatter(\n",
    "    tsne_projections[\"tsne-0\"][~mask],\n",
    "    tsne_projections[\"tsne-1\"][~mask],\n",
    "    c=\"whitesmoke\",\n",
    "    s=5,\n",
    ")\n",
    "\n",
    "# all near points in color\n",
    "sc = ax.scatter(\n",
    "    tsne_projections[\"tsne-0\"][mask],\n",
    "    tsne_projections[\"tsne-1\"][mask],\n",
    "    cmap=\"Blues_r\",\n",
    "    c=idx_distances[mask],\n",
    "    s=10,\n",
    "    zorder=1000,\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"grey\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"$t$-SNE Axis 1\")\n",
    "ax.set_ylabel(\"$t$-SNE Axis 2\")\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i, cond in enumerate(mask):\n",
    "\n",
    "    if cond:\n",
    "        l = label[\"label\"].iloc[i]\n",
    "        factor = 1.5 if l == key else 1\n",
    "\n",
    "        # annotate labels with underlyings\n",
    "        texts.append(\n",
    "            ax.text(\n",
    "                tsne_projections[\"tsne-0\"].iloc[i],\n",
    "                tsne_projections[\"tsne-1\"].iloc[i],\n",
    "                r\"\\texttt{\" + l + r\"}\",\n",
    "                fontsize=7 * factor,\n",
    "                zorder=2000,\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "# adjust labels automatically to avoid overlap\n",
    "adjust_text(\n",
    "    texts, ax=ax, min_arrow_len=1, arrowprops=dict(arrowstyle=\"-\", color=\"k\", lw=0.5)\n",
    ")\n",
    "\n",
    "fig.colorbar(sc)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f\"../reports/Graphs/categorical_embeddings_{key}.pdf\", bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
