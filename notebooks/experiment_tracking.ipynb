{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatible with wandb version 0.9.2+\n",
    "!pip install wandb -qqq\n",
    "!apt install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data parameters\n",
    "num_classes = 10\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# drop slow mirror from list of MNIST mirrors\n",
    "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
    "                                      if not mirror.startswith(\"http://yann.lecun.com\")]\n",
    "\n",
    "def load(train_size=50_000):\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    \"\"\"\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    train = torchvision.datasets.MNIST(\"./\", train=True, download=True)\n",
    "    test = torchvision.datasets.MNIST(\"./\", train=False, download=True)\n",
    "    (x_train, y_train), (x_test, y_test) = (train.data, train.targets), (test.data, test.targets)\n",
    "\n",
    "    # split off a validation set for hyperparameter tuning\n",
    "    x_train, x_val = x_train[:train_size], x_train[train_size:]\n",
    "    y_train, y_val = y_train[:train_size], y_train[train_size:]\n",
    "\n",
    "    training_set = TensorDataset(x_train, y_train)\n",
    "    validation_set = TensorDataset(x_val, y_val)\n",
    "    test_set = TensorDataset(x_test, y_test)\n",
    "\n",
    "    datasets = [training_set, validation_set, test_set]\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_log():\n",
    "\n",
    "    # üöÄ start a run, with a type to label it and a project it can call home\n",
    "    with wandb.init(project=\"artifacts-example\", job_type=\"load-data\") as run:\n",
    "        \n",
    "        datasets = load()  # separate code for loading the datasets\n",
    "        names = [\"training\", \"validation\", \"test\"]\n",
    "\n",
    "        # üè∫ create our Artifact\n",
    "        raw_data = wandb.Artifact(\n",
    "            \"mnist-raw\", type=\"dataset\",\n",
    "            description=\"Raw MNIST dataset, split into train/val/test\",\n",
    "            metadata={\"source\": \"torchvision.datasets.MNIST\",\n",
    "                      \"sizes\": [len(dataset) for dataset in datasets]})\n",
    "\n",
    "        for name, data in zip(names, datasets):\n",
    "            # üê£ Store a new file in the artifact, and write something into its contents.\n",
    "            with raw_data.new_file(name + \".pt\", mode=\"wb\") as file:\n",
    "                x, y = data.tensors\n",
    "                torch.save((x, y), file)\n",
    "\n",
    "        # ‚úçÔ∏è Save the artifact to W&B.\n",
    "        run.log_artifact(raw_data)\n",
    "\n",
    "load_and_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset, normalize=True, expand_dims=True):\n",
    "    \"\"\"\n",
    "    ## Prepare the data\n",
    "    \"\"\"\n",
    "    x, y = dataset.tensors\n",
    "\n",
    "    if normalize:\n",
    "        # Scale images to the [0, 1] range\n",
    "        x = x.type(torch.float32) / 255\n",
    "\n",
    "    if expand_dims:\n",
    "        # Make sure images have shape (1, 28, 28)\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "    \n",
    "    return TensorDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_log(steps):\n",
    "\n",
    "    with wandb.init(project=\"artifacts-example\", job_type=\"preprocess-data\") as run:\n",
    "\n",
    "        processed_data = wandb.Artifact(\n",
    "            \"mnist-preprocess\", type=\"dataset\",\n",
    "            description=\"Preprocessed MNIST dataset\",\n",
    "            metadata=steps)\n",
    "         \n",
    "        # ‚úîÔ∏è declare which artifact we'll be using\n",
    "        raw_data_artifact = run.use_artifact('mnist-raw:latest')\n",
    "\n",
    "        # üì• if need be, download the artifact\n",
    "        raw_dataset = raw_data_artifact.download()\n",
    "        \n",
    "        for split in [\"training\", \"validation\", \"test\"]:\n",
    "            raw_split = read(raw_dataset, split)\n",
    "            processed_dataset = preprocess(raw_split, **steps)\n",
    "\n",
    "            with processed_data.new_file(split + \".pt\", mode=\"wb\") as file:\n",
    "                x, y = processed_dataset.tensors\n",
    "                torch.save((x, y), file)\n",
    "\n",
    "        run.log_artifact(processed_data)\n",
    "\n",
    "\n",
    "def read(data_dir, split):\n",
    "    filename = split + \".pt\"\n",
    "    x, y = torch.load(os.path.join(data_dir, filename))\n",
    "\n",
    "    return TensorDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {\"normalize\": True,\n",
    "         \"expand_dims\": True}\n",
    "\n",
    "preprocess_and_log(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
