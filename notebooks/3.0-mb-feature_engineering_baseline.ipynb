{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarelZe/thesis/blob/baseline/notebooks/3.0-mb-feature_engineering_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQwYMQAr-0vu",
        "outputId": "96b4428a-8363-448f-b103-4cdc9dc11eba"
      },
      "outputs": [],
      "source": [
        "!pip install catboost==1.1\n",
        "!pip install gcsfs==2022.10.0\n",
        "!pip install ipywidgets==8.0.2\n",
        "!pip install numpy==1.23.4\n",
        "!pip install pandas==1.5.1\n",
        "!pip install fastparquet\n",
        "!pip install optuna==3.0.3\n",
        "!pip install scikit-learn==1.1.3\n",
        "!pip install seaborn==0.12.1\n",
        "#!pip install shap==0.41.0\n",
        "!pip install wandb==0.13.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WXF7w4VyVgG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "import gcsfs\n",
        "\n",
        "# import google.auth\n",
        "# from google.colab import auth, output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# import shap\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCzoR4qrH4Nv",
        "outputId": "f3ee8986-f441-4942-8307-367d1f890ad5"
      },
      "outputs": [],
      "source": [
        "# init shap\n",
        "# shap.initjs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-eGOVujp_TN"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/root/.config/gcloud/application_default_credentials.json\"\n",
        "\n",
        "# connect to google cloud storage\n",
        "import google.auth\n",
        "from google.colab import auth, output\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "credentials, _ = google.auth.default()\n",
        "fs = gcsfs.GCSFileSystem(project=\"thesis\", token=credentials)\n",
        "fs_prefix = \"gs://\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF0_Mz8DYjGz"
      },
      "outputs": [],
      "source": [
        "# set fixed seed\n",
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproducibility of results\n",
        "    \"\"\"\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "seed = 42\n",
        "seed_everything(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmXtH-PEqyQE"
      },
      "outputs": [],
      "source": [
        "train = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/train_set_60.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        ")\n",
        "val = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/val_set_20.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        ")\n",
        "test = pd.read_parquet(\n",
        "    f\"gs://thesis-bucket-option-trade-classification/data/preprocessed/test_set_20.parquet\",\n",
        "    engine=\"fastparquet\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYosl7qJwYFS",
        "outputId": "12f6e7ec-043d-4128-ebde-7836dd591188"
      },
      "outputs": [],
      "source": [
        "train.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2ZHX3MpqzKD"
      },
      "outputs": [],
      "source": [
        "# randomly sample frac of rows\n",
        "# frac = 0.02\n",
        "\n",
        "# train = train.sample(frac=frac, random_state=seed)\n",
        "# val = val.sample(frac=frac, random_state=seed)\n",
        "# test = test.sample(frac=frac, random_state=seed)\n",
        "\n",
        "# unify for common preprocessing\n",
        "X = pd.concat([train, val, test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# isolate target\n",
        "y = X[[\"buy_sell\"]]\n",
        "X = X.drop([\"buy_sell\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4RRb08pyo6p"
      },
      "outputs": [],
      "source": [
        "# calculate days to maturity\n",
        "X[\"time_to_maturity\"] = (X[\"EXPIRATION\"] - X[\"QUOTE_DATETIME\"]).dt.days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDU5Wy02WWT"
      },
      "outputs": [],
      "source": [
        "# apply positional encoding to dates\n",
        "X[\"date_month_sin\"] = np.sin(2 * np.pi * X[\"QUOTE_DATETIME\"].dt.year / 12)\n",
        "X[\"date_month_cos\"] = np.cos(2 * np.pi * X[\"QUOTE_DATETIME\"].dt.year / 12)\n",
        "\n",
        "# apply positional encoding to dates\n",
        "X[\"date_month_sin\"] = np.sin(2 * np.pi * X[\"QUOTE_DATETIME\"].dt.year / 12)\n",
        "X[\"date_month_cos\"] = np.cos(2 * np.pi * X[\"QUOTE_DATETIME\"].dt.year / 12)\n",
        "\n",
        "seconds_in_day = 24 * 60 * 60\n",
        "\n",
        "seconds = (X[\"QUOTE_DATETIME\"] - X[\"QUOTE_DATETIME\"].dt.normalize()).dt.total_seconds()\n",
        "\n",
        "X[\"date_time_sin\"] = np.sin(2 * np.pi * seconds / seconds_in_day)\n",
        "X[\"date_time_cos\"] = np.cos(2 * np.pi * seconds / seconds_in_day)\n",
        "\n",
        "# add year\n",
        "X[\"date_year\"] = (X[\"QUOTE_DATETIME\"].dt.year - 2005) / (2017 - 2005)\n",
        "\n",
        "date_columns = [\n",
        "    \"date_month_sin\",\n",
        "    \"date_month_cos\",\n",
        "    \"date_time_sin\",\n",
        "    \"date_time_cos\",\n",
        "    \"date_year\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_set_date = [\n",
        "    \"date_month_sin\",\n",
        "    \"date_month_cos\",\n",
        "    \"date_time_sin\",\n",
        "    \"date_time_cos\" \"date_year\",\n",
        "]\n",
        "feature_set_option = [\n",
        "    \"STRK_PRC\",\n",
        "    \"ROOT\",\n",
        "    \"price_underlying\",\n",
        "    \"time_to_maturity\",\n",
        "    \"moneyness\",\n",
        "    \"delta\",\n",
        "    \"option-type\",\n",
        "    \"security_type\",\n",
        "]\n",
        "\n",
        "# features of classical rules\n",
        "feature_set_1 = [\n",
        "    \"TRADE_PRICE\",\n",
        "    \"price_ex_lag\",\n",
        "    \"chg_ex_lag\",\n",
        "    \"price_ex_lead\",\n",
        "    \"chg_ex_lead\",\n",
        "    \"bid_ex\",\n",
        "    \"ask_ex\",\n",
        "    \"midpoint_ex\",\n",
        "    \"rel_mid_ex\",\n",
        "    \"rel_bid_dist_ex\",\n",
        "    \"rel_ask_dist_ext\",\n",
        "]\n",
        "\n",
        "# features of classical rules enhanced for date features\n",
        "feature_set_2 = [*feature_set_1, *feature_set_date]\n",
        "\n",
        "# features of classical rules enhanced for date features and option features\n",
        "feature_set_4 = [*feature_set_1, *feature_set_date, *feature_set_option]\n",
        "\n",
        "# FIXME: adjust as needed\n",
        "feature_sets = [feature_set_1, feature_set_2]\n",
        "ignored_features = [x for x in X.columns.tolist() if x not in feature_set_2]\n",
        "X.drop(columns=ignored_features, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate change similar to tick rule\n",
        "X[\"chg_ex_lead\"] = X[\"TRADE_PRICE\"] - X[\"price_ex_lead\"]\n",
        "\n",
        "# Calculate change similar to reverse tick rule\n",
        "X[\"chg_ex_lag\"] = X[\"TRADE_PRICE\"] - X[\"price_ex_lag\"]\n",
        "\n",
        "# Midspread\n",
        "mid = 0.5 * (X[\"ask_ex\"] + X[\"bid_ex\"])\n",
        "X[\"midpoint_ex\"] = mid\n",
        "\n",
        "# distance metrics\n",
        "X[\"rel_mid_ex\"] = (X[\"TRADE_PRICE\"] - mid) / (X[\"ask_ex\"] - mid)\n",
        "X[\"rel_bid_dist_ex\"] = (X[\"TRADE_PRICE\"] - X[\"bid_ex\"]) / (mid - X[\"bid_ex\"])\n",
        "X[\"rel_ask_dist_ex\"] = (X[\"ask_ex\"] - X[\"TRADE_PRICE\"]) / (X[\"ask_ex\"] - mid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log transform\n",
        "log_columns = [\n",
        "    \"TRADE_PRICE\",\n",
        "    \"price_ex_lag\",\n",
        "    \"price_ex_lead\",\n",
        "    \"bid_ex\",\n",
        "    \"ask_ex\",\n",
        "    \"midpoint_ex\",\n",
        "]\n",
        "\n",
        "X[log_columns] = np.log(X[log_columns] + 1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KmaiY0m5i8X",
        "outputId": "0501b042-3e24-499e-c12d-8a1053b45409"
      },
      "outputs": [],
      "source": [
        "# binarize\n",
        "\n",
        "# select categorical e. g., option type and strings e. g., ticker\n",
        "cat_columns = X.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\n",
        "print(cat_columns)\n",
        "\n",
        "# binarize categorical similar to Borisov et al.\n",
        "X[cat_columns] = X[cat_columns].apply(lambda x: pd.factorize(x)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngZUqSLW_M_8"
      },
      "outputs": [],
      "source": [
        "# treat inf as nan\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIXLmMcZ5-aC"
      },
      "outputs": [],
      "source": [
        "# separate again for training scaling\n",
        "X_train = X.loc[train.index, :]\n",
        "X_val = X.loc[val.index, :]\n",
        "X_test = X.loc[test.index, :]\n",
        "\n",
        "y_train = y.loc[train.index, :]\n",
        "y_val = y.loc[val.index, :]\n",
        "y_test = y.loc[test.index, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV5a5st_2vrt"
      },
      "outputs": [],
      "source": [
        "# Standardize numerical values, if not standardized otherwise\n",
        "num_columns = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_columns = [\n",
        "    x for x in num_columns if x not in [*cat_columns, *date_columns, *log_columns]\n",
        "]\n",
        "# use scaler due to outlying observations > dataset notebook.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train[num_columns] = scaler.fit_transform(X_train[num_columns])\n",
        "X_val[num_columns] = scaler.transform(X_val[num_columns])\n",
        "X_test[num_columns] = scaler.transform(X_test[num_columns])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIOV1jA_ImH"
      },
      "source": [
        "## CatBoost Baseline ðŸˆâ€â¬›"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmbM8by1WO5J"
      },
      "source": [
        "### Hyperparameter Search BaselineðŸ—ƒï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4hMoRaVQa64"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial, features: list, cat_features: list = None):\n",
        "    # See docs for recommendations on tuning hyperparameters\n",
        "    #  https://catboost.ai/en/docs/concepts/parameter-tuning\n",
        "\n",
        "    ignored_features = [x for x in X_train.columns.tolist() if x not in features]\n",
        "\n",
        "    iterations = trial.suggest_int(\"iterations\", 100, 1500, log=False)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 0.005, 1, log=True)\n",
        "    depth = trial.suggest_int(\"depth\", 1, 8, log=False)\n",
        "    grow_policy = trial.suggest_categorical(\n",
        "        \"grow_policy\", [\"SymmetricTree\", \"Depthwise\"]\n",
        "    )\n",
        "    params = {\n",
        "        \"iterations\": iterations,\n",
        "        \"depth\": depth,\n",
        "        \"grow_policy\": grow_policy,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"od_type\": \"Iter\",\n",
        "        \"logging_level\": \"Silent\",\n",
        "        \"task_type\": \"GPU\",\n",
        "        \"cat_features\": cat_features,\n",
        "        \"ignored_features\": ignored_features,\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val, prediction_type=\"Class\")\n",
        "    return accuracy_score(y_val, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgdvLxBI3Cs3",
        "outputId": "77febc83-d538-4324-dd19-f8daa8b61aaf"
      },
      "outputs": [],
      "source": [
        "studies = []\n",
        "\n",
        "for features in tqdm(feature_sets):\n",
        "\n",
        "    # FIXME: Change later if needed\n",
        "    cat_features = None\n",
        "\n",
        "    # connect to weights and biases\n",
        "    run = wandb.init(project=\"thesis\", job_type=\"baseline\", entity=\"fbv\")\n",
        "\n",
        "    wandb_kwargs = {\"project\": \"thesis\"}\n",
        "    wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
        "\n",
        "    # Implement hyperparameter search\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        sampler=optuna.samplers.TPESampler(seed=seed),\n",
        "        study_name=\"baseline_gbm\",\n",
        "    )\n",
        "\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, features, cat_features),\n",
        "        n_trials=25,\n",
        "        callbacks=[wandbc],\n",
        "    )\n",
        "    studies.append(study)\n",
        "\n",
        "    # fit classifier using best parameter combination\n",
        "    trial = study.best_trial\n",
        "    static_params = {\"od_type\": \"Iter\", \"task_type\": \"GPU\", \"cat_features\": cat_columns}\n",
        "    params = {**static_params, **trial.params}\n",
        "    print(params)\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(X_train, y_train, plot=True, verbose=False)\n",
        "\n",
        "    # plot accuracy for train, val and test\n",
        "    acc_train = model.score(X_train, y_train)\n",
        "    acc_val = model.score(X_val, y_val)\n",
        "    acc_test = model.score(X_test, y_test)\n",
        "\n",
        "    print(f\"Accuracy (train): {acc_train}, (val) {acc_val}, and (test) {acc_test}\")\n",
        "\n",
        "    run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujM_aozLILeQ",
        "outputId": "cfde78b6-8c2f-42e3-fbdd-97d85d8a5f60"
      },
      "outputs": [],
      "source": [
        "for study in tqdm(studies):\n",
        "    ax_history = optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "    ax_param_importance = optuna.visualization.matplotlib.plot_param_importances(study)\n",
        "    fig_contour = optuna.visualization.matplotlib.plot_contour(\n",
        "        study, [\"iterations\", \"depth\", \"grow_policy\", \"learning_rate\"]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3vzAVSc_DfD"
      },
      "source": [
        "### Robustness BaselineðŸ¥Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3evMG-KVA2eX"
      },
      "outputs": [],
      "source": [
        "# Copy unscaled columns\n",
        "X_print = test.copy()\n",
        "# X_print = pd.concat([train, val, test])\n",
        "\n",
        "# add baseline results\n",
        "X_print[\"rule\"] = \"Baseline\"\n",
        "X_print[\"buy_sell_predicted\"] = 0  # model.predict(X_test)\n",
        "\n",
        "# prepare columns for printing\n",
        "X_print[\"ttm\"] = (\n",
        "    X_print[\"EXPIRATION\"].dt.to_period(\"M\")\n",
        "    - X_print[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
        ").apply(lambda x: x.n)\n",
        "X_print[\"year\"] = X_print[\"QUOTE_DATETIME\"].dt.year\n",
        "\n",
        "bins_tradesize = [0, 1, 3, 5, 11, np.inf]\n",
        "trade_size_labels = [\"(0,1]\", \"(1,3]\", \"(3,5]\", \"(5,11]\", \">11\"]\n",
        "X_print[\"TRADE_SIZE_binned\"] = pd.cut(\n",
        "    X_print[\"TRADE_SIZE\"], bins_tradesize, labels=trade_size_labels\n",
        ")\n",
        "\n",
        "bins_years = [2005, 2007, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
        "year_labels = [\n",
        "    \"2005-2007\",\n",
        "    \"2008-2010\",\n",
        "    \"2011\",\n",
        "    \"2012\",\n",
        "    \"2013\",\n",
        "    \"2014\",\n",
        "    \"2015\",\n",
        "    \"2016\",\n",
        "    \"2017\",\n",
        "]\n",
        "X_print[\"year_binned\"] = pd.cut(X_print[\"year\"], bins_years, labels=year_labels)\n",
        "\n",
        "bins_ttm = [0, 1, 2, 3, 6, 12, np.inf]\n",
        "ttm_labels = [\n",
        "    \"ttm <= 1 month\",\n",
        "    \"ttm (1-2] month\",\n",
        "    \"ttm (2-3] month\",\n",
        "    \"ttm (3-6] month\",\n",
        "    \"ttm (6-12] month\",\n",
        "    \"ttm > 12 month\",\n",
        "]\n",
        "X_print[\"ttm_binned\"] = pd.cut(X_print[\"ttm\"], bins_ttm, labels=ttm_labels)\n",
        "\n",
        "# TODO: Security type\n",
        "# TODO: Moneyness\n",
        "# TODO: time from previous trade; same underlying or any?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clDZ4Z95_0jj"
      },
      "outputs": [],
      "source": [
        "def check_robustness(criterion: str = \"year_binned\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Check robustness of rules by calculating the accuracy for a given\n",
        "    criterion and rules.\n",
        "\n",
        "    Example:\n",
        "    rule\t\tBaseline\n",
        "    TRADE_SIZE_binned\n",
        "    (0,1]\t  0.710966\n",
        "    (1,3]\t  0.717664\n",
        "    (3,5]\t  0.715195\n",
        "    (5,11]\t0.699428\n",
        "    >11\t  \t0.688348\n",
        "\n",
        "    Args:\n",
        "        criterion (str, optional): criterion to check robustness for.\n",
        "        Defaults to \"year_binned\".\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with accuracy of rules. Rule in columns and\n",
        "        criterion values in rows.\n",
        "    \"\"\"\n",
        "\n",
        "    # fill others with\n",
        "    # X_print[\"buy_sell_predicted\"] = X_print[\"buy_sell_predicted\"].map(\n",
        "    #     lambda l: l if not np.isnan(l) else 0\n",
        "    # )\n",
        "\n",
        "    # fill others randomly\n",
        "    X_print[\"buy_sell_predicted\"] = X_print[\"buy_sell_predicted\"].map(\n",
        "        lambda l: l if not np.isnan(l) else np.random.choice([-1, 1])\n",
        "    )\n",
        "\n",
        "    # cuculate average over columns if multiple subsets are combined\n",
        "    results = (\n",
        "        X_print.groupby([\"rule\", criterion])[[\"buy_sell\", \"buy_sell_predicted\"]]\n",
        "        .apply(lambda x: accuracy_score(x[\"buy_sell\"], x[\"buy_sell_predicted\"]))\n",
        "        .unstack(level=0)\n",
        "        .assign(avg=lambda x: x.mean(axis=1))\n",
        "    )\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KRw_J0IJiFU",
        "outputId": "073e5fba-bf29-4eb7-c4ac-18bc2a027967"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCey7G_tE6zt",
        "outputId": "7880ba07-7573-4b84-f389-1ddc056d8ab0"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"OPTION_TYPE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpg1yY2MEGFa",
        "outputId": "358e3f60-1f32-463e-c6b2-f416391cf4df"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"TRADE_SIZE_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8624JR8wEN4D",
        "outputId": "d3bfb646-877e-4665-8309-25b1d0feb485"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"ttm_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P3UVsQb2T_V"
      },
      "source": [
        "## Classical rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXOz7eU-T0dj"
      },
      "outputs": [],
      "source": [
        "# tick rule\n",
        "# FIXME: Discuss with Grauer et al what is used in table 9 ISE at '=='? How is their accuracy defined?\n",
        "\n",
        "subset = \"all\"\n",
        "\n",
        "# print(X_print[f\"price_{subset}_lag\"].isna().sum())\n",
        "# X_print[f\"price_{subset}_lag\"].fillna(0, inplace=True)\n",
        "filter = X_print[f\"price_{subset}_lag\"].isna()\n",
        "\n",
        "tt = np.where(X_print[\"TRADE_PRICE\"] > X_print[f\"price_{subset}_lag\"], 1, -1)\n",
        "X_print[\"buy_sell_predicted\"] = tt\n",
        "# X_print[\"buy_sell_predicted\"][filter] = np.nan\n",
        "\n",
        "X_print[\"rule\"] = f\"tick rule ({subset})\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WalF1CT1RpmB",
        "outputId": "40a19227-88fe-46e6-fb22-6cada46a7758"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xixmnFFwNfo"
      },
      "outputs": [],
      "source": [
        "# TODO: Reported accuracy is slightly different from table 9 on page 36. Difference has\n",
        "# very likely to do with how missing trade prices (here \"price_all_lag\") are handled.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpZTx7tzSxmY"
      },
      "outputs": [],
      "source": [
        "# reverse tick rule\n",
        "X_print[\"buy_sell_predicted\"] = np.where(\n",
        "    X_print[\"TRADE_PRICE\"] > X_print[\"price_ex_lead\"],\n",
        "    1,\n",
        "    np.where(X_print[\"price_ex_lead\"] > X_print[\"TRADE_PRICE\"], -1, np.NaN),\n",
        ")\n",
        "X_print[\"rule\"] = \"reverse tick rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "QjxlCgTkVAb8",
        "outputId": "44060d9d-5e10-4674-da03-e08a9ccce5b6"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh4sHlOjxFHs",
        "outputId": "b78e7363-a4ba-44de-a8bd-31ddca3f54c1"
      },
      "outputs": [],
      "source": [
        "X_print.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTr6C0gPEAlh"
      },
      "outputs": [],
      "source": [
        "# quote rule\n",
        "# TODO: Variants QR (NBBO), QUOTE_RULE (ISE) etc.\n",
        "\n",
        "mid = 0.5 * (X_print[\"ask_ex\"] + X_print[\"bid_ex\"])\n",
        "qr = np.where(\n",
        "    X_print[\"TRADE_PRICE\"] > mid, 1, np.where(X_print[\"TRADE_PRICE\"] < mid, -1, np.nan)\n",
        ")\n",
        "X_print[\"buy_sell_predicted\"] = qr\n",
        "\n",
        "X_print[\"rule\"] = \"quote rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "S3tVWvFtV66V",
        "outputId": "40c09092-0080-4928-df8f-722eb784ef72"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKFUz1AHxFHQ"
      },
      "outputs": [],
      "source": [
        "# trade size rule\n",
        "\n",
        "subset = \"all\"\n",
        "\n",
        "bid_eq_ask = X_print[f\"ask_size_{subset}\"] == X_print[f\"bid_size_{subset}\"]\n",
        "\n",
        "# \"matches either\"\n",
        "ts_eq_bid = (X_print[\"TRADE_SIZE\"] == X_print[f\"bid_size_{subset}\"]) & -bid_eq_ask\n",
        "ts_eq_ask = (X_print[\"TRADE_SIZE\"] == X_print[f\"ask_size_{subset}\"]) & -bid_eq_ask\n",
        "\n",
        "# trad size + tick rule\n",
        "X_print[\"buy_sell_predicted\"] = np.where(ts_eq_bid, 1.0, np.where(ts_eq_ask, -1.0, tt))\n",
        "\n",
        "\n",
        "X_print[\"rule\"] = \"trade size + tick rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "5WMY1YC5XnO9",
        "outputId": "f55506c6-5543-49f7-fd9b-3531e8e30f25"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkGlIJxVXlFM"
      },
      "outputs": [],
      "source": [
        "X_print[\"buy_sell_predicted\"] = np.where(ts_eq_bid, 1, np.where(ts_eq_ask, -1, qr))\n",
        "\n",
        "X_print[\"rule\"] = \"trade size + quote rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ad4VLhDVZGmy",
        "outputId": "fd52a999-b5f3-4081-8001-bb3444ae2a4a"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym31mXboWRUL"
      },
      "outputs": [],
      "source": [
        "# depth rule p. 14\n",
        "dr = np.where(\n",
        "    X_print[\"ask_size_ex\"] > X_print[\"bid_size_ex\"],\n",
        "    1,\n",
        "    np.where(X_print[\"ask_size_ex\"] < X_print[\"bid_size_ex\"], -1, np.nan),\n",
        ")\n",
        "\n",
        "X_print[\"buy_sell_predicted\"] = dr\n",
        "X_print[\"rule\"] = \"depth rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "vQEGKJStb9SA",
        "outputId": "04088138-551a-4d66-bd66-abd346d5aa90"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZToz_urayRD"
      },
      "outputs": [],
      "source": [
        "# TODO: Depth rule + reverse LR (NBBO), Depth rule + reverse LR (NBBO, ISE), ...\n",
        "\n",
        "X_print[\"buy_sell_predicted\"] = np.where(ts_eq_bid, 1.0, np.where(ts_eq_ask, -1.0, dr))\n",
        "\n",
        "X_print[\"rule\"] = \"trade size + depth rule\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "xUL24ZqCb-da",
        "outputId": "c3575159-9430-4fc6-f8c4-f820c6cee58e"
      },
      "outputs": [],
      "source": [
        "check_robustness(\"year_binned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vzzLA34Z4Bu"
      },
      "source": [
        "## Classical Rules Sklearn Implementation ðŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV4JDAz_RpmG"
      },
      "outputs": [],
      "source": [
        "%%script false --no-raise-error\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.base import MultiOutputMixin\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.utils.validation import _num_samples\n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "from sklearn.utils.validation import check_is_fitted, _check_sample_weight\n",
        "from sklearn.utils.random import _random_choice_csc\n",
        "from sklearn.utils.multiclass import class_distribution\n",
        "\n",
        "\n",
        "class TRClassifier(MultiOutputMixin, ClassifierMixin, BaseEstimator):\n",
        "\n",
        "    def __init__(self, *, strategy=\"standard\", random_state=None, constant=None):\n",
        "        self.strategy = strategy\n",
        "        self.random_state = random_state\n",
        "        self.constant = constant\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        \"\"\"Fit the baseline classifier.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data.\n",
        "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
        "            Target values.\n",
        "        sample_weight : array-like of shape (n_samples,), default=None\n",
        "            Sample weights.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns the instance itself.\n",
        "        \"\"\"\n",
        "        allowed_strategies = (\"standard\", \"tradesize\")\n",
        "\n",
        "        if self.strategy not in allowed_strategies:\n",
        "            raise ValueError(\n",
        "                \"Unknown strategy type: %s, expected one of %s.\"\n",
        "                % (self.strategy, allowed_strategies)\n",
        "            )\n",
        "\n",
        "        self._strategy = self.strategy\n",
        "\n",
        "        if self._strategy == \"uniform\" and sp.issparse(y):\n",
        "            y = y.toarray()\n",
        "            warnings.warn(\n",
        "                \"A local copy of the target data has been converted \"\n",
        "                \"to a numpy array. Predicting on sparse target data \"\n",
        "                \"with the uniform strategy would not save memory \"\n",
        "                \"and would be slower.\",\n",
        "                UserWarning,\n",
        "            )\n",
        "\n",
        "        self.sparse_output_ = sp.issparse(y)\n",
        "\n",
        "        if not self.sparse_output_:\n",
        "            y = np.asarray(y)\n",
        "            y = np.atleast_1d(y)\n",
        "\n",
        "        if y.ndim == 1:\n",
        "            y = np.reshape(y, (-1, 1))\n",
        "\n",
        "        self.n_outputs_ = y.shape[1]\n",
        "\n",
        "        check_consistent_length(X, y)\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = _check_sample_weight(sample_weight, X)\n",
        "\n",
        "        if self._strategy == \"constant\":\n",
        "            if self.constant is None:\n",
        "                raise ValueError(\n",
        "                    \"Constant target value has to be specified \"\n",
        "                    \"when the constant strategy is used.\"\n",
        "                )\n",
        "            else:\n",
        "                constant = np.reshape(np.atleast_1d(self.constant), (-1, 1))\n",
        "                if constant.shape[0] != self.n_outputs_:\n",
        "                    raise ValueError(\n",
        "                        \"Constant target value should have shape (%d, 1).\"\n",
        "                        % self.n_outputs_\n",
        "                    )\n",
        "\n",
        "        (self.classes_, self.n_classes_, self.class_prior_) = class_distribution(\n",
        "            y, sample_weight\n",
        "        )\n",
        "\n",
        "        if self._strategy == \"constant\":\n",
        "            for k in range(self.n_outputs_):\n",
        "                if not any(constant[k][0] == c for c in self.classes_[k]):\n",
        "                    # Checking in case of constant strategy if the constant\n",
        "                    # provided by the user is in y.\n",
        "                    err_msg = (\n",
        "                        \"The constant target value must be present in \"\n",
        "                        \"the training data. You provided constant={}. \"\n",
        "                        \"Possible values are: {}.\".format(\n",
        "                            self.constant, list(self.classes_[k])\n",
        "                        )\n",
        "                    )\n",
        "                    raise ValueError(err_msg)\n",
        "\n",
        "        if self.n_outputs_ == 1:\n",
        "            self.n_classes_ = self.n_classes_[0]\n",
        "            self.classes_ = self.classes_[0]\n",
        "            self.class_prior_ = self.class_prior_[0]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Perform classification on test vectors X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Test data.\n",
        "        Returns\n",
        "        -------\n",
        "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
        "            Predicted target values for X.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        # numpy random_state expects Python int and not long as size argument\n",
        "        # under Windows\n",
        "        n_samples = _num_samples(X)\n",
        "        rs = check_random_state(self.random_state)\n",
        "\n",
        "        n_classes_ = self.n_classes_\n",
        "        classes_ = self.classes_\n",
        "        class_prior_ = self.class_prior_\n",
        "        constant = self.constant\n",
        "        if self.n_outputs_ == 1:\n",
        "            # Get same type even for self.n_outputs_ == 1\n",
        "            n_classes_ = [n_classes_]\n",
        "            classes_ = [classes_]\n",
        "            class_prior_ = [class_prior_]\n",
        "            constant = [constant]\n",
        "        # Compute probability only once\n",
        "        if self._strategy == \"stratified\":\n",
        "            proba = self.predict_proba(X)\n",
        "            if self.n_outputs_ == 1:\n",
        "                proba = [proba]\n",
        "\n",
        "        if self.sparse_output_:\n",
        "            class_prob = None\n",
        "            if self._strategy in (\"most_frequent\", \"prior\"):\n",
        "                classes_ = [np.array([cp.argmax()]) for cp in class_prior_]\n",
        "\n",
        "            elif self._strategy == \"stratified\":\n",
        "                class_prob = class_prior_\n",
        "\n",
        "            elif self._strategy == \"uniform\":\n",
        "                raise ValueError(\n",
        "                    \"Sparse target prediction is not \"\n",
        "                    \"supported with the uniform strategy\"\n",
        "                )\n",
        "\n",
        "            elif self._strategy == \"constant\":\n",
        "                classes_ = [np.array([c]) for c in constant]\n",
        "\n",
        "            y = _random_choice_csc(n_samples, classes_, class_prob, self.random_state)\n",
        "        else:\n",
        "            if self._strategy in (\"most_frequent\", \"prior\"):\n",
        "                y = np.tile(\n",
        "                    [\n",
        "                        classes_[k][class_prior_[k].argmax()]\n",
        "                        for k in range(self.n_outputs_)\n",
        "                    ],\n",
        "                    [n_samples, 1],\n",
        "                )\n",
        "\n",
        "            elif self._strategy == \"stratified\":\n",
        "                y = np.vstack(\n",
        "                    [\n",
        "                        classes_[k][proba[k].argmax(axis=1)]\n",
        "                        for k in range(self.n_outputs_)\n",
        "                    ]\n",
        "                ).T\n",
        "\n",
        "            elif self._strategy == \"uniform\":\n",
        "                ret = [\n",
        "                    classes_[k][rs.randint(n_classes_[k], size=n_samples)]\n",
        "                    for k in range(self.n_outputs_)\n",
        "                ]\n",
        "                y = np.vstack(ret).T\n",
        "\n",
        "            elif self._strategy == \"constant\":\n",
        "                y = np.tile(self.constant, (n_samples, 1))\n",
        "\n",
        "            if self.n_outputs_ == 1:\n",
        "                y = np.ravel(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pass\n",
        "\n",
        "    def predict_log_proba(self, X):\n",
        "        pass\n",
        "\n",
        "    def _more_tags(self):\n",
        "        return {\n",
        "            \"poor_score\": True,\n",
        "            \"no_validation\": True,\n",
        "            \"_xfail_checks\": {\n",
        "                \"check_methods_subset_invariance\": \"fails for the predict method\",\n",
        "                \"check_methods_sample_order_invariance\": \"fails for the predict method\",\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        \"\"\"Return the mean accuracy on the given test data and labels.\n",
        "        In multi-label classification, this is the subset accuracy\n",
        "        which is a harsh metric since you require for each sample that\n",
        "        each label set be correctly predicted.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : None or array-like of shape (n_samples, n_features)\n",
        "            Test samples. Passing None as test samples gives the same result\n",
        "            as passing real test samples, since DummyClassifier\n",
        "            operates independently of the sampled observations.\n",
        "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
        "            True labels for X.\n",
        "        sample_weight : array-like of shape (n_samples,), default=None\n",
        "            Sample weights.\n",
        "        Returns\n",
        "        -------\n",
        "        score : float\n",
        "            Mean accuracy of self.predict(X) wrt. y.\n",
        "        \"\"\"\n",
        "        if X is None:\n",
        "            X = np.zeros(shape=(len(y), 1))\n",
        "        return super().score(X, y, sample_weight)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
