{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqA-31WTmVb2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_c4GpJmndXz"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pgf.texsystem\": \"xelatex\",\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"font.serif\": [],\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.sans-serif\": [],\n",
    "    \"axes.labelsize\": 11,\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "CM = 1 / 2.54\n",
    "# cmap = plt.cm.get_cmap(\"viridis\")\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"Blues\")\n",
    "# plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "# Bright color scheme\n",
    "# color-blind safe\n",
    "# from Paul Tot's website: https://personal.sron.nl/~pault/\n",
    "# Set color cycle\n",
    "# mpl.rcParams['axes.prop_cycle'] = mpl.cycler('color', ['4477AA', 'EE6677', '228833', 'CCBB44', '66CCEE', 'AA3377', 'BBBBBB'])\n",
    "\n",
    "\n",
    "# Standard SciencePlots color cycle\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(\n",
    "    \"color\", [\"0C5DA5\", \"00B945\", \"FF9500\", \"FF2C00\", \"845B97\", \"474747\", \"9e9e9e\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_csv(\"../data/results/learning_curves_gbm_default_params.csv\")\n",
    "# train_sizes = results_df.start.abs().unique()\n",
    "# train_acc_uni = results_df[results_df.strategy == \"uniform\"].train_acc\n",
    "# val_acc_uni = results_df[results_df.strategy == \"uniform\"].val_acc\n",
    "\n",
    "# train_acc_exp = results_df[results_df.strategy == \"exponential\"].train_acc\n",
    "# val_acc_exp = results_df[results_df.strategy == \"exponential\"].val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fig, axs = plt.subplot_mosaic(\"AB;CD\", figsize=(10,10))\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(12*CM, 6*CM), sharey=True, sharex=True, constrained_layout=True)\n",
    "\n",
    "# ax1.plot(train_sizes, train_acc_uni, \".-\", label=\"Train\", color=\"C1\")\n",
    "# ax1.plot(train_sizes, val_acc_uni, \".-\", label=\"Val\", color=\"C0\")\n",
    "\n",
    "\n",
    "# ax2.plot(train_sizes, train_acc_exp, \".-\", label=\"Train\", color=\"C1\")\n",
    "# ax2.plot(train_sizes, val_acc_exp, \".-\", label=\"Val\", color=\"C0\")\n",
    "\n",
    "# # if not ax:\n",
    "# #     ax=plt.gca()\n",
    "\n",
    "# # ax.fill_between(\n",
    "# #         train_sizes,\n",
    "# #         train_acc + 0.02, # .mean(axis=1) - fit_times.std(axis=1),\n",
    "# #         train_acc - 0.02, # fit_times.mean(axis=1) + fit_times.std(axis=1),\n",
    "# #         alpha=0.3,\n",
    "# #         color=\"C3\",\n",
    "# # )\n",
    "\n",
    "# # ax.fill_between(\n",
    "# #         train_sizes,\n",
    "# #         val_acc + 0.02, # .mean(axis=1) - fit_times.std(axis=1),\n",
    "# #         val_acc - 0.02, # fit_times.mean(axis=1) + fit_times.std(axis=1),\n",
    "# #         alpha=0.3,\n",
    "# # )\n",
    "\n",
    "# # max\n",
    "# xmax = train_sizes[np.argmax(val_acc_uni)]\n",
    "# ymax = val_acc_uni.max()\n",
    "# ax1.plot(xmax, ymax, \".\", color=\"C3\")\n",
    "# ax1.text(xmax, ymax + 0.02, f\"{ymax * 100 :.2f}\\%\",         horizontalalignment='center')\n",
    "# #ax1.axvline(x=xmax, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# xmax = train_sizes[np.argmax(val_acc_exp)]\n",
    "# ymax = val_acc_exp.max()\n",
    "# ax2.plot(xmax, ymax, \".\", color=\"C3\")\n",
    "# ax2.text(xmax, ymax + 0.02, f\"{ymax * 100 :.2f}\\%\",         horizontalalignment='center')\n",
    "# #ax2.axvline(x=xmax, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# ax2.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
    "# ax2.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "# # title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'\n",
    "# # plt.title(title, fontsize = 18, y = 1.03)\n",
    "# ax1.legend(loc=\"lower right\", frameon=False)\n",
    "# ax2.legend(loc=\"lower right\", frameon=False)\n",
    "# plt.ylim(0.6, 1)\n",
    "# # plt.show()\n",
    "\n",
    "# ax1.set_title('(a) Uniform Weights')\n",
    "# ax2.set_title('(b) Exponential Weights')\n",
    "# # plt.tight_layout()\n",
    "# # plt.ylabel(\"Accuracy\")  # , fontsize = \"small\")\n",
    "# # plt.xlabel(\"Number of Training Samples\")  # , fontsize = \"small\")\n",
    "\n",
    "# fig.supylabel('Accuracy')\n",
    "# fig.supxlabel('Number of Training Samples')\n",
    "\n",
    "# plt.savefig(\n",
    "#     f\"../reports/Graphs/learning-curves-gradient-boosting.pdf\",\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_adv_val = pd.read_csv(\"../data/results/feature_importance_gbm_classical_size.csv\")\n",
    "# # feature_importance_adv_val.set_index(\"Feature Id\", drop=True, inplace=True)\n",
    "# # feature_importance_adv_val.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_adv_val[\"Feature Id\"] = feature_importance_adv_val[\"Feature Id\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature_importance_adv_val.plot.bar(figsize=(12 * CM, 6 * CM))\n",
    "# ax = feature_importance_adv_val.plot.bar(x='Feature Id', y='Importances', figsize=(12 * CM, 6 * CM))\n",
    "# ax.set_ylabel(\"Feature Importance in \\%\")\n",
    "# ax.set_xlabel(\"Feature\")\n",
    "# # ax.set_major_formatter(ticker.PercentFormatter(xmax=100, decimals=0))\n",
    "# plt.legend(frameon=False)\n",
    "# plt.savefig(\n",
    "#     f\"../reports/Graphs/adv-val-gradient-boosting.pdf\",\n",
    "#     bbox_inches=\"tight\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mpl(start: str, end: str):\n",
    "    mpl_start = mdates.date2num(pd.to_datetime(start))\n",
    "    mpl_end = mdates.date2num(pd.to_datetime(end))\n",
    "    return mpl_start, mpl_end - mpl_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pos(span: tuple):\n",
    "    return span[0] + 0.5 * span[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(\n",
    "    2, 1, sharey=\"none\", sharex=\"col\", figsize=(12 * CM, 6 * CM)\n",
    ")\n",
    "\n",
    "# ise\n",
    "ax.broken_barh([to_mpl(\"2005-05-02\", \"2017-05-31\")], (1, 5), facecolors=\"#D6DCE5\")\n",
    "\n",
    "# ise pretraining\n",
    "span = [to_mpl(\"2012-10-23\", \"2013-10-24\")]\n",
    "ax.broken_barh(span, (2.5, 1), facecolors=\"C0\", edgecolor=\"black\", linewidth=0.8)\n",
    "\n",
    "ax.text(\n",
    "    x=to_pos(span[0]),\n",
    "    y=3,\n",
    "    s=\"train\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    color=\"black\",\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "spans = [\n",
    "    to_mpl(\"2005-05-02\", \"2013-10-24\"),\n",
    "    to_mpl(\"2013-10-25\", \"2015-11-05\"),\n",
    "    to_mpl(\"2015-11-06\", \"2017-05-31\"),\n",
    "]\n",
    "\n",
    "# ise supervised\n",
    "ax.broken_barh(\n",
    "    spans,\n",
    "    (1.2, 1),\n",
    "    facecolors=(\"C0\", \"C1\", \"C3\"),\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "\n",
    "# add text labels manually\n",
    "labels = [\"train\", \"val\", \"test\"]\n",
    "for i, s in enumerate(spans):\n",
    "    ax.text(\n",
    "        x=to_pos(s),\n",
    "        y=1.7,\n",
    "        s=labels[i],\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"black\",\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "\n",
    "ax.xaxis_date()\n",
    "plt.setp(ax.get_xticklabels(), visible=True)\n",
    "\n",
    "# cboe\n",
    "bx.broken_barh([to_mpl(\"2011-01-01\", \"2017-10-31\")], (1, 2.5), facecolors=\"#D6DCE5\")\n",
    "\n",
    "spans = [\n",
    "    to_mpl(\"2015-11-06\", \"2017-10-31\"),\n",
    "]\n",
    "\n",
    "# cboe supervised\n",
    "bx.broken_barh(\n",
    "    spans,\n",
    "    (1.85, 1),\n",
    "    facecolors=(\"C3\"),\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "\n",
    "# add text labels manually\n",
    "labels = [\"test\"]\n",
    "for i, s in enumerate(spans):\n",
    "    bx.text(\n",
    "        x=to_pos(s),\n",
    "        y=2.35,\n",
    "        s=labels[i],\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"black\",\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Modify y-axis tick labels\n",
    "ax.set_yticks([1.7, 3], labels=[\"ISE Supervised\", \"ISE Pretraining\"])\n",
    "bx.set_yticks([2.35], labels=[\"CBOE Transfer\"])\n",
    "\n",
    "ax.set_ylim(1, 3.7)\n",
    "bx.set_ylim(1, 3.7)\n",
    "\n",
    "# into to date\n",
    "bx.xaxis_date()\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\"../reports/Graphs/train-test-split.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.rcParams[\"axes.linewidth\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://d2l.ai/d2l-en.pdf\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap=cmap):\n",
    "    num_rows, num_cols, _, _ = matrices.shape\n",
    "    fig, axes = plt.subplots(\n",
    "        num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False\n",
    "    )\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            ax.set_facecolor(\"gainsboro\")\n",
    "            # m = np.tril(matrix.detach().numpy())\n",
    "            m = matrix.detach().numpy()\n",
    "            m[np.tril_indices(m.shape[0], -1)] = np.nan\n",
    "            pcm = ax.imshow(m, cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes)\n",
    "    plt.savefig(\"../reports/Graphs/attention-maps.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_weights = torch.eye(10).reshape((1, 1, 10, 10))\n",
    "attention_weights = torch.rand(size=(2, 4, 10, 10))\n",
    "show_heatmaps(\n",
    "    attention_weights, xlabel=\"Keys\", ylabel=\"Queries\", figsize=(12 * CM, 6 * CM)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LeO039jmYXY"
   },
   "outputs": [],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/text/transformer\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return pos_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "jXDCDLyhmhJ2",
    "outputId": "aef336ef-da01-4833-e5eb-856af7afca1b"
   },
   "outputs": [],
   "source": [
    "tokens = 64\n",
    "dimensions = 96\n",
    "\n",
    "\n",
    "pos_encoding = positional_encoding(tokens, dimensions)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.figure(figsize=(12 * CM, 6 * CM))\n",
    "plt.pcolormesh(pos_encoding[0], cmap=cmap)\n",
    "plt.xlabel(\"Embedding dimension $d_e$\")\n",
    "plt.xlim((0, dimensions))\n",
    "plt.ylim((tokens, 0))\n",
    "plt.ylabel(\"token position $t$\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"../reports/Graphs/positional-encoding.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set study globally here\n",
    "study = \"fbv/thesis/17malsep.optuna:v49\"\n",
    "model = \"17malsep_CatBoostClassifier_default.cbm:v7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "study_name, version = study.split(\":\")\n",
    "\n",
    "model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "study_id = model_name.split(\"_\")[0]\n",
    "\n",
    "artifact = run.use_artifact(study)\n",
    "study_dir = artifact.download()\n",
    "\n",
    "artifact = run.use_artifact(model)\n",
    "model_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = open(f\"./artifacts/{study_id}.optuna:{version}/{study_id}.optuna\",'rb')\n",
    "study = pickle.load(file)\n",
    "\n",
    "#optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "param_importances = optuna.visualization.matplotlib.plot_param_importances(study);\n",
    "slices = optuna.visualization.matplotlib.plot_slice(study);\n",
    "contours = optuna.visualization.matplotlib.plot_contour(\n",
    "     study, [\"learning_rate\", \"depth\", \"bagging_temperature\", \"l2_leaf_reg\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = param_importances\n",
    "\n",
    "# https://stackoverflow.com/a/46906599/5755604\n",
    "ax.remove()\n",
    "fig2 = plt.figure()\n",
    "ax.figure=fig2\n",
    "fig2.axes.append(ax)\n",
    "fig2.add_axes(ax)\n",
    "\n",
    "plt.title(\"My Title\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/46906599/5755604\n",
    "ax = slices\n",
    "\n",
    "fig2 = plt.figure(figsize=(16,9))\n",
    "\n",
    "for i, a in enumerate(ax.flat, start=1):\n",
    "    a.remove()\n",
    "    a.figure = fig2\n",
    "    fig2.axes.append(a)\n",
    "    fig2.add_axes(a)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert axis array to figure\n",
    "\n",
    "# https://stackoverflow.com/a/46906599/5755604\n",
    "ax = contours\n",
    "\n",
    "fig2 = plt.figure(figsize=(16,9))\n",
    "\n",
    "for i, a in enumerate(ax.flat, start=1):\n",
    "    a.remove()\n",
    "    a.figure = fig2\n",
    "    # a.set_cmap(cmap)\n",
    "    fig2.axes.append(a)\n",
    "    fig2.add_axes(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test relabelling\n",
    "for a in fig2.axes:\n",
    "    if a.get_xlabel() == \"learning_rate\":\n",
    "        a.set_xlabel(\"$\\lambda$\")\n",
    "    if a.get_ylabel() == \"learning_rate\":\n",
    "        a.set_ylabel(\"$\\lambda$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize learning curves\n",
    "with open(Path(model_dir,model_name[:-4]+\"_training.json\"), 'r') as j:\n",
    "     contents = json.loads(j.read())\n",
    "    \n",
    "# extract relevant keys\n",
    "iterations = contents.get(\"iterations\")\n",
    "test_metrics = [d['name'] for d in contents['meta']['test_metrics'] ]\n",
    "test_results = [d['test'] for d in iterations]\n",
    "learn_metrics = [d['name'] for d in contents['meta']['learn_metrics'] ]\n",
    "learn_results = [d['learn'] for d in iterations]\n",
    "\n",
    "metrics_learn = pd.DataFrame(learn_results, columns=learn_metrics).add_prefix(\"learn_\")\n",
    "metrics_test = pd.DataFrame(test_results, columns=test_metrics).add_prefix(\"test_\")\n",
    "\n",
    "learning_metrics = pd.concat([metrics_learn, metrics_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_metrics.plot(kind=\"line\", figsize=(6*CM,8*CM), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzakCmj4ncGOCn8/01TeqE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
