{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqA-31WTmVb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_c4GpJmndXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pgf.texsystem\": \"xelatex\",\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"font.serif\": [],\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.sans-serif\": [],\n",
    "    \"axes.labelsize\": 11,\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "CM = 1 / 2.54\n",
    "# cmap = plt.cm.get_cmap(\"viridis\")\n",
    "cmap = mpl.colormaps.get_cmap(\"plasma\")\n",
    "# plt.style.use(['science','nature'])\n",
    "\n",
    "# Bright color scheme\n",
    "# color-blind safe\n",
    "# from Paul Tot's website: https://personal.sron.nl/~pault/\n",
    "# Set color cycle\n",
    "# mpl.rcParams['axes.prop_cycle'] = mpl.cycler('color', ['4477AA', 'EE6677', '228833', 'CCBB44', '66CCEE', 'AA3377', 'BBBBBB'])\n",
    "\n",
    "\n",
    "# Standard SciencePlots color cycle\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(\n",
    "    \"color\", [\"0C5DA5\", \"00B945\", \"FF9500\", \"FF2C00\", \"845B97\", \"474747\", \"9e9e9e\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_csv(\"../data/results/learning_curves_gbm_default_params.csv\")\n",
    "# train_sizes = results_df.start.abs().unique()\n",
    "# train_acc_uni = results_df[results_df.strategy == \"uniform\"].train_acc\n",
    "# val_acc_uni = results_df[results_df.strategy == \"uniform\"].val_acc\n",
    "\n",
    "# train_acc_exp = results_df[results_df.strategy == \"exponential\"].train_acc\n",
    "# val_acc_exp = results_df[results_df.strategy == \"exponential\"].val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fig, axs = plt.subplot_mosaic(\"AB;CD\", figsize=(10,10))\n",
    "\n",
    "# fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(12*CM, 6*CM), sharey=True, sharex=True, constrained_layout=True)\n",
    "\n",
    "# ax1.plot(train_sizes, train_acc_uni, \".-\", label=\"Train\", color=\"C1\")\n",
    "# ax1.plot(train_sizes, val_acc_uni, \".-\", label=\"Val\", color=\"C0\")\n",
    "\n",
    "\n",
    "# ax2.plot(train_sizes, train_acc_exp, \".-\", label=\"Train\", color=\"C1\")\n",
    "# ax2.plot(train_sizes, val_acc_exp, \".-\", label=\"Val\", color=\"C0\")\n",
    "\n",
    "# # if not ax:\n",
    "# #     ax=plt.gca()\n",
    "\n",
    "# # ax.fill_between(\n",
    "# #         train_sizes,\n",
    "# #         train_acc + 0.02, # .mean(axis=1) - fit_times.std(axis=1),\n",
    "# #         train_acc - 0.02, # fit_times.mean(axis=1) + fit_times.std(axis=1),\n",
    "# #         alpha=0.3,\n",
    "# #         color=\"C3\",\n",
    "# # )\n",
    "\n",
    "# # ax.fill_between(\n",
    "# #         train_sizes,\n",
    "# #         val_acc + 0.02, # .mean(axis=1) - fit_times.std(axis=1),\n",
    "# #         val_acc - 0.02, # fit_times.mean(axis=1) + fit_times.std(axis=1),\n",
    "# #         alpha=0.3,\n",
    "# # )\n",
    "\n",
    "# # max\n",
    "# xmax = train_sizes[np.argmax(val_acc_uni)]\n",
    "# ymax = val_acc_uni.max()\n",
    "# ax1.plot(xmax, ymax, \".\", color=\"C3\")\n",
    "# ax1.text(xmax, ymax + 0.02, f\"{ymax * 100 :.2f}\\%\",         horizontalalignment='center')\n",
    "# #ax1.axvline(x=xmax, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# xmax = train_sizes[np.argmax(val_acc_exp)]\n",
    "# ymax = val_acc_exp.max()\n",
    "# ax2.plot(xmax, ymax, \".\", color=\"C3\")\n",
    "# ax2.text(xmax, ymax + 0.02, f\"{ymax * 100 :.2f}\\%\",         horizontalalignment='center')\n",
    "# #ax2.axvline(x=xmax, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# ax2.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
    "# ax2.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "# # title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'\n",
    "# # plt.title(title, fontsize = 18, y = 1.03)\n",
    "# ax1.legend(loc=\"lower right\", frameon=False)\n",
    "# ax2.legend(loc=\"lower right\", frameon=False)\n",
    "# plt.ylim(0.6, 1)\n",
    "# # plt.show()\n",
    "\n",
    "# ax1.set_title('(a) Uniform Weights')\n",
    "# ax2.set_title('(b) Exponential Weights')\n",
    "# # plt.tight_layout()\n",
    "# # plt.ylabel(\"Accuracy\")  # , fontsize = \"small\")\n",
    "# # plt.xlabel(\"Number of Training Samples\")  # , fontsize = \"small\")\n",
    "\n",
    "# fig.supylabel('Accuracy')\n",
    "# fig.supxlabel('Number of Training Samples')\n",
    "\n",
    "# plt.savefig(\n",
    "#     f\"../reports/Graphs/learning-curves-gradient-boosting.pdf\",\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_adv_val = pd.read_csv(\"../data/results/feature_importance_gbm_classical_size.csv\")\n",
    "# # feature_importance_adv_val.set_index(\"Feature Id\", drop=True, inplace=True)\n",
    "# # feature_importance_adv_val.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_adv_val[\"Feature Id\"] = feature_importance_adv_val[\"Feature Id\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature_importance_adv_val.plot.bar(figsize=(12 * CM, 6 * CM))\n",
    "# ax = feature_importance_adv_val.plot.bar(x='Feature Id', y='Importances', figsize=(12 * CM, 6 * CM))\n",
    "# ax.set_ylabel(\"Feature Importance in \\%\")\n",
    "# ax.set_xlabel(\"Feature\")\n",
    "# # ax.set_major_formatter(ticker.PercentFormatter(xmax=100, decimals=0))\n",
    "# plt.legend(frameon=False)\n",
    "# plt.savefig(\n",
    "#     f\"../reports/Graphs/adv-val-gradient-boosting.pdf\",\n",
    "#     bbox_inches=\"tight\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mpl(start: str, end: str):\n",
    "    mpl_start = mdates.date2num(pd.to_datetime(start))\n",
    "    mpl_end = mdates.date2num(pd.to_datetime(end))\n",
    "    return mpl_start, mpl_end - mpl_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pos(span: tuple):\n",
    "    return span[0] + 0.5 * span[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(\n",
    "    2, 1, sharey=\"none\", sharex=\"col\", figsize=(12 * CM, 6 * CM)\n",
    ")\n",
    "\n",
    "# ise\n",
    "ax.broken_barh([to_mpl(\"2005-05-02\", \"2017-05-31\")], (1, 5), facecolors=\"#D6DCE5\")\n",
    "\n",
    "# ise pretraining\n",
    "span = [to_mpl(\"2012-10-23\", \"2013-10-24\")]\n",
    "ax.broken_barh(span, (2.5, 1), facecolors=\"C0\", edgecolor=\"black\", linewidth=0.8)\n",
    "\n",
    "ax.text(\n",
    "    x=to_pos(span[0]),\n",
    "    y=3,\n",
    "    s=\"train\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    color=\"black\",\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "spans = [\n",
    "    to_mpl(\"2005-05-02\", \"2013-10-24\"),\n",
    "    to_mpl(\"2013-10-25\", \"2015-11-05\"),\n",
    "    to_mpl(\"2015-11-06\", \"2017-05-31\"),\n",
    "]\n",
    "\n",
    "# ise supervised\n",
    "ax.broken_barh(\n",
    "    spans,\n",
    "    (1.2, 1),\n",
    "    facecolors=(\"C0\", \"C1\", \"C3\"),\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "\n",
    "# add text labels manually\n",
    "labels = [\"train\", \"val\", \"test\"]\n",
    "for i, s in enumerate(spans):\n",
    "    ax.text(\n",
    "        x=to_pos(s),\n",
    "        y=1.7,\n",
    "        s=labels[i],\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"black\",\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "\n",
    "ax.xaxis_date()\n",
    "plt.setp(ax.get_xticklabels(), visible=True)\n",
    "\n",
    "# cboe\n",
    "bx.broken_barh([to_mpl(\"2011-01-01\", \"2017-10-31\")], (1, 2.5), facecolors=\"#D6DCE5\")\n",
    "\n",
    "spans = [\n",
    "    to_mpl(\"2015-11-06\", \"2017-10-31\"),\n",
    "]\n",
    "\n",
    "# cboe supervised\n",
    "bx.broken_barh(\n",
    "    spans,\n",
    "    (1.85, 1),\n",
    "    facecolors=(\"C3\"),\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "\n",
    "# add text labels manually\n",
    "labels = [\"test\"]\n",
    "for i, s in enumerate(spans):\n",
    "    bx.text(\n",
    "        x=to_pos(s),\n",
    "        y=2.35,\n",
    "        s=labels[i],\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"black\",\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Modify y-axis tick labels\n",
    "ax.set_yticks([1.7, 3], labels=[\"ISE Supervised\", \"ISE Pretraining\"])\n",
    "bx.set_yticks([2.35], labels=[\"CBOE Transfer\"])\n",
    "\n",
    "ax.set_ylim(1, 3.7)\n",
    "bx.set_ylim(1, 3.7)\n",
    "\n",
    "# into to date\n",
    "bx.xaxis_date()\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\"../reports/Graphs/train-test-split.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.rcParams[\"axes.linewidth\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://d2l.ai/d2l-en.pdf\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap=cmap):\n",
    "    num_rows, num_cols, _, _ = matrices.shape\n",
    "    fig, axes = plt.subplots(\n",
    "        num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False\n",
    "    )\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes)\n",
    "    plt.savefig(\"../reports/Graphs/attention-maps.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_weights = torch.eye(10).reshape((1, 1, 10, 10))\n",
    "attention_weights = torch.rand(size=(2, 4, 10, 10))\n",
    "show_heatmaps(\n",
    "    attention_weights, xlabel=\"Keys\", ylabel=\"Queries\", figsize=(12 * CM, 6 * CM)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LeO039jmYXY"
   },
   "outputs": [],
   "source": [
    "# Code from https://www.tensorflow.org/tutorials/text/transformer\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return pos_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "jXDCDLyhmhJ2",
    "outputId": "aef336ef-da01-4833-e5eb-856af7afca1b"
   },
   "outputs": [],
   "source": [
    "tokens = 64\n",
    "dimensions = 96\n",
    "\n",
    "\n",
    "pos_encoding = positional_encoding(tokens, dimensions)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.figure(figsize=(12 * CM, 6 * CM))\n",
    "plt.pcolormesh(pos_encoding[0], cmap=cmap)\n",
    "plt.xlabel(\"Embedding dimension $d_e$\")\n",
    "plt.xlim((0, dimensions))\n",
    "plt.ylim((tokens, 0))\n",
    "plt.ylabel(\"token position $t$\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"../reports/Graphs/positional-encoding.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set study globally here\n",
    "study = \"2qzvvdbw.optuna:v49\"\n",
    "# study = \"30sl6vqf.optuna:v49\"\n",
    "# study = \"2w28suql.optuna:v49\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "# study_id = model_name.split(\"_\")[0]\n",
    "\n",
    "study_id = study.split(\".\")[0]\n",
    "\n",
    "\n",
    "artifact = run.use_artifact(study)\n",
    "study_dir = artifact.download()\n",
    "\n",
    "# artifact = run.use_artifact(model)\n",
    "# model_dir = artifact.download()\n",
    "\n",
    "study_name, version = study.split(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file  = open(f\"./artifacts/{study_id}.optuna:{version}/{study_id}.optuna\",'rb')\n",
    "study = pickle.load(file)\n",
    "\n",
    "sampler = study.sampler\n",
    "storage = f\"sqlite:///../{study_id}.db\"\n",
    "\n",
    "study = optuna.load_study(study_name=study_id, storage=storage,sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LUT_LABELS = {\"Objective Value\": \"Accuracy\", \"bagging_temperature\": \"Bagging Temp.\", \"depth\":\"Depth\", \"l2_leaf_reg\": \"$\\ell_2$ Leaf Reg.\" , \"learning_rate\" : \"$\\lambda$\", \"random_strength\": \"Rand. Str.\", \"\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Sequence\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from optuna._experimental import experimental_func\n",
    "from optuna._imports import try_import\n",
    "from optuna.logging import get_logger\n",
    "from optuna.study import Study\n",
    "from optuna.trial import FrozenTrial\n",
    "from optuna.visualization._contour import _AxisInfo\n",
    "from optuna.visualization._contour import _ContourInfo\n",
    "from optuna.visualization._contour import _get_contour_info\n",
    "from optuna.visualization._contour import _SubContourInfo\n",
    "from optuna.visualization.matplotlib._matplotlib_imports import _imports\n",
    "\n",
    "\n",
    "with try_import() as _optuna_imports:\n",
    "    import scipy\n",
    "\n",
    "if _imports.is_successful():\n",
    "    from optuna.visualization.matplotlib._matplotlib_imports import Axes\n",
    "    from optuna.visualization.matplotlib._matplotlib_imports import Colormap\n",
    "    from optuna.visualization.matplotlib._matplotlib_imports import ContourSet\n",
    "    from optuna.visualization.matplotlib._matplotlib_imports import plt\n",
    "\n",
    "_logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "CONTOUR_POINT_NUM = 100\n",
    "\n",
    "\n",
    "def plot_contour(\n",
    "    study: Study,\n",
    "    params: Optional[List[str]] = None,\n",
    "    *,\n",
    "    target: Optional[Callable[[FrozenTrial], float]] = None,\n",
    "    target_name: str = \"Objective Value\",\n",
    ") -> \"Axes\":\n",
    "    \"\"\"Plot the parameter relationship as contour plot in a study with Matplotlib.\n",
    "\n",
    "    Note that, if a parameter contains missing values, a trial with missing values is not plotted.\n",
    "\n",
    "    .. seealso::\n",
    "        Please refer to :func:`optuna.visualization.plot_contour` for an example.\n",
    "\n",
    "    Warnings:\n",
    "        Output figures of this Matplotlib-based\n",
    "        :func:`~optuna.visualization.matplotlib.plot_contour` function would be different from\n",
    "        those of the Plotly-based :func:`~optuna.visualization.plot_contour`.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        The following code snippet shows how to plot the parameter relationship as contour plot.\n",
    "\n",
    "        .. plot::\n",
    "\n",
    "            import optuna\n",
    "\n",
    "\n",
    "            def objective(trial):\n",
    "                x = trial.suggest_float(\"x\", -100, 100)\n",
    "                y = trial.suggest_categorical(\"y\", [-1, 0, 1])\n",
    "                return x ** 2 + y\n",
    "\n",
    "\n",
    "            sampler = optuna.samplers.TPESampler(seed=10)\n",
    "            study = optuna.create_study(sampler=sampler)\n",
    "            study.optimize(objective, n_trials=30)\n",
    "\n",
    "            optuna.visualization.matplotlib.plot_contour(study, params=[\"x\", \"y\"])\n",
    "\n",
    "    Args:\n",
    "        study:\n",
    "            A :class:`~optuna.study.Study` object whose trials are plotted for their target values.\n",
    "        params:\n",
    "            Parameter list to visualize. The default is all parameters.\n",
    "        target:\n",
    "            A function to specify the value to display. If it is :obj:`None` and ``study`` is being\n",
    "            used for single-objective optimization, the objective values are plotted.\n",
    "\n",
    "            .. note::\n",
    "                Specify this argument if ``study`` is being used for multi-objective optimization.\n",
    "        target_name:\n",
    "            Target's name to display on the color bar.\n",
    "\n",
    "    Returns:\n",
    "        A :class:`matplotlib.axes.Axes` object.\n",
    "\n",
    "    .. note::\n",
    "        The colormap is reversed when the ``target`` argument isn't :obj:`None` or ``direction``\n",
    "        of :class:`~optuna.study.Study` is ``minimize``.\n",
    "    \"\"\"\n",
    "\n",
    "    _imports.check()\n",
    "    info = _get_contour_info(study, params, target, target_name)\n",
    "    return _get_contour_plot(info)\n",
    "\n",
    "\n",
    "\n",
    "def _get_contour_plot(info: _ContourInfo) -> \"Axes\":\n",
    "\n",
    "    sorted_params = info.sorted_params\n",
    "    sub_plot_infos = info.sub_plot_infos\n",
    "    reverse_scale = info.reverse_scale\n",
    "    target_name = info.target_name\n",
    "\n",
    "    if len(sorted_params) <= 1:\n",
    "        _, ax = plt.subplots()\n",
    "        return ax\n",
    "    n_params = len(sorted_params)\n",
    "\n",
    "    if n_params == 2:\n",
    "        # Set up the graph style.\n",
    "        fig, axs = plt.subplots()\n",
    "        cmap = _set_cmap(reverse_scale)\n",
    "\n",
    "        cs = _generate_contour_subplot(sub_plot_infos[0][0], axs, cmap)\n",
    "        if isinstance(cs, ContourSet):\n",
    "            axcb = fig.colorbar(cs)\n",
    "            axcb.set_label(\"Accuracy\")\n",
    "    else:\n",
    "        # Set up the graph style.\n",
    "        fig, axs = plt.subplots(n_params, n_params, figsize=(15 *CM, 15 *CM))\n",
    "        cmap = _set_cmap(reverse_scale)\n",
    "\n",
    "        # Prepare data and draw contour plots.\n",
    "        cs_list = []\n",
    "        for x_i in range(len(sorted_params)):\n",
    "            for y_i in range(len(sorted_params)):\n",
    "                ax = axs[y_i, x_i]\n",
    "                cs = _generate_contour_subplot(sub_plot_infos[y_i][x_i], ax, cmap)\n",
    "                if isinstance(cs, ContourSet):\n",
    "                    cs_list.append(cs)\n",
    "        if cs_list:\n",
    "            axcb = fig.colorbar(cs_list[0], ax=axs, aspect=50)\n",
    "            axcb.set_label(\"Accuracy\")\n",
    "\n",
    "    return axs\n",
    "\n",
    "\n",
    "def _set_cmap(reverse_scale: bool) -> \"Colormap\":\n",
    "    cmap = \"viridis_r\" if not reverse_scale else \"virids\"\n",
    "    return plt.get_cmap(cmap)\n",
    "\n",
    "\n",
    "class _LabelEncoder:\n",
    "    def __init__(self) -> None:\n",
    "        self.labels: List[str] = []\n",
    "\n",
    "    def fit(self, labels: List[str]) -> \"_LabelEncoder\":\n",
    "        self.labels = sorted(set(labels))\n",
    "        return self\n",
    "\n",
    "    def transform(self, labels: List[str]) -> List[int]:\n",
    "        return [self.labels.index(label) for label in labels]\n",
    "\n",
    "    def fit_transform(self, labels: List[str]) -> List[int]:\n",
    "        return self.fit(labels).transform(labels)\n",
    "\n",
    "    def get_labels(self) -> List[str]:\n",
    "        return self.labels\n",
    "\n",
    "    def get_indices(self) -> List[int]:\n",
    "        return list(range(len(self.labels)))\n",
    "\n",
    "\n",
    "def _calculate_griddata(\n",
    "    xaxis: _AxisInfo,\n",
    "    yaxis: _AxisInfo,\n",
    "    z_values_dict: Dict[Tuple[int, int], float],\n",
    ") -> Tuple[\n",
    "    np.ndarray,\n",
    "    np.ndarray,\n",
    "    np.ndarray,\n",
    "    List[int],\n",
    "    List[str],\n",
    "    List[int],\n",
    "    List[str],\n",
    "    List[Union[int, float]],\n",
    "    List[Union[int, float]],\n",
    "]:\n",
    "\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    z_values = []\n",
    "    for x_value, y_value in zip(xaxis.values, yaxis.values):\n",
    "        if x_value is not None and y_value is not None:\n",
    "            x_values.append(x_value)\n",
    "            y_values.append(y_value)\n",
    "            x_i = xaxis.indices.index(x_value)\n",
    "            y_i = yaxis.indices.index(y_value)\n",
    "            z_values.append(z_values_dict[(x_i, y_i)])\n",
    "\n",
    "    # Return empty values when x or y has no value.\n",
    "    if len(x_values) == 0 or len(y_values) == 0:\n",
    "        return np.array([]), np.array([]), np.array([]), [], [], [], [], [], []\n",
    "\n",
    "    def _calculate_axis_data(\n",
    "        axis: _AxisInfo,\n",
    "        values: Sequence[Union[str, float]],\n",
    "    ) -> Tuple[np.ndarray, List[str], List[int], List[Union[int, float]]]:\n",
    "\n",
    "        # Convert categorical values to int.\n",
    "        cat_param_labels = []  # type: List[str]\n",
    "        cat_param_pos = []  # type: List[int]\n",
    "        returned_values: Sequence[Union[int, float]]\n",
    "        if axis.is_cat:\n",
    "            enc = _LabelEncoder()\n",
    "            returned_values = enc.fit_transform(list(map(str, values)))\n",
    "            cat_param_labels = enc.get_labels()\n",
    "            cat_param_pos = enc.get_indices()\n",
    "        else:\n",
    "            returned_values = list(map(lambda x: float(x), values))\n",
    "\n",
    "        # For x and y, create 1-D array of evenly spaced coordinates on linear or log scale.\n",
    "        if axis.is_log:\n",
    "            ci = np.logspace(np.log10(axis.range[0]), np.log10(axis.range[1]), CONTOUR_POINT_NUM)\n",
    "        else:\n",
    "            ci = np.linspace(axis.range[0], axis.range[1], CONTOUR_POINT_NUM)\n",
    "\n",
    "        return ci, cat_param_labels, cat_param_pos, list(returned_values)\n",
    "\n",
    "    xi, cat_param_labels_x, cat_param_pos_x, transformed_x_values = _calculate_axis_data(\n",
    "        xaxis,\n",
    "        x_values,\n",
    "    )\n",
    "    yi, cat_param_labels_y, cat_param_pos_y, transformed_y_values = _calculate_axis_data(\n",
    "        yaxis,\n",
    "        y_values,\n",
    "    )\n",
    "\n",
    "    # Calculate grid data points.\n",
    "    zi: np.ndarray = np.array([])\n",
    "    # Create irregularly spaced map of trial values\n",
    "    # and interpolate it with Plotly's interpolation formulation.\n",
    "    if xaxis.name != yaxis.name:\n",
    "        zmap = _create_zmap(transformed_x_values, transformed_y_values, z_values, xi, yi)\n",
    "        zi = _interpolate_zmap(zmap, CONTOUR_POINT_NUM)\n",
    "\n",
    "    return (\n",
    "        xi,\n",
    "        yi,\n",
    "        zi,\n",
    "        cat_param_pos_x,\n",
    "        cat_param_labels_x,\n",
    "        cat_param_pos_y,\n",
    "        cat_param_labels_y,\n",
    "        transformed_x_values,\n",
    "        transformed_y_values,\n",
    "    )\n",
    "\n",
    "\n",
    "def _generate_contour_subplot(info: _SubContourInfo, ax: \"Axes\", cmap: \"Colormap\") -> \"ContourSet\":\n",
    "\n",
    "    if len(info.xaxis.indices) < 2 or len(info.yaxis.indices) < 2:\n",
    "        ax.label_outer()\n",
    "        return ax\n",
    "\n",
    "    # replace with lut values\n",
    "    ax.set(xlabel=LUT_LABELS[info.xaxis.name], ylabel=LUT_LABELS[info.yaxis.name])\n",
    "    ax.set_xlim(info.xaxis.range[0], info.xaxis.range[1])\n",
    "    ax.set_ylim(info.yaxis.range[0], info.yaxis.range[1])\n",
    "\n",
    "    if info.xaxis.name == info.yaxis.name:\n",
    "        ax.label_outer()\n",
    "        return ax\n",
    "\n",
    "    (\n",
    "        xi,\n",
    "        yi,\n",
    "        zi,\n",
    "        x_cat_param_pos,\n",
    "        x_cat_param_label,\n",
    "        y_cat_param_pos,\n",
    "        y_cat_param_label,\n",
    "        x_values,\n",
    "        y_values,\n",
    "    ) = _calculate_griddata(info.xaxis, info.yaxis, info.z_values)\n",
    "    cs = None\n",
    "    if len(zi) > 0:\n",
    "        if info.xaxis.is_log:\n",
    "            ax.set_xscale(\"log\")\n",
    "        if info.yaxis.is_log:\n",
    "            ax.set_yscale(\"log\")\n",
    "        if info.xaxis.name != info.yaxis.name:\n",
    "            # Contour the gridded data.\n",
    "            ax.contour(xi, yi, zi, 15, linewidths=0.5, colors=\"k\")\n",
    "            cs = ax.contourf(xi, yi, zi, 15, cmap=cmap.reversed())\n",
    "            # Plot data points.\n",
    "            ax.scatter(\n",
    "                x_values,\n",
    "                y_values,\n",
    "                marker=\"o\",\n",
    "                c=\"black\",\n",
    "                s=20,\n",
    "                edgecolors=\"grey\",\n",
    "                linewidth=2.0,\n",
    "            )\n",
    "    if info.xaxis.is_cat:\n",
    "        ax.set_xticks(x_cat_param_pos)\n",
    "        ax.set_xticklabels(x_cat_param_label)\n",
    "    if info.yaxis.is_cat:\n",
    "        ax.set_yticks(y_cat_param_pos)\n",
    "        ax.set_yticklabels(y_cat_param_label)\n",
    "    ax.label_outer()\n",
    "    return cs\n",
    "\n",
    "\n",
    "def _create_zmap(\n",
    "    x_values: List[Union[int, float]],\n",
    "    y_values: List[Union[int, float]],\n",
    "    z_values: List[float],\n",
    "    xi: np.ndarray,\n",
    "    yi: np.ndarray,\n",
    ") -> Dict[Tuple[int, int], float]:\n",
    "\n",
    "    # Creates z-map from trial values and params.\n",
    "    # z-map is represented by hashmap of coordinate and trial value pairs.\n",
    "    #\n",
    "    # Coordinates are represented by tuple of integers, where the first item\n",
    "    # indicates x-axis index and the second item indicates y-axis index\n",
    "    # and refer to a position of trial value on irregular param grid.\n",
    "    #\n",
    "    # Since params were resampled either with linspace or logspace\n",
    "    # original params might not be on the x and y axes anymore\n",
    "    # so we are going with close approximations of trial value positions.\n",
    "    zmap = dict()\n",
    "    for x, y, z in zip(x_values, y_values, z_values):\n",
    "        xindex = int(np.argmin(np.abs(xi - x)))\n",
    "        yindex = int(np.argmin(np.abs(yi - y)))\n",
    "        zmap[(xindex, yindex)] = z\n",
    "\n",
    "    return zmap\n",
    "\n",
    "\n",
    "def _interpolate_zmap(zmap: Dict[Tuple[int, int], float], contour_plot_num: int) -> np.ndarray:\n",
    "\n",
    "    # Implements interpolation formulation used in Plotly\n",
    "    # to interpolate heatmaps and contour plots\n",
    "    # https://github.com/plotly/plotly.js/blob/95b3bd1bb19d8dc226627442f8f66bce9576def8/src/traces/heatmap/interp2d.js#L15-L20\n",
    "    # citing their doc:\n",
    "    #\n",
    "    # > Fill in missing data from a 2D array using an iterative\n",
    "    # > poisson equation solver with zero-derivative BC at edges.\n",
    "    # > Amazingly, this just amounts to repeatedly averaging all the existing\n",
    "    # > nearest neighbors\n",
    "    #\n",
    "    # Plotly's algorithm is equivalent to solve the following linear simultaneous equation.\n",
    "    # It is discretization form of the Poisson equation.\n",
    "    #\n",
    "    #     z[x, y] = zmap[(x, y)]                                  (if zmap[(x, y)] is given)\n",
    "    # 4 * z[x, y] = z[x-1, y] + z[x+1, y] + z[x, y-1] + z[x, y+1] (if zmap[(x, y)] is not given)\n",
    "\n",
    "    a_data = []\n",
    "    a_row = []\n",
    "    a_col = []\n",
    "    b = np.zeros(contour_plot_num**2)\n",
    "    for x in range(contour_plot_num):\n",
    "        for y in range(contour_plot_num):\n",
    "            grid_index = y * contour_plot_num + x\n",
    "            if (x, y) in zmap:\n",
    "                a_data.append(1)\n",
    "                a_row.append(grid_index)\n",
    "                a_col.append(grid_index)\n",
    "                b[grid_index] = zmap[(x, y)]\n",
    "            else:\n",
    "                for dx, dy in ((-1, 0), (1, 0), (0, -1), (0, 1)):\n",
    "                    if 0 <= x + dx < contour_plot_num and 0 <= y + dy < contour_plot_num:\n",
    "                        a_data.append(1)\n",
    "                        a_row.append(grid_index)\n",
    "                        a_col.append(grid_index)\n",
    "                        a_data.append(-1)\n",
    "                        a_row.append(grid_index)\n",
    "                        a_col.append(grid_index + dy * contour_plot_num + dx)\n",
    "\n",
    "    z = scipy.sparse.linalg.spsolve(scipy.sparse.csc_matrix((a_data, (a_row, a_col))), b)\n",
    "\n",
    "    return z.reshape((contour_plot_num, contour_plot_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axes = plot_contour(study)\n",
    "plt.savefig(f\"../reports/Graphs/{study_id}-hyperparam-search-space.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize learning curves\n",
    "with open(Path(model_dir,model_name[:-4]+\"_training.json\"), 'r') as j:\n",
    "     contents = json.loads(j.read())\n",
    "    \n",
    "# extract relevant keys\n",
    "iterations = contents.get(\"iterations\")\n",
    "test_metrics = [d['name'] for d in contents['meta']['test_metrics'] ]\n",
    "test_results = [d['test'] for d in iterations]\n",
    "learn_metrics = [d['name'] for d in contents['meta']['learn_metrics'] ]\n",
    "learn_results = [d['learn'] for d in iterations]\n",
    "\n",
    "metrics_learn = pd.DataFrame(learn_results, columns=learn_metrics).add_prefix(\"learn_\")\n",
    "metrics_test = pd.DataFrame(test_results, columns=test_metrics).add_prefix(\"test_\")\n",
    "\n",
    "learning_metrics = pd.concat([metrics_learn, metrics_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_metrics.plot(kind=\"line\", figsize=(6*CM,8*CM), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# model = \"xl3n4thc_CatBoostClassifier_default.cbm:v9\"\n",
    "# model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "# artifact = run.use_artifact(model)\n",
    "# model_dir = artifact.download()\n",
    "\n",
    "# clf = CatBoostClassifier()\n",
    "# clf.load_model(fname=Path(model_dir, model_name))\n",
    "\n",
    "# RocCurveDisplay.from_estimator(\n",
    "# clf, X_test, y_test, response_method=\"predict_proba\")\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"random\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# PrecisionRecallDisplay.from_estimator(clf, X_test, y_test, pos_label=clf.classes_[1])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "# for name in tqdm(names):\n",
    "#     RocCurveDisplay.from_predictions(\n",
    "#         results[name],\n",
    "#         y_test,\n",
    "#         pos_label=1,\n",
    "#         name=name,\n",
    "#         linewidth=1,\n",
    "#         ax=ax,\n",
    "#     )\n",
    "# plt.plot([0, 1], [0, 1], \"k--\", label=\"random\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzakCmj4ncGOCn8/01TeqE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
