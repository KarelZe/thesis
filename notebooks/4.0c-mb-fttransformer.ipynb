{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b853e9-a97e-4a0b-b1af-1bd0ede09c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9361c4b-0819-45a0-b9a4-5089914cd280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "# fs = gcsfs.GCSFileSystem(project=\"thesis\")\n",
    "# fs_prefix = \"gs://\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a63a56-6aff-4459-9765-1242403443b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3elp0v65) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1816bea7921f4a859798ad99c80a9589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-hill-1225</strong>: <a href=\"https://wandb.ai/fbv/thesis/runs/3elp0v65\" target=\"_blank\">https://wandb.ai/fbv/thesis/runs/3elp0v65</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230407_100620-3elp0v65/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3elp0v65). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec52c04e3784d8fa5472493e1d94a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669532866217196, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/pfs/data5/home/kit/stud/uloak/thesis/notebooks/wandb/run-20230407_100841-1m52rz3l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fbv/thesis/runs/1m52rz3l\" target=\"_blank\">valiant-river-1226</a></strong> to <a href=\"https://wandb.ai/fbv/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact ise_supervised_log_standardized:latest, 5414.39MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.0\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "dataset = \"fbv/thesis/ise_supervised_log_standardized:latest\"\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf7b797-6256-45c0-9bec-d4faf98d9daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from otc.models.fttransformer import FeatureTokenizer, FTTransformer, Transformer\n",
    "from otc.models.activation import ReGLU\n",
    "from otc.data.dataset import TabDataset\n",
    "from otc.data.dataloader import TabDataLoader\n",
    "from otc.features.build_features import features_classical, features_classical_size\n",
    "from otc.optim.early_stopping import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd424255-737f-4590-93ee-e9e6dcfc3258",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2106.11959.pdf\n",
    "\n",
    "Layer count 3\n",
    "Feature embedding size 192\n",
    "Head count 8\n",
    "Activation & FFN size factor (ReGLU,\n",
    "4/3)\n",
    "Attention dropout 0.2\n",
    "FFN dropout 0.1\n",
    "Residual dropout 0.0\n",
    "Initialization Kaiming (He et al., 2015a)\n",
    "Parameter count 929K The value is given for 100 numerical features\n",
    "Optimizer AdamW\n",
    "Learning rate 1e−4\n",
    "Weight decay 1e−5 0.0 for Feature Tokenizer, LayerNorm and biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bf75ce-b0b4-4198-9be7-f0da4e699f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\").sample(frac=0.1)\n",
    "y_train = X_train[\"buy_sell\"]\n",
    "X_train = X_train[features_classical_size]\n",
    "\n",
    "X_val = pd.read_parquet(Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\").sample(frac=0.1)\n",
    "y_val = X_val[\"buy_sell\"]\n",
    "X_val = X_val[features_classical_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61405d57-ae2c-49af-9dce-396f15314e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_parquet(Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\")\n",
    "y_test = X_test[\"buy_sell\"]\n",
    "X_test = X_test[features_classical_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f7d45b-7390-4b6f-8a3b-e6bef4e9deba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRADE_PRICE              0\n",
       "bid_ex                   0\n",
       "ask_ex                   0\n",
       "BEST_ASK                 0\n",
       "BEST_BID                 0\n",
       "price_ex_lag             0\n",
       "price_ex_lead            0\n",
       "price_all_lag            0\n",
       "price_all_lead           0\n",
       "chg_ex_lead              0\n",
       "chg_ex_lag               0\n",
       "chg_all_lead             0\n",
       "chg_all_lag              0\n",
       "prox_ex                  0\n",
       "prox_best                0\n",
       "bid_ask_size_ratio_ex    0\n",
       "rel_bid_size_ex          0\n",
       "rel_ask_size_ex          0\n",
       "TRADE_SIZE               0\n",
       "bid_size_ex              0\n",
       "ask_size_ex              0\n",
       "depth_ex                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8878c6-6340-40ad-819f-f4ec3b8d575b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = TabDataset(X_train, y_train)\n",
    "val_data = TabDataset(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdf1535c-438d-4db7-aee6-b0f1bbf39d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_token = 192\n",
    "n_blocks = 3\n",
    "attention_dropout = 0.2\n",
    "ffn_dropout = 0.1\n",
    "residual_dropout = 0.0\n",
    "attention_heads = 8\n",
    "epochs = 100\n",
    "device = \"cuda\"\n",
    "batch_size = 16192\n",
    "\n",
    "feature_tokenizer_kwargs = {\n",
    "    \"num_continous\": len(X_train.columns.tolist()),\n",
    "    \"cat_cardinalities\": (),\n",
    "    \"d_token\": d_token,\n",
    "}\n",
    "\n",
    "dl_params = {\n",
    "    \"batch_size\": batch_size,  # dataprallel splits batches across devices\n",
    "    \"shuffle\": False,\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "transformer_kwargs = {\n",
    "    \"d_token\": d_token,\n",
    "    \"n_blocks\": n_blocks,\n",
    "    \"attention_n_heads\": attention_heads,\n",
    "    \"attention_initialization\": \"kaiming\",\n",
    "    \"ffn_activation\": ReGLU,\n",
    "    \"attention_normalization\": nn.LayerNorm,\n",
    "    \"ffn_normalization\": nn.LayerNorm,\n",
    "    \"ffn_dropout\": ffn_dropout,\n",
    "    # fix at 4/3, as activation (see search space B in\n",
    "    # https://arxiv.org/pdf/2106.11959v2.pdf)\n",
    "    # is static with ReGLU / GeGLU\n",
    "    \"ffn_d_hidden\": int(d_token * (4 / 3)),\n",
    "    \"attention_dropout\": attention_dropout,\n",
    "    \"residual_dropout\": residual_dropout,  # see search space (B)\n",
    "    \"prenormalization\": True,\n",
    "    \"first_prenormalization\": False,\n",
    "    \"last_layer_query_idx\": None,\n",
    "    \"n_tokens\": None,\n",
    "    \"kv_compression_ratio\": None,\n",
    "    \"kv_compression_sharing\": None,\n",
    "    \"head_activation\": nn.ReLU,\n",
    "    \"head_normalization\": nn.LayerNorm,\n",
    "    \"d_out\": 1,  # fix at 1, due to binary classification\n",
    "}\n",
    "\n",
    "\n",
    "# module_params = {\n",
    "#             \"transformer\": Transformer(**transformer_kwargs),  # type: ignore\n",
    "#             \"feature_tokenizer\": FeatureTokenizer(**feature_tokenizer_kwargs),  # type: ignore # noqa: E501\n",
    "#             \"cat_features\": self._cat_features,\n",
    "#             \"cat_cardinalities\": self._cat_cardinalities,\n",
    "#         }\n",
    "\n",
    "optim_params = {\"lr\": 5e-5, \"weight_decay\": 0.00001}\n",
    "\n",
    "module_params = {\n",
    "    \"transformer\": Transformer(**transformer_kwargs),  # type: ignore\n",
    "    \"feature_tokenizer\": FeatureTokenizer(**feature_tokenizer_kwargs),  # type: ignore # noqa: E501\n",
    "    \"cat_features\": None,\n",
    "    \"cat_cardinalities\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4338aad0-df27-45df-ac41-f605ed3722db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = TabDataLoader(\n",
    "    training_data.x_cat,\n",
    "    training_data.x_cont,\n",
    "    training_data.weight,\n",
    "    training_data.y,\n",
    "    **dl_params\n",
    ")\n",
    "val_loader = TabDataLoader(\n",
    "    val_data.x_cat, val_data.x_cont, val_data.weight, val_data.y, **dl_params\n",
    ")\n",
    "test_data = TabDataset(X_test, y_test)\n",
    "test_loader = TabDataLoader(\n",
    "    test_data.x_cat, test_data.x_cont, test_data.weight, test_data.y, **dl_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a57c959b-29fa-4329-a1d5-c05bea812dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b6f2e15d1403fa89ee8d710090cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-07 11:16:59,082] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:16:59,422] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:16:59,976] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:00,664] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:01,212] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:01,539] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:43,745] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:44,081] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:44,625] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:44,949] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:45,494] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-07 11:17:45,818] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.4409811198711395 val:0.6001198887825012 val acc: 0.7144993058274892\n",
      "train:0.37286242842674255 val:0.5875769853591919 val acc: 0.7195848187268927\n",
      "train:0.36443108320236206 val:0.5836888551712036 val acc: 0.7211918408031042\n",
      "train:0.3600050210952759 val:0.5829820036888123 val acc: 0.7224113467963812\n",
      "train:0.35720086097717285 val:0.579143226146698 val acc: 0.7232189262448064\n",
      "train:0.3551231622695923 val:0.5790125131607056 val acc: 0.7239105559991252\n",
      "train:0.353357195854187 val:0.5725494027137756 val acc: 0.725388406047692\n",
      "train:0.3518710732460022 val:0.5734875798225403 val acc: 0.7253365338161181\n",
      "train:0.35023051500320435 val:0.5710821151733398 val acc: 0.7267655629408504\n",
      "train:0.34882816672325134 val:0.5692160129547119 val acc: 0.7269323677639509\n",
      "train:0.3477879762649536 val:0.568117618560791 val acc: 0.7275934844408732\n",
      "train:0.34680628776550293 val:0.566942572593689 val acc: 0.7278162299058671\n",
      "train:0.34602391719818115 val:0.5670880079269409 val acc: 0.7279911715496067\n",
      "train:0.3452456295490265 val:0.564714789390564 val acc: 0.7288801192044224\n",
      "train:0.34451794624328613 val:0.5632196068763733 val acc: 0.7289452137695347\n",
      "train:0.34378182888031006 val:0.5621238946914673 val acc: 0.7293134049034515\n",
      "train:0.3429834544658661 val:0.5624843835830688 val acc: 0.7294730900084928\n",
      "train:0.342145174741745 val:0.5603495836257935 val acc: 0.7304108585871428\n",
      "train:0.3410651385784149 val:0.5609021782875061 val acc: 0.7305664752818646\n",
      "train:0.34009867906570435 val:0.5616738796234131 val acc: 0.7304495084851783\n",
      "train:0.33927208185195923 val:0.560463011264801 val acc: 0.7311604631885149\n",
      "train:0.3387241065502167 val:0.5593297481536865 val acc: 0.7311563947781954\n",
      "train:0.33813148736953735 val:0.5583232045173645 val acc: 0.7318683665841118\n",
      "train:0.3377399742603302 val:0.5579739809036255 val acc: 0.73171376699197\n",
      "train:0.3372005224227905 val:0.556902289390564 val acc: 0.7326098343648448\n",
      "train:0.3366737961769104 val:0.556508481502533 val acc: 0.7326332277241822\n",
      "train:0.3361535370349884 val:0.5559837818145752 val acc: 0.7326983222892944\n",
      "train:0.335822194814682 val:0.5548740029335022 val acc: 0.7327603655466672\n",
      "train:0.3353917896747589 val:0.5560459494590759 val acc: 0.7329292045749274\n",
      "train:0.3349195420742035 val:0.5552142858505249 val acc: 0.7329464953187854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(train_loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     54\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiled_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     57\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/pfs/data5/home/kit/stud/uloak/thesis/torchtwo/lib64/python3.9/site-packages/torch/nn/utils/clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[0;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = FTTransformer(**module_params)\n",
    "\n",
    "# use multiple gpus, if available\n",
    "clf = nn.DataParallel(clf).to(device)\n",
    "\n",
    "# half precision, see https://pytorch.org/docs/stable/amp.html\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# Generate the optimizers\n",
    "optimizer = optim.AdamW(\n",
    "    clf.parameters(),\n",
    "    lr=optim_params[\"lr\"],\n",
    "    weight_decay=optim_params[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "compiled_clf = torch.compile(clf)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=15)\n",
    "\n",
    "# see https://stackoverflow.com/a/53628783/5755604\n",
    "# no sigmoid required; numerically more stable\n",
    "# do not reduce, calculate mean after multiplication with weight\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # perform training\n",
    "    loss_in_epoch_train = 0\n",
    "\n",
    "    compiled_clf.train()\n",
    "\n",
    "    for x_cat, x_cont, weights, targets in train_loader:\n",
    "\n",
    "        # print(x_cat)\n",
    "        # print(x_cont)\n",
    "        # print(weights)\n",
    "        # reset the gradients back to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output and train loss\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = compiled_clf(x_cat, x_cont).flatten()\n",
    "            # print(logits)\n",
    "            train_loss = criterion(logits, targets)\n",
    "            # print(intermediate_loss)\n",
    "            # weight train loss with (decaying) weights\n",
    "            # train_loss = torch.mean(weights * intermediate_loss)\n",
    "            # compute accumulated gradients\n",
    "            \n",
    "            # https://pytorch.org/docs/stable/amp.html\n",
    "            # https://discuss.huggingface.co/t/why-is-grad-norm-clipping-done-during-training-by-default/1866\n",
    "            scaler.scale(train_loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(compiled_clf.parameters(), 5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # scaler.unscale_(optimizer)\n",
    "            # nn.utils.clip_grad_norm_(compiled.parameters(), 5)\n",
    "            # scaler.scale(train_loss).backward()\n",
    "\n",
    "#             # perform parameter update based on current gradients\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss_in_epoch_train += train_loss  # .item()\n",
    "\n",
    "    compiled_clf.eval()\n",
    "    loss_in_epoch_val = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_cat, x_cont, weights, targets in val_loader:\n",
    "            logits = clf(x_cat, x_cont)\n",
    "            logits = logits.flatten()\n",
    "\n",
    "            # get probabilities and round to nearest integer\n",
    "            preds = torch.sigmoid(logits).round()\n",
    "            correct += (preds == targets).sum().item()\n",
    "\n",
    "            # loss calculation.\n",
    "            # Criterion contains softmax already.\n",
    "            # Weight sample loss with (equal) weights\n",
    "            val_loss = criterion(logits, targets)\n",
    "            # val_loss = torch.mean(weights * intermediate_loss)\n",
    "            loss_in_epoch_val += val_loss  # val_loss #.item()\n",
    "    # loss average over all batches\n",
    "    train_loss = loss_in_epoch_train / len(train_loader)\n",
    "    val_loss = loss_in_epoch_val / len(val_loader)\n",
    "    \n",
    "    # update lr\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # correct samples / no samples\n",
    "    val_accuracy = correct / len(X_val)\n",
    "\n",
    "    print(f\"train:{train_loss} val:{val_loss} val acc: {val_accuracy}\")\n",
    "\n",
    "    # return early if val accuracy doesn't improve. Minus to minimize.\n",
    "    early_stopping(-val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "832522b0-9119-47e7-95eb-664e6f25aa81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = clf.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8cfe0-c6fc-46dc-8606-d6deb1e9dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train:nan val:0.5720667839050293 val acc: 0.7240031123338945\n",
    "train:nan val:0.5636194348335266 val acc: 0.7252551656097276\n",
    "train:nan val:0.5604064464569092 val acc: 0.7272873365643292\n",
    "train:nan val:0.5546848773956299 val acc: 0.7298300930140309\n",
    "train:nan val:0.5749767422676086 val acc: 0.7012596815451823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97f40d-9d4e-4018-98f1-5fc87e8e9f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred, y_true = [], []\n",
    "\n",
    "for x_cat, x_cont, weights, targets in test_loader:\n",
    "    logits = compiled_clf(x_cat, x_cont)\n",
    "\n",
    "    # map between zero and one, sigmoid is otherwise included in loss already\n",
    "    # https://stackoverflow.com/a/66910866/5755604\n",
    "    preds = torch.sigmoid(logits.squeeze())\n",
    "    y_pred.append(preds.detach().cpu().numpy())\n",
    "    y_true.append(targets.detach().cpu().numpy())  # type: ignore\n",
    "\n",
    "print(len(y_pred))\n",
    "print(len(y_true))\n",
    "\n",
    "# round prediction to nearest int\n",
    "y_pred = np.rint(np.concatenate(y_pred))\n",
    "y_pred[y_pred == 0] = -1\n",
    "y_true = np.concatenate(y_true)\n",
    "y_true[y_true == 0] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4e8c4-16f4-4a5f-9151-8d904cac165b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa74e5-fdb3-4e3b-a0f2-5fa998ddde06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef71391-1e86-4f17-ae6b-4fc51bba6c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_pred, y_true)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe09899-2aa5-42c2-8736-a514269ec8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtwo",
   "language": "python",
   "name": "torchtwo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
