{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from otc.data.dataloader import TabDataLoader\n",
        "from otc.models.activation import ReGLU\n",
        "from otc.models.fttransformer import (\n",
        "    CategoricalFeatureTokenizer,\n",
        "    CLSToken,\n",
        "    FeatureTokenizer,\n",
        "    FTTransformer,\n",
        "    MultiheadAttention,\n",
        "    NumericalFeatureTokenizer,\n",
        "    Transformer,\n",
        ")\n",
        "from otc.models.tabtransformer import TabTransformer\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os \n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "cf721f54b254482482c152ac155f979d",
            "f28a4d5288574bef831604096f8810e5",
            "6c3df6ba8d034fbab73eaea6291cf22b",
            "95681fb6b27444568eac8ee363b0f9ac",
            "2b70cdcb5ce44b6e9a52e6b353ce3a5e",
            "9046f63b323141ec80ba215a5c6ea1bc",
            "8c9d70af3c184d78bb98819ca0aba1b9",
            "45e989c2906d4ae18acaebea3eccfbd5",
            "b3f8ec205c9c4f6ab0ab906b1ea80535",
            "04fbb71360224ea3a89f5105c7e30080",
            "d30a4cddbf324b1a866899dd18121fdd"
          ]
        },
        "id": "aUoXCM9yM0qw",
        "outputId": "8f89a6d1-292a-4310-d0b0-03c33cfc6724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test batch size\n",
            "\tTesting batch size 64\n",
            "\tTesting batch size 128\n",
            "\tTesting batch size 256\n",
            "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
            "\tOOM at batch size 256\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\5.0a-mb-batch-size-finder.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 157>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m     batch_size \u001b[39m=\u001b[39m get_batch_size(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m         min_batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m         max_batch_size\u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     main()\n",
            "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\5.0a-mb-batch-size-finder.ipynb Cell 2\u001b[0m in \u001b[0;36mmain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m module_params \u001b[39m=\u001b[39m {\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdepth\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m12\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mheads\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m8\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnum_continuous\u001b[39m\u001b[39m\"\u001b[39m: NUM_FEATURES_CONT,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     }\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m model \u001b[39m=\u001b[39m TabTransformer(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodule_params\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m )\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m batch_size \u001b[39m=\u001b[39m get_batch_size(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     min_batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     max_batch_size\u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1024\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m )\n",
            "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\5.0a-mb-batch-size-finder.ipynb Cell 2\u001b[0m in \u001b[0;36mget_batch_size\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mdel\u001b[39;00m model, optimizer\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mempty_cache()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinal batch size \u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m batch_size\n",
            "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\memory.py:125\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 125\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_emptyCache()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ],
      "source": [
        "# code adapted from here:\n",
        "# https://towardsdatascience.com/a-batch-too-large-finding-the-batch-size-that-fits-on-gpus-aef70902a9f1\n",
        "\n",
        "\n",
        "# dataset information\n",
        "CAT_CARDINALITY = 9_000\n",
        "NUM_FEATURES_CAT = 3\n",
        "NUM_FEATURES_CONT = 41\n",
        "DATASET_SIZE = 50_000_000\n",
        "\n",
        "\n",
        "def get_batch_size(\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    min_batch_size: int = 2,\n",
        "    max_batch_size: Optional[int] = None,\n",
        "    num_iterations: int = 5,\n",
        ") -> int:\n",
        "    #print(model)\n",
        "    model.to(device)\n",
        "    model.train(True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "    print(\"Test batch size\")\n",
        "    batch_size = min_batch_size\n",
        "    while True:\n",
        "        if max_batch_size is not None and batch_size >= max_batch_size:\n",
        "            batch_size = max_batch_size\n",
        "            break\n",
        "        if batch_size >= DATASET_SIZE:\n",
        "            batch_size = batch_size // 2\n",
        "            break\n",
        "        try:\n",
        "            for _ in range(num_iterations):\n",
        "                # dummy inputs and targets\n",
        "\n",
        "                x_cat = torch.randint(\n",
        "                    1, CAT_CARDINALITY, (batch_size, NUM_FEATURES_CAT)\n",
        "                ).to(device)\n",
        "                x_cont = torch.rand((batch_size, NUM_FEATURES_CONT)).to(device)\n",
        "                targets = torch.randint(0, 1, (batch_size, 1)).float().to(device)\n",
        "                outputs = model(x_cat, x_cont)\n",
        "                loss = F.binary_cross_entropy_with_logits(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "            batch_size *= 2\n",
        "            print(f\"\\tTesting batch size {batch_size}\")\n",
        "            sleep(3)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "            print(f\"\\tOOM at batch size {batch_size}\")\n",
        "            batch_size //= 2\n",
        "            break\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"Final batch size {batch_size}\")\n",
        "    return batch_size\n",
        "\n",
        "\n",
        "def get_datasets(batch_size: int, num_workers: int = 2):\n",
        "\n",
        "    x_cat = torch.randint(0, CAT_CARDINALITY, (DATASET_SIZE, NUM_FEATURES_CAT))\n",
        "    x_cont = torch.rand((DATASET_SIZE, NUM_FEATURES_CONT))\n",
        "    weight = torch.ones((DATASET_SIZE, 1))\n",
        "    y = torch.randint(0, 1, (DATASET_SIZE, 1))\n",
        "\n",
        "    train_ds = TabDataLoader(\n",
        "        x_cat,\n",
        "        x_cont,\n",
        "        weight,\n",
        "        y,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    test_ds = TabDataLoader(\n",
        "        x_cat,\n",
        "        x_cont,\n",
        "        weight,\n",
        "        y,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_ds, test_ds\n",
        "\n",
        "\n",
        "def main(epochs: int = 2):\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA is not available.\")\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # https://github.com/Yura52/rtdl/blob/main/rtdl/modules.py\n",
        "    # set max cardinality for all categorical features and max dimension from search space\n",
        "    # params_feature_tokenizer = {\n",
        "    #     \"num_continous\": NUM_FEATURES_CONT,\n",
        "    #     \"cat_cardinalities\": [CAT_CARDINALITY] * NUM_FEATURES_CAT,\n",
        "    #     \"d_token\": 512,\n",
        "    # }\n",
        "    # feature_tokenizer = FeatureTokenizer(**params_feature_tokenizer)\n",
        "    # params_transformer = {\n",
        "    #     \"d_token\": 512,\n",
        "    #     \"n_blocks\": 6,\n",
        "    #     \"attention_n_heads\": 8,\n",
        "    #     \"attention_initialization\": \"kaiming\",\n",
        "    #     \"ffn_activation\": ReGLU,\n",
        "    #     \"attention_normalization\": nn.LayerNorm,\n",
        "    #     \"ffn_normalization\": nn.LayerNorm,\n",
        "    #     \"ffn_dropout\": 0.1,\n",
        "    #     \"ffn_d_hidden\": int(512 * (4 / 3)),\n",
        "    #     \"attention_dropout\": 0.1,\n",
        "    #     \"residual_dropout\": 0.1,\n",
        "    #     \"prenormalization\": True,\n",
        "    #     \"first_prenormalization\": False,\n",
        "    #     \"last_layer_query_idx\": None,\n",
        "    #     \"n_tokens\": None,\n",
        "    #     \"kv_compression_ratio\": None,\n",
        "    #     \"kv_compression_sharing\": None,\n",
        "    #     \"head_activation\": nn.ReLU,\n",
        "    #     \"head_normalization\": nn.LayerNorm,\n",
        "    #     \"d_out\": 1,\n",
        "    # }\n",
        "\n",
        "    # transformer = Transformer(**params_transformer)\n",
        "\n",
        "    # model = FTTransformer(feature_tokenizer, transformer)\n",
        "\n",
        "    module_params = {\n",
        "            \"depth\": 12,\n",
        "            \"heads\":8,\n",
        "            \"dim\": 256,\n",
        "            \"dim_out\": 1,\n",
        "            \"mlp_act\": nn.ReLU,\n",
        "            \"transformer_act\": F.gelu,\n",
        "            \"transformer_norm_first\": False,\n",
        "            \"mlp_hidden_mults\": (4, 2),\n",
        "            \"transformer_dropout\": 0.5,\n",
        "            \"cat_cardinalities\": [CAT_CARDINALITY] * NUM_FEATURES_CAT,\n",
        "            \"cat_features\": NUM_FEATURES_CAT,\n",
        "            \"num_continuous\": NUM_FEATURES_CONT,\n",
        "        }\n",
        "\n",
        "    model = TabTransformer(\n",
        "        **module_params\n",
        "    )\n",
        "\n",
        "\n",
        "    batch_size = get_batch_size(\n",
        "        model=model,\n",
        "        device=device,\n",
        "        min_batch_size=32,\n",
        "        max_batch_size= 1024 * 1024,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04fbb71360224ea3a89f5105c7e30080": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b70cdcb5ce44b6e9a52e6b353ce3a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e989c2906d4ae18acaebea3eccfbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3df6ba8d034fbab73eaea6291cf22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e989c2906d4ae18acaebea3eccfbd5",
            "max": 102540417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3f8ec205c9c4f6ab0ab906b1ea80535",
            "value": 102540417
          }
        },
        "8c9d70af3c184d78bb98819ca0aba1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9046f63b323141ec80ba215a5c6ea1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95681fb6b27444568eac8ee363b0f9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04fbb71360224ea3a89f5105c7e30080",
            "placeholder": "​",
            "style": "IPY_MODEL_d30a4cddbf324b1a866899dd18121fdd",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 85.3MB/s]"
          }
        },
        "b3f8ec205c9c4f6ab0ab906b1ea80535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf721f54b254482482c152ac155f979d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f28a4d5288574bef831604096f8810e5",
              "IPY_MODEL_6c3df6ba8d034fbab73eaea6291cf22b",
              "IPY_MODEL_95681fb6b27444568eac8ee363b0f9ac"
            ],
            "layout": "IPY_MODEL_2b70cdcb5ce44b6e9a52e6b353ce3a5e"
          }
        },
        "d30a4cddbf324b1a866899dd18121fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28a4d5288574bef831604096f8810e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9046f63b323141ec80ba215a5c6ea1bc",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9d70af3c184d78bb98819ca0aba1b9",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
