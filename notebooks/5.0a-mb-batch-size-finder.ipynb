{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is not available.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\5.0a-mb-batch-size-finder.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 179>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_result[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.04f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_result[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_result[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.04f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_result[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m         )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\5.0a-mb-batch-size-finder.ipynb Cell 1\u001b[0m in \u001b[0;36mmain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m(epochs: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCUDA is not available.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     batch_size \u001b[39m=\u001b[39m get_batch_size(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m         model\u001b[39m=\u001b[39mResNet(),\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m         dataset_size\u001b[39m=\u001b[39mDATASET_SIZE,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/5.0a-mb-batch-size-finder.ipynb#W0sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA is not available."
     ]
    }
   ],
   "source": [
    "# code adapted from here: \n",
    "# https://towardsdatascience.com/a-batch-too-large-finding-the-batch-size-that-fits-on-gpus-aef70902a9f1\n",
    "\n",
    "import torch\n",
    "from typing import Tuple\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "# dataset information\n",
    "IMAGE_SHAPE = (3, 224, 224)\n",
    "NUM_CLASSES = 100\n",
    "DATASET_SIZE = 1000\n",
    "\n",
    "\n",
    "def get_batch_size(\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    input_shape: Tuple[int, int, int],\n",
    "    output_shape: Tuple[int],\n",
    "    dataset_size: int,\n",
    "    max_batch_size: int = None,\n",
    "    num_iterations: int = 5,\n",
    ") -> int:\n",
    "    model.to(device)\n",
    "    model.train(True)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    print(\"Test batch size\")\n",
    "    batch_size = 2\n",
    "    while True:\n",
    "        if max_batch_size is not None and batch_size >= max_batch_size:\n",
    "            batch_size = max_batch_size\n",
    "            break\n",
    "        if batch_size >= dataset_size:\n",
    "            batch_size = batch_size // 2\n",
    "            break\n",
    "        try:\n",
    "            for _ in range(num_iterations):\n",
    "                # dummy inputs and targets\n",
    "                inputs = torch.rand(*(batch_size, *input_shape), device=device)\n",
    "                targets = torch.rand(*(batch_size, *output_shape), device=device)\n",
    "                outputs = model(inputs)\n",
    "                loss = F.mse_loss(targets, outputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            batch_size *= 2\n",
    "            print(f\"\\tTesting batch size {batch_size}\")\n",
    "            sleep(3)\n",
    "        except RuntimeError:\n",
    "            print(f\"\\tOOM at batch size {batch_size}\")\n",
    "            batch_size //= 2\n",
    "            break\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Final batch size {batch_size}\")\n",
    "    return batch_size\n",
    "\n",
    "\n",
    "def get_datasets(batch_size: int, num_workers: int = 2):\n",
    "    train_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=DATASET_SIZE,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_ds = DataLoader(\n",
    "        datasets.FakeData(\n",
    "            size=200,\n",
    "            image_size=IMAGE_SHAPE,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            transform=transforms.Compose([transforms.ToTensor()]),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return train_ds, test_ds\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=1000, out_features=NUM_CLASSES),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        outputs = self.resnet(inputs)\n",
    "        outputs = self.output_layer(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim,\n",
    "    train_ds: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_ds, desc=\"Train\")):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": train_loss / len(train_ds),\n",
    "        \"accuracy\": 100.0 * correct / len(train_ds.dataset),\n",
    "    }\n",
    "\n",
    "\n",
    "def test(model: nn.Module, test_ds: DataLoader, device: torch.device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        for data, target in tqdm(test_ds, desc=\"Test\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return {\n",
    "        \"loss\": test_loss / len(test_ds),\n",
    "        \"accuracy\": 100.0 * correct / len(test_ds.dataset),\n",
    "    }\n",
    "\n",
    "\n",
    "def main(epochs: int = 2):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available.\")\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    batch_size = get_batch_size(\n",
    "        model=ResNet(),\n",
    "        device=device,\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "        output_shape=(NUM_CLASSES,),\n",
    "        dataset_size=DATASET_SIZE,\n",
    "    )\n",
    "\n",
    "    train_ds, test_ds = get_datasets(batch_size=batch_size)\n",
    "    model = ResNet().to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        train_result = train(\n",
    "            model=model, optimizer=optimizer, train_ds=train_ds, device=device\n",
    "        )\n",
    "        test_result = test(model=model, test_ds=test_ds, device=device)\n",
    "        print(\n",
    "            f'Train loss: {train_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {train_result[\"accuracy\"]:.2f}%\\n'\n",
    "            f'Test loss: {test_result[\"loss\"]:.04f}\\t'\n",
    "            f'accuracy: {test_result[\"accuracy\"]}%'\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
