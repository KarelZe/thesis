{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from otc.models.activation import ReGLU\n",
    "from otc.models.fttransformer import (\n",
    "    CategoricalFeatureTokenizer,\n",
    "    CLSToken,\n",
    "    FeatureTokenizer,\n",
    "    FTTransformer,\n",
    "    MultiheadAttention,\n",
    "    NumericalFeatureTokenizer,\n",
    "    Transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2 Layer MLP projection head\n",
    "    \"\"\"\n",
    "    def __init__(self, *, d_in: int, d_hidden: int):\n",
    "        super().__init__()\n",
    "        self.first = nn.Linear(d_in, d_hidden)\n",
    "        self.out = nn.Linear(d_hidden, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x[:, 1:]\n",
    "\n",
    "        x = self.out(F.relu(self.first(x))).squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSHead(\n",
      "  (first): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "head = CLSHead(d_in=768, d_hidden=768)\n",
    "\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShufflePermutations(object):\n",
    "    \"\"\"\n",
    "    Generate permutations by shuffeling.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_num, X_cat):\n",
    "        self.X_num = X_num\n",
    "        self.X_cat = X_cat\n",
    "\n",
    "    def permute(self, X):\n",
    "        \"\"\"\n",
    "        generate random index\n",
    "        \"\"\"\n",
    "        if X is None:\n",
    "            return None\n",
    "\n",
    "        idx = torch.randint_like(X, X.shape[0], dtype=torch.long)\n",
    "\n",
    "        print(idx)\n",
    "        # generate random index array\n",
    "        return idx\n",
    "\n",
    "    def gen_permutations(self):\n",
    "        # permute numerical and categorical by random index\n",
    "        X_num = self.X_num\n",
    "        X_cat = self.X_cat if self.X_cat is not None else None\n",
    "        return self.permute(X_num), self.permute(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 1, 0, 1, 1, 0, 1, 3],\n",
      "        [2, 1, 2, 3, 0, 3, 0, 1],\n",
      "        [0, 0, 2, 1, 3, 0, 2, 0],\n",
      "        [0, 2, 1, 3, 3, 0, 2, 2]])\n",
      "tensor([[0, 3, 1, 0, 2, 3, 0, 2],\n",
      "        [2, 0, 0, 3, 3, 1, 0, 1],\n",
      "        [2, 2, 0, 1, 3, 0, 3, 0],\n",
      "        [3, 2, 0, 0, 3, 0, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "d_num, d_cat = 8,8\n",
    "batch_size = 4\n",
    "\n",
    "X_num = torch.randn(batch_size, d_num)\n",
    "X_cat = torch.randint(0, 10, (batch_size, d_cat))\n",
    "\n",
    "perm_class = ShufflePermutations(X_num, X_cat)\n",
    "x_num_perm, x_cat_perm = perm_class.gen_permutations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 1, 0, 2, 3, 0, 2],\n",
       "        [2, 0, 0, 3, 3, 1, 0, 1],\n",
       "        [2, 2, 0, 1, 3, 0, 3, 0],\n",
       "        [3, 2, 0, 0, 3, 0, 2, 3]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_probability = 0.15\n",
    "\n",
    "def gen_masks(X, perm):\n",
    "    # generate binary masks\n",
    "    masks = torch.empty_like(X).bernoulli(p=corrupt_probability).bool()\n",
    "    new_masks = masks & (X != X[perm, torch.arange(X.shape[1], device=X.device)])\n",
    "    return new_masks\n",
    "\n",
    "# FIXME: probably generate for train and val set\n",
    "x_num_mask = gen_masks(X_num, x_num_perm)\n",
    "x_cat_mask = gen_masks(X_cat, x_cat_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True, False]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6433e-02,  1.3993e+00,  1.2468e+00,  2.2310e-01,  9.4196e-01,\n",
       "         -1.5232e+00,  2.2584e+00,  1.9991e-01],\n",
       "        [ 8.6043e-04, -1.1932e+00, -7.4213e-01,  5.9814e-01,  1.0956e+00,\n",
       "         -1.1463e-02, -9.1753e-01, -9.2581e-01],\n",
       "        [ 9.0125e-01, -4.4415e-01,  1.2171e+00, -1.5085e-01,  1.2403e+00,\n",
       "          7.1277e-01,  2.4970e-02,  4.8426e-01],\n",
       "        [-4.3104e-01, -1.1699e+00, -1.7388e+00,  5.7839e-01,  1.8581e+00,\n",
       "          9.6402e-01,  1.2153e+00,  1.1985e+00]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values at permuted places\n",
    "x_num_permuted = torch.gather(X_num, 0, x_num_perm)\n",
    "\n",
    "# replace at mask = True\n",
    "X_num[x_num_mask] = x_num_permuted[x_num_mask]\n",
    "\n",
    "if X_cat is not None:\n",
    "\n",
    "    # along the 0 axis get elements based on perm_cat\n",
    "    x_cat_permuted = torch.gather(X_cat, 0, x_cat_perm)\n",
    "    \n",
    "    # replace at mask\n",
    "    X_cat[x_cat_mask] = x_cat_permuted[x_cat_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True, False]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6433e-02,  1.3993e+00,  1.2468e+00,  2.2310e-01,  1.0956e+00,\n",
       "         -1.5232e+00,  2.2584e+00,  1.9991e-01],\n",
       "        [ 8.6043e-04, -1.1932e+00, -7.4213e-01,  5.9814e-01,  1.0956e+00,\n",
       "         -1.1463e-02, -9.1753e-01, -9.2581e-01],\n",
       "        [ 9.0125e-01,  1.3993e+00,  1.2171e+00, -1.5085e-01,  1.2403e+00,\n",
       "          7.1277e-01,  2.4970e-02,  4.8426e-01],\n",
       "        [-4.3104e-01, -1.1699e+00, -1.7388e+00,  5.7839e-01,  1.8581e+00,\n",
       "          9.6402e-01,  2.4970e-02,  1.1985e+00]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_token = 96\n",
    "\n",
    "params_feature_tokenizer = {\n",
    "            \"num_continous\": d_num,\n",
    "            \"cat_cardinalities\": [11] * d_cat,\n",
    "            \"d_token\": d_token,\n",
    "        }\n",
    "\n",
    "feature_tokenizer = FeatureTokenizer(**params_feature_tokenizer)\n",
    "\n",
    "params_transformer = {\n",
    "            \"d_token\": d_token,\n",
    "            \"n_blocks\": 3,\n",
    "            \"attention_n_heads\": 8,\n",
    "            \"attention_initialization\": \"kaiming\",\n",
    "            \"ffn_activation\": ReGLU,\n",
    "            \"attention_normalization\": nn.LayerNorm,\n",
    "            \"ffn_normalization\": nn.LayerNorm,\n",
    "            \"ffn_dropout\": 0.1,\n",
    "            \"ffn_d_hidden\": 96 * 2,\n",
    "            \"attention_dropout\": 0.1,\n",
    "            \"residual_dropout\": 0.1,\n",
    "            \"prenormalization\": True,\n",
    "            \"first_prenormalization\": False,\n",
    "            \"last_layer_query_idx\": None,\n",
    "            \"n_tokens\": None,\n",
    "            \"kv_compression_ratio\": None,\n",
    "            \"kv_compression_sharing\": None,\n",
    "            \"head_activation\": nn.ReLU,\n",
    "            \"head_normalization\": nn.LayerNorm,\n",
    "            \"d_out\": 1,\n",
    "        }\n",
    "\n",
    "transformer = Transformer(**params_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden = 32\n",
    "\n",
    "class PretrainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # # Input modules\n",
    "        # d_cat_embedding = C.model.d_cat_embedding\n",
    "        # d_num_embedding = C.model.d_num_embedding\n",
    "\n",
    "        # self.category_sizes = D.get_category_sizes(\"train\")\n",
    "        # if self.category_sizes and (\n",
    "        #     C.model.kind == \"transformer\"\n",
    "        #     or C.model.d_cat_embedding == \"d_num_embedding\"\n",
    "        # ):\n",
    "        #     d_cat_embedding = C.model.d_num_embedding\n",
    "\n",
    "        # if d_num_embedding:\n",
    "        #     self.num_embeddings = lib.NumEmbeddings(\n",
    "        #         C.model.num_embedding_arch,\n",
    "        #         D.n_num_features,\n",
    "        #         d_num_embedding,\n",
    "        #         d_feature=bins_store.n_bins if bins_store else None,\n",
    "        #         periodic_embedding_options=C.model.positional_encoding,\n",
    "        #     )\n",
    "        #     d_in_num = D.n_num_features * C.model.d_num_embedding\n",
    "        # else:\n",
    "        #     self.num_embeddings = None\n",
    "        #     d_in_num = bins_store.n_bins if bins_store else D.n_num_features\n",
    "\n",
    "        # if d_cat_embedding:\n",
    "        #     self.cat_embeddings = rtdl.CategoricalFeatureTokenizer(\n",
    "        #         self.category_sizes, d_cat_embedding, True, \"uniform\"\n",
    "        #     )\n",
    "        #     d_in_cat = d_cat_embedding * D.n_cat_features\n",
    "        # else:\n",
    "        #     self.cat_embeddings = None\n",
    "        #     d_in_cat = sum(self.category_sizes)\n",
    "\n",
    "        # d_in = d_in_num + d_in_cat\n",
    "        # print(f\"Model: Built embeddings flattened input dim: {d_in}\")\n",
    "\n",
    "        # # Backbones\n",
    "        # self.cls_token = None\n",
    "        # if C.model.kind == \"transformer\":\n",
    "        #     # load configuration\n",
    "        #     baseline_config = rtdl.FTTransformer.get_baseline_transformer_subconfig()\n",
    "        #     C.model.config = baseline_config | C.model.config\n",
    "        #     C.model.config[\"d_token\"] = C.model.d_num_embedding\n",
    "        #     # set backbone and cls token\n",
    "        #     self.backbone = lib.Transformer(C.model.config)\n",
    "        #     self.cls_token = rtdl.CLSToken(self.backbone.d, \"uniform\")\n",
    "\n",
    "\n",
    "        self.feature_tokenizer = feature_tokenizer\n",
    "\n",
    "        d_in = d_num + d_cat\n",
    "        \n",
    "        self.cls_token = CLSToken(d_token, \"uniform\")\n",
    "\n",
    "        # change later\n",
    "        # self.backbone = nn.Identity()\n",
    "        self.backbone = transformer\n",
    "\n",
    "        self.head = CLSHead(\n",
    "                d_in=d_token,\n",
    "                d_hidden=d_hidden,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "\n",
    "        # # concat embeddings, if available\n",
    "        # if self.num_embeddings:\n",
    "        #     x_num = self.num_embeddings(x_num)\n",
    "        # if self.cat_embeddings is not None:\n",
    "        #     assert x_cat is not None\n",
    "        #     x_cat = self.cat_embeddings(x_cat)\n",
    "\n",
    "        # print(x_num.shape)\n",
    "        # print(x_cat.shape)\n",
    "\n",
    "\n",
    "        # x = torch.cat(\n",
    "        #     [\n",
    "        #         x_ for x_ in [x_num, x_cat]\n",
    "        #         if x_ is not None\n",
    "        #     ],\n",
    "        #     dim=1,\n",
    "        # )\n",
    "\n",
    "        # tokenize\n",
    "        x = self.feature_tokenizer(x_num, x_cat)\n",
    "        # add cls token to input\n",
    "        #x = self.cls_token(x)\n",
    "\n",
    "        # add backbone\n",
    "        h = self.backbone(x)\n",
    "        \n",
    "        print(h)\n",
    "\n",
    "        # add classification head\n",
    "        return self.head(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1002],\n",
      "        [-0.1421],\n",
      "        [-0.4934],\n",
      "        [-0.1751]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x0 and 96x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\4.0e-mb-fttransformer-pretraining.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m PretrainModel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model(X_num, X_cat)\n",
      "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\4.0e-mb-fttransformer-pretraining.ipynb Cell 12\u001b[0m in \u001b[0;36mPretrainModel.forward\u001b[1;34m(self, x_num, x_cat)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mprint\u001b[39m(h)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39m# add classification head\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead(h)\n",
      "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\4.0e-mb-fttransformer-pretraining.ipynb Cell 12\u001b[0m in \u001b[0;36mCLSHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m x[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfirst(x)))\u001b[39m.\u001b[39msqueeze(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0e-mb-fttransformer-pretraining.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x0 and 96x32)"
     ]
    }
   ],
   "source": [
    "model = PretrainModel()\n",
    "model(X_num, X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to device\n",
    "device = \"cuda\"\n",
    "\n",
    "model = PretrainModel().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False,  True, False,  True, False,\n",
      "          True,  True, False, False, False, False],\n",
      "        [ True, False, False,  True, False, False, False, False, False,  True,\n",
      "         False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False, False,  True, False, False]])\n",
      "tensor([[1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
      "        [0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0]])\n",
      "tensor([0.2500, 0.2500, 0.7500, 0.7500, 0.2500, 0.2500, 0.2500, 0.5000, 0.2500,\n",
      "        0.5000, 0.5000, 0.2500, 0.5000, 0.0000, 0.5000, 0.2500])\n"
     ]
    }
   ],
   "source": [
    "# TODO: move into training loop\n",
    "\n",
    "# cat masks if cat variables are present\n",
    "if X_cat != None:\n",
    "    masks = torch.cat([x_num_mask, x_cat_mask], dim=1)\n",
    "else:\n",
    "    masks = x_num_mask\n",
    "\n",
    "# logits to binary mask\n",
    "predictions = torch.randn(batch_size, d_num + d_cat)\n",
    "hard_predictions = torch.zeros_like(predictions, dtype=torch.long)\n",
    "hard_predictions[predictions > 0] = 1\n",
    "\n",
    "# column-wise accuracy\n",
    "features_accuracy = (hard_predictions.bool() == masks).sum(0) / hard_predictions.shape[0]\n",
    "\n",
    "print(masks)\n",
    "print(hard_predictions)\n",
    "print(features_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
