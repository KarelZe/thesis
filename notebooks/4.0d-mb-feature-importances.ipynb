{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b20cffb9-5df8-4606-8b33-f7abf7429842",
   "metadata": {},
   "source": [
    "Do custom install of `sage-importance`\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/karelze/sage.git\n",
    "cd sage\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd44d4a0-223b-4117-ade7-5c5cfacfa28a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from torch import nn\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from otc.models.classical_classifier import ClassicalClassifier\n",
    "\n",
    "from sage import GroupedMarginalImputer, PermutationEstimator\n",
    "\n",
    "from otc.features.build_features import (\n",
    "    features_categorical,\n",
    "    features_classical,\n",
    "    features_classical_size,\n",
    "    features_ml,\n",
    ")\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22901e37-f5e0-43fa-a489-8581b094f3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# set globally here\n",
    "EXCHANGE = \"ise\"  \n",
    "STRATEGY = \"supervised\"  \n",
    "SUBSET = \"test\"  \n",
    "\n",
    "# Change depending on model!\n",
    "FEATURES = features_classical_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f00103-842c-473b-80d7-05e57f6ee25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set project name. Required to access files and artefacts\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334b77d-6ec7-44cc-b57d-94977a69d438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
    "dataset = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_none:latest\"\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce2b60eb",
   "metadata": {},
   "source": [
    "## Data Preparation üåä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfd371-1b90-4133-8e7c-6b8a6afb4c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "dataset = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_none:latest\"\n",
    "\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()\n",
    "\n",
    "columns = [\n",
    "    *FEATURES,\n",
    "    \"buy_sell\",\n",
    "]\n",
    "\n",
    "data = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\", columns=columns)\n",
    "\n",
    "y_train_none = data[\"buy_sell\"]\n",
    "X_train_none = data.drop(columns=\"buy_sell\")\n",
    "\n",
    "data = pd.read_parquet(Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\", columns=columns)\n",
    "\n",
    "y_test_none = data[\"buy_sell\"]\n",
    "X_test_none = data.drop(columns=\"buy_sell\")\n",
    "\n",
    "\n",
    "dataset = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_log_standardized_clipped:latest\"\n",
    "\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()\n",
    "\n",
    "data = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\", columns=columns)\n",
    "\n",
    "y_train_processed = data[\"buy_sell\"]\n",
    "X_train_processed = data.drop(columns=\"buy_sell\")\n",
    "\n",
    "data = pd.read_parquet(Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\", columns=columns)\n",
    "\n",
    "y_test_processed = data[\"buy_sell\"]\n",
    "X_test_processed = data.drop(columns=\"buy_sell\")\n",
    "\n",
    "feature_names = X_train_none.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64241e2b",
   "metadata": {},
   "source": [
    "## Sage Valuesüåµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22968e-d4e5-4473-bddb-71af4b8bbddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define feature groups (disjoint)\n",
    "feature_groups = group_names = {\n",
    "    'chg_all_lead (grouped)': ['price_all_lead', 'chg_all_lead'],\n",
    "    'chg_all_lag (grouped)': ['price_all_lag', 'chg_ex_lag'],\n",
    "    'chg_ex_lead (grouped)': ['price_ex_lead', 'chg_ex_lead', 'chg_all_lag'],\n",
    "    'chg_ex_lag (grouped)': ['price_ex_lag'],\n",
    "    'size_ex (grouped)': [ 'bid_ask_size_ratio_ex', 'rel_bid_size_ex',  'rel_ask_size_ex', 'bid_size_ex', 'ask_size_ex','depth_ex'],\n",
    "    'quote_best (grouped)': ['BEST_ASK', 'BEST_BID', 'prox_best'],\n",
    "    'quote_ex (grouped)': ['bid_ex', 'ask_ex','prox_ex' ],\n",
    "    'TRADE_PRICE': ['TRADE_PRICE'],\n",
    "    'TRADE_SIZE': ['TRADE_SIZE']    \n",
    "}\n",
    "group_names = [group for group in feature_groups]\n",
    "for col in feature_names:\n",
    "    if np.all([col not in group[1] for group in feature_groups.items()]):\n",
    "        group_names.append(col)\n",
    "\n",
    "# Group indices\n",
    "groups = []\n",
    "for _, group in feature_groups.items():\n",
    "    ind_list = []\n",
    "    for feature in group:\n",
    "        ind_list.append(feature_names.tolist().index(feature))\n",
    "    groups.append(ind_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f88b949e",
   "metadata": {},
   "source": [
    "### Classical Classifierüè¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f011f3-149e-47ef-b565-ff60d6751c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = ClassicalClassifier(layers=[(\"trade_size\", \"ex\"), (\"rev_lr\", \"best\")], \n",
    "                                  random_state=SEED, strategy=\"random\")\n",
    "\n",
    "clf.fit(X=X_train_none.head(5), y=y_train_none.head(5))\n",
    "\n",
    "imputer = GroupedMarginalImputer(clf, X_test_none.head(1024).values, groups)\n",
    "estimator = PermutationEstimator(imputer, \"cross entropy\")\n",
    "sage_values = estimator(X_test_none.head(1024).values, y_test_none.head(1024).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ca421-f617-44d0-9dcc-67acf0c24727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sage_values.plot(group_names, title=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efa51927",
   "metadata": {},
   "source": [
    "### Gradient Boosting üêà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef3a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model by identifier from wandb\n",
    "model = \"17malsep_CatBoostClassifier_default.cbm:v7\"\n",
    "model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "artifact = run.use_artifact(model)\n",
    "model_dir = artifact.download()\n",
    "\n",
    "clf = CatBoostClassifier()\n",
    "clf.load_model(fname=Path(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db6ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = GroupedMarginalImputer(clf, X_test_processed.head(128).values, groups)\n",
    "estimator = PermutationEstimator(imputer, \"cross entropy\")\n",
    "sage_values = estimator(X_test_processed.head(128).values, y_test_processed.head(128).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a8d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sage_values.plot(group_names, title=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b26639ad",
   "metadata": {},
   "source": [
    "### Transformer Classifier ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d380c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"2rq3hrkw_TransformerClassifier_default.pkl:latest\"\n",
    "model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "artifact = run.use_artifact(model)\n",
    "model_dir = artifact.download()\n",
    "    \n",
    "with open(Path(model_dir, model_name), 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98618fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = GroupedMarginalImputer(clf, X_test_processed.head(1024).values, groups)\n",
    "estimator = PermutationEstimator(imputer, \"cross entropy\")\n",
    "sage_values = estimator(X_test_processed.head(1024).values, y_test_processed.head(1024).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a2b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sage_values.plot(group_names, title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844714d-3e33-48e2-811a-9d26198729fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"i3pvza1q_TransformerClassifier_default.pkl:latest\"\n",
    "model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "artifact = run.use_artifact(model)\n",
    "model_dir = artifact.download()\n",
    "    \n",
    "with open(Path(model_dir, model_name), 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a13ba17c-50af-4f24-9cf5-b60a95057020",
   "metadata": {},
   "source": [
    "## Attention Maps for Transformers\n",
    "\n",
    "We calculate the average attention map from all transformer blocks, as done in the Gorishniy paper (see [here](https://github.com/Yura52/tabular-dl-revisiting-models/issues/2)). This is different from the Borisov paper (see [here](https://github.com/kathrinse/TabSurvey/blob/main/models/basemodel_torch.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153345ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otc.models.activation import ReGLU\n",
    "from otc.models.fttransformer import (\n",
    "    CategoricalFeatureTokenizer,\n",
    "    CLSToken,\n",
    "    FeatureTokenizer,\n",
    "    FTTransformer,\n",
    "    MultiheadAttention,\n",
    "    NumericalFeatureTokenizer,\n",
    "    Transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcf45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_cont = 5\n",
    "num_features_cat = 1\n",
    "cat_cardinalities = [2]\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x_cat = torch.randint(0, 1, (batch_size, num_features_cat)).to(\n",
    "            device\n",
    "        )\n",
    "x_cont = (\n",
    "            torch.randn(batch_size, num_features_cont).float().to(device)\n",
    ")\n",
    "\n",
    "params_feature_tokenizer  = {\n",
    "            \"num_continous\": num_features_cont,\n",
    "            \"cat_cardinalities\": cat_cardinalities,\n",
    "            \"d_token\": 96,\n",
    "        }\n",
    "feature_tokenizer = FeatureTokenizer(**params_feature_tokenizer)\n",
    "params_transformer = {\n",
    "            \"d_token\": 96,\n",
    "            \"n_blocks\": 3,\n",
    "            \"attention_n_heads\": 8,\n",
    "            \"attention_initialization\": \"kaiming\",\n",
    "            \"ffn_activation\": ReGLU,\n",
    "            \"attention_normalization\": nn.LayerNorm,\n",
    "            \"ffn_normalization\": nn.LayerNorm,\n",
    "            \"ffn_dropout\": 0.1,\n",
    "            \"ffn_d_hidden\": 96 * 2,\n",
    "            \"attention_dropout\": 0.1,\n",
    "            \"residual_dropout\": 0.1,\n",
    "            \"prenormalization\": True,\n",
    "            \"first_prenormalization\": False,\n",
    "            \"last_layer_query_idx\": None,\n",
    "            \"n_tokens\": None,\n",
    "            \"kv_compression_ratio\": None,\n",
    "            \"kv_compression_sharing\": None,\n",
    "            \"head_activation\": nn.ReLU,\n",
    "            \"head_normalization\": nn.LayerNorm,\n",
    "            \"d_out\": 1,\n",
    "        }\n",
    "\n",
    "transformer = Transformer(**params_transformer)\n",
    "model = FTTransformer(feature_tokenizer, transformer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe4e7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveAttentionMaps:\n",
    "    \"\"\"\n",
    "    Hook for attention maps.\n",
    "\n",
    "    Inspired by:\n",
    "    https://github.com/Yura52/tabular-dl-revisiting-models/issues/2#issuecomment-1068123629\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.attention_maps: List[torch.Tensor] = []\n",
    "\n",
    "    def __call__(self, _, __, output):\n",
    "        # print(output[1][\"attention_probs\"].shape)\n",
    "        self.attention_maps.append(output[1][\"attention_probs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca45bd57",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Markus\\OneDrive\\Documents\\git\\thesis\\notebooks\\4.0d-mb-feature-importances.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0d-mb-feature-importances.ipynb#X56sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m attention_probs \u001b[39m=\u001b[39m attention_probs\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0d-mb-feature-importances.ipynb#X56sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# calculate gradient with respect to output\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0d-mb-feature-importances.ipynb#X56sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(y\u001b[39m.\u001b[39;49msum(), [attention_probs], retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0d-mb-feature-importances.ipynb#X56sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m cam \u001b[39m=\u001b[39m attention_probs\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Markus/OneDrive/Documents/git/thesis/notebooks/4.0d-mb-feature-importances.ipynb#X56sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(grad\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Markus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# The following hook will save all attention maps from all attention modules.\n",
    "# Prepare data and model.\n",
    "n_objects = len(x_cat)  # 12\n",
    "n_features = num_features_cont + num_features_cat\n",
    "\n",
    "# The following hook will save all attention maps from all attention modules.\n",
    "hook = SaveAttentionMaps()\n",
    "for block in model.transformer.blocks:\n",
    "    block.attention.register_forward_hook(hook)\n",
    "\n",
    "# Apply the model to all objects.\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y = model(x_cat, x_cont)\n",
    "    # y.requires_grad_(True)\n",
    "    # print(y.shape)\n",
    "\n",
    "# Collect attention maps\n",
    "n_blocks = len(model.transformer.blocks)\n",
    "n_heads = model.transformer.blocks[0].attention.n_heads\n",
    "# continuous features + categorical features + CLS token\n",
    "n_tokens = n_features + 1\n",
    "# residual connection\n",
    "res = torch.eye(n_tokens, n_tokens)\n",
    "res = res.unsqueeze(0).expand(batch_size, n_tokens, n_tokens)\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "# index = [i for i in range(batch_size)]\n",
    "# one_hot = np.zeros((logits_per_image.shape[0], logits_per_image.shape[1]), dtype=np.float32)\n",
    "# one_hot[torch.arange(logits_per_image.shape[0]), index] = 1\n",
    "# one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "# one_hot = torch.sum(one_hot.cuda() * logits_per_image)\n",
    "# model.zero_grad()\n",
    "\n",
    "for attention_map in hook.attention_maps:\n",
    "    # batch size, n_heads, n_tokens, n_tokens\n",
    "    attention_probs = attention_map.reshape(batch_size, n_heads, n_tokens, n_tokens)\n",
    "\n",
    "    attention_probs = attention_probs.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # calculate gradient with respect to output\n",
    "    grad = torch.autograd.grad(y.sum(), [attention_probs], retain_graph=True)[0].detach()\n",
    "    cam = attention_probs.detach()\n",
    "    print(grad.shape)\n",
    "    print(cam.shape)\n",
    "\n",
    "    cam = cam.reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "    grad = grad.reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "    cam = grad * cam\n",
    "    cam = cam.reshape(batch_size, -1, cam.shape[-1], cam.shape[-1])\n",
    "    cam = cam.clamp(min=0).mean(dim=1)\n",
    "    res = res + torch.bmm(cam, res)\n",
    "\n",
    "attention_maps = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2023ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/hila-chefer/Transformer-MM-Explainability/blob/main/CLIP_explainability.ipynb#scrollTo=fWKGyu2YAeSV\n",
    "\n",
    "def interpret(image, texts, model, device, start_layer=start_layer, start_layer_text=start_layer_text):\n",
    "    batch_size = texts.shape[0]\n",
    "    images = image.repeat(batch_size, 1, 1, 1)\n",
    "    logits_per_image, logits_per_text = model(images, texts)\n",
    "    probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
    "    index = [i for i in range(batch_size)]\n",
    "    one_hot = np.zeros((logits_per_image.shape[0], logits_per_image.shape[1]), dtype=np.float32)\n",
    "    one_hot[torch.arange(logits_per_image.shape[0]), index] = 1\n",
    "    one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "    one_hot = torch.sum(one_hot.cuda() * logits_per_image)\n",
    "    model.zero_grad()\n",
    "\n",
    "    image_attn_blocks = list(dict(model.visual.transformer.resblocks.named_children()).values())\n",
    "\n",
    "    if start_layer == -1: \n",
    "      # calculate index of last layer \n",
    "      start_layer = len(image_attn_blocks) - 1\n",
    "    \n",
    "    num_tokens = image_attn_blocks[0].attn_probs.shape[-1]\n",
    "    R = torch.eye(num_tokens, num_tokens, dtype=image_attn_blocks[0].attn_probs.dtype).to(device)\n",
    "    R = R.unsqueeze(0).expand(batch_size, num_tokens, num_tokens)\n",
    "    for i, blk in enumerate(image_attn_blocks):\n",
    "        if i < start_layer:\n",
    "          continue\n",
    "        grad = torch.autograd.grad(one_hot, [blk.attn_probs], retain_graph=True)[0].detach()\n",
    "        cam = blk.attn_probs.detach()\n",
    "        cam = cam.reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "        grad = grad.reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "        cam = grad * cam\n",
    "        cam = cam.reshape(batch_size, -1, cam.shape[-1], cam.shape[-1])\n",
    "        cam = cam.clamp(min=0).mean(dim=1)\n",
    "        R = R + torch.bmm(cam, R)\n",
    "    image_relevance = R[:, 0, 1:]\n",
    "\n",
    "    \n",
    "    text_attn_blocks = list(dict(model.transformer.resblocks.named_children()).values())\n",
    "\n",
    "    if start_layer_text == -1: \n",
    "      # calculate index of last layer \n",
    "      start_layer_text = len(text_attn_blocks) - 1\n",
    "\n",
    "    num_tokens = text_attn_blocks[0].attn_probs.shape[-1]\n",
    "    R_text = torch.eye(num_tokens, num_tokens, dtype=text_attn_blocks[0].attn_probs.dtype).to(device)\n",
    "    R_text = R_text.unsqueeze(0).expand(batch_size, num_tokens, num_tokens)\n",
    "    for i, blk in enumerate(text_attn_blocks):\n",
    "        if i < start_layer_text:\n",
    "          continue\n",
    "        grad = torch.autograd.grad(one_hot, [blk.attn_probs], retain_graph=True)[0].detach()\n",
    "        cam = blk.attn_probs.detach()\n",
    "        cam = cam.reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "        grad = grad.reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "        cam = grad * cam\n",
    "        cam = cam.reshape(batch_size, -1, cam.shape[-1], cam.shape[-1])\n",
    "        cam = cam.clamp(min=0).mean(dim=1)\n",
    "        R_text = R_text + torch.bmm(cam, R_text)\n",
    "    text_relevance = R_text\n",
    "   \n",
    "    return text_relevance, image_relevance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
