{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WXF7w4VyVgG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "\n",
    "import wandb\n",
    "from otc.metrics.metrics import effective_spread\n",
    "from scipy.stats import wilcoxon\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set here globally\n",
    "EXCHANGE = \"cboe\" # \"ise\"\n",
    "MODELS = [\"classical\"] \n",
    "SUBSET = \"all\"  # \"all\"\n",
    "STRATEGY = \"supervised\" # \"transfer\" #  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KEY = f\"{EXCHANGE}_{STRATEGY}_{SUBSET}\"\n",
    "DATASET = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_raw:latest\"\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# load unscaled data\n",
    "artifact = run.use_artifact(DATASET)  # type: ignore\n",
    "data_dir = artifact.download()\n",
    "\n",
    "# load results\n",
    "result_dirs = []\n",
    "for model in MODELS:\n",
    "    results = f\"fbv/thesis/{EXCHANGE}_{model}_{STRATEGY}_{SUBSET}:latest\"\n",
    "    artifact = run.use_artifact(results)  # type: ignore\n",
    "    result_dir = artifact.download()\n",
    "    result_dirs.append(result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p. 35-38\n",
    "COLUMNS = [\n",
    "    \"buy_sell\",\n",
    "    \"EXPIRATION\",\n",
    "    \"QUOTE_DATETIME\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"TRADE_PRICE\",\n",
    "    \"ask_ex\",\n",
    "    \"bid_ex\",\n",
    "    \"myn\",\n",
    "    \"OPTION_TYPE\",\n",
    "    \"issue_type\",\n",
    "]\n",
    "\n",
    "\n",
    "if SUBSET == \"all\":\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    val = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    eval_data = pd.concat([train, val, test])\n",
    "    del train, val, test\n",
    "\n",
    "elif SUBSET == \"test\":\n",
    "    eval_data = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, model in tqdm(enumerate(MODELS)):\n",
    "    result = pd.read_parquet(Path(result_dirs[i], \"results\"), engine=\"fastparquet\")\n",
    "    result.columns = pd.MultiIndex.from_product([[model], result.columns])\n",
    "    results.append(result)\n",
    "\n",
    "results_data = pd.concat(results, axis=1, names=MODELS)\n",
    "\n",
    "assert len(eval_data) == len(results_data)\n",
    "\n",
    "X_print = eval_data\n",
    "\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIXME: select a subset of results for testing.\n",
    "results_data = results_data[\n",
    "    [\n",
    "        # (\"fttransformer\", \"fttransformer(classical)\"),\n",
    "        # (\"fttransformer\", \"fttransformer(classical-size)\"),\n",
    "        # (\"fttransformer\", \"fttransformer(ml)\"),        \n",
    "        # (\"gbm\", \"gbm(classical)\"),\n",
    "        # (\"gbm\", \"gbm(classical-size)\"),\n",
    "        # (\"gbm\", \"gbm(ml)\"),\n",
    "        # (\"gbm\", \"gbm(classical-retraining)\"),\n",
    "        # (\"gbm\", \"gbm(classical-size-retraining)\"),\n",
    "        # (\"gbm\", \"gbm(ml-retraining)\"),\n",
    "        # (\"gbm\", \"gbm(semi-classical)\"),\n",
    "        # (\"gbm\",'gbm(semi-classical-size)'),\n",
    "        # (\"gbm\",'gbm(semi-ml)'),\n",
    "\n",
    "        # viz\n",
    "        (\"classical\", \"tick(all)\"),\n",
    "        (\"classical\", \"quote(best)\"),\n",
    "        (\"classical\", \"quote(best)->quote(ex)->rev_tick(all)\"),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->quote(ex)->depth(best)->depth(ex)->rev_tick(all)\",\n",
    "        ),       \n",
    "\n",
    "        # batch 1\n",
    "        # (\"classical\", \"tick(ex)\"),\n",
    "        # (\"classical\", \"quote(ex)\"),\n",
    "        # (\"classical\", \"lr(ex)\"),\n",
    "        # (\"classical\", \"emo(ex)\"),\n",
    "        # (\"classical\", \"clnv(ex)\"),\n",
    "        # (\"classical\", \"quote(best)->quote(ex)->rev_tick(all)\"),\n",
    "        # (\n",
    "        #     \"classical\",\n",
    "        #     \"trade_size(ex)->quote(best)->quote(ex)->depth(best)->depth(ex)->rev_tick(all)\",\n",
    "        # ),\n",
    "        \n",
    "        # batch 2\n",
    "        # (\"classical\", \"tick(all)\"),  \n",
    "        # (\"classical\", \"quote(best)\"),\n",
    "        # (\"classical\", \"lr(best)\"),\n",
    "        # (\"classical\", \"emo(best)\"),\n",
    "        # (\"classical\", \"clnv(best)\"),\n",
    "        \n",
    "        # batch 3\n",
    "        # (\"classical\", \"rev_tick(ex)\"),\n",
    "        # (\"classical\", \"rev_tick(all)\"),\n",
    "        # (\"classical\", \"rev_lr(ex)\"),\n",
    "        # (\"classical\", \"rev_emo(ex)\"),\n",
    "        # (\"classical\", \"rev_clnv(ex)\"),\n",
    "        # (\"classical\", \"rev_lr(best)\"),\n",
    "        # (\"classical\", \"rev_emo(best)\"),\n",
    "        # (\"classical\", \"rev_clnv(best)\"),     \n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LUT = {\n",
    "    \"Trade_Size(ex)->Quote(Best)->Depth(Best)->Quote(Ex)->Depth(Ex)->Rev_Tick(All)\": \"\\gls{GBM}\",\n",
    "    \"(Ex)\": \" (Ex)\",\n",
    "    \"(Best)\": \" (Best)\",\n",
    "    \"(Classical)\": \" (Classical)\",\n",
    "    \"(Classical-Size)\": \" (Classical, Size)\",\n",
    "    \"Rev_\": \"Rev. \",\n",
    "    \"Trade_Size\": \"Trade Size\",\n",
    "    \"Depth\": \"Depth\",\n",
    "    \"->\": \" $\\\\to$ \",\n",
    "    \"Lr\": \"\\gls{LR}\",\n",
    "    \"Emo\": \"\\gls{EMO}\",\n",
    "    \"Clnv\": \"\\gls{CLNV}\",\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    \"_\": \"$\\_\",\n",
    "    \"Gbm\": \"\\gls{GBM}\",\n",
    "}\n",
    "\n",
    "LUT_INDEX = {\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    \"issue_type\": \"Security Type\",\n",
    "    \"TRADE_SIZE_binned\": \"Trade Size\",\n",
    "    \"year_binned\": \"Year\",\n",
    "    \"ttm_binned\": \"Time to Maturity\",\n",
    "    \"myn_binned\": \"Moneyness\",\n",
    "    \"prox_q_binned\": \"Location to Quote\",\n",
    "    \"all\": \"All trades\",\n",
    "}\n",
    "\n",
    "\n",
    "def cell_str(x):\n",
    "    x = x.title()\n",
    "    for orig, sub in LUT.items():\n",
    "        x = x.replace(orig, sub)\n",
    "    # title-case everything\n",
    "    return x\n",
    "\n",
    "\n",
    "def highlight_max(s, props=\"\"):\n",
    "    return np.where(s == np.nanmax(s.values), props, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_tex_style(styler, caption, label, bold_axis=1):\n",
    "    res = styler.set_caption(caption)\n",
    "\n",
    "    res = (\n",
    "        res.apply(highlight_max, props=\"font-weight:bold;\", axis=bold_axis)\n",
    "        .format(precision=4, decimal=\".\", thousands=\",\", escape=False, hyperlinks=None)\n",
    "        .format_index(cell_str, axis=0)\n",
    "        .format_index(cell_str, axis=1)\n",
    "        .to_latex(\n",
    "            f\"{label}.tex\",\n",
    "            siunitx=True,\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            clines=\"skip-last;data\",\n",
    "            label=\"tab:\" + label,\n",
    "            caption=caption,\n",
    "            convert_css=True,\n",
    "        )\n",
    "    )\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = results_data.columns.tolist()\n",
    "criterions = list(LUT_INDEX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unclassified by method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclassified = (\n",
    "    (results_data[results_data == 0.0].count(axis=0) / len(results_data.index))\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name=\"unclassified\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclassified.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(f\"{KEY}-unclassified-long\", \"{key}-unclassified-short\"),\n",
    "    label=f\"{KEY.lower()}-unclassfied\",\n",
    "    bold_axis=0,\n",
    ")\n",
    "unclassified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in unclassified\n",
    "\n",
    "Unclassified are `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# replace 0 -> nan -> [-1,1]\n",
    "results_data.replace(0, np.nan, inplace=True)\n",
    "# assume same filler for every column\n",
    "filler = pd.Series(\n",
    "        rng.choice(a=[-1, 1], size=results_data.shape[0]),\n",
    "        index=results_data.index,\n",
    "        # columns=results_data.columns,\n",
    ")\n",
    "\n",
    "# do column-wise as we run out of memory otherwise\n",
    "for classifier in tqdm(classifiers):\n",
    "    results_data[classifier].fillna(filler, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print[\"all\"] = \"all\"\n",
    "X_print[\"date\"] = X_print[\"QUOTE_DATETIME\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if EXCHANGE == \"ise\":\n",
    "    bins_dt = [pd.Timestamp(\"2000-01-01 00:00:00\"), pd.Timestamp(\"2013-10-24 23:59:00\"), pd.Timestamp(\"2015-11-05 23:59:00\"),pd.Timestamp(\"2099-12-31 23:59:59\")]\n",
    "    labels_dt = [\"train\", \"val\", \"test\"]\n",
    "else:\n",
    "    bins_dt = [pd.Timestamp(\"2000-01-01 00:00:00\"), pd.Timestamp(\"2015-11-05 23:59:00\"), pd.Timestamp(\"2099-12-31 23:59:59\")]\n",
    "    labels_dt = [\"unused\", \"test\"]\n",
    "\n",
    "X_print[\"date\"] = pd.to_datetime(X_print['date'])\n",
    "\n",
    "X_print[\"set\"] = pd.cut(X_print['date'], bins=bins_dt, labels=labels_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print = pd.concat([X_print, results_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for classifier in tqdm(classifiers):\n",
    "    res = (\n",
    "        X_print.groupby([\"date\"])[[\"buy_sell\", classifier]]\n",
    "        .apply(\n",
    "                lambda x: accuracy_score(x[\"buy_sell\"].astype(\"int8\"), x[classifier])\n",
    "        )\n",
    "        .mul(100)\n",
    "        .rename(classifier)\n",
    "    )\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies_over_time = pd.concat(results, axis=1)\n",
    "accuracies_over_time.columns = accuracies_over_time.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    f\"gs://thesis-bucket-option-trade-classification/data/results/{KEY}-classical-accurcies-over-time.parquet\"\n",
    ")\n",
    "accuracies_over_time.to_parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the artifact to save it as an output of this run\n",
    "result_set = wandb.Artifact(name=f\"{KEY}-classical-accurcies-over-time\", type=\"results\")\n",
    "result_set.add_reference(output_path, name=\"results\")\n",
    "run.log_artifact(result_set)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies_over_time.plot(ylim=(0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3vzAVSc_DfD"
   },
   "source": [
    "### Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3evMG-KVA2eX"
   },
   "outputs": [],
   "source": [
    "# prepare columns for printing\n",
    "X_print[\"ttm\"] = (\n",
    "    X_print[\"EXPIRATION\"].dt.to_period(\"M\")\n",
    "    - X_print[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
    ").apply(lambda x: x.n)\n",
    "\n",
    "X_print[\"year\"] = X_print[\"QUOTE_DATETIME\"].dt.year\n",
    "\n",
    "bins_tradesize = [-1, 1, 3, 5, 11, np.inf]\n",
    "trade_size_labels = [\"(0,1]\", \"(1,3]\", \"(3,5]\", \"(5,11]\", \">11\"]\n",
    "X_print[\"TRADE_SIZE_binned\"] = pd.cut(\n",
    "    X_print[\"TRADE_SIZE\"], bins_tradesize, labels=trade_size_labels\n",
    ")\n",
    "\n",
    "# p. 38\n",
    "bins_years = [2004, 2007, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "year_labels = [\n",
    "    \"2005-2007\",\n",
    "    \"2008-2010\",\n",
    "    \"2011\",\n",
    "    \"2012\",\n",
    "    \"2013\",\n",
    "    \"2014\",\n",
    "    \"2015\",\n",
    "    \"2016\",\n",
    "    \"2017\",\n",
    "]\n",
    "X_print[\"year_binned\"] = pd.cut(X_print[\"year\"], bins_years, labels=year_labels)\n",
    "\n",
    "# p. 37\n",
    "bins_ttm = [-1, 1, 2, 3, 6, 12, np.inf]\n",
    "ttm_labels = [\n",
    "    \"<= 1\",\n",
    "    \"(1-2]\",\n",
    "    \"(2-3]\",\n",
    "    \"(3-6]\",\n",
    "    \"(6-12]\",\n",
    "    \"> 12\",\n",
    "]\n",
    "X_print[\"ttm_binned\"] = pd.cut(X_print[\"ttm\"], bins_ttm, labels=ttm_labels)\n",
    "\n",
    "# Security type\n",
    "# see 3.0a-mb-explanatory-data-analysis.ipynb\n",
    "X_print[\"issue_type\"] = X_print[\"issue_type\"].map(\n",
    "    {\n",
    "        \"0\": \"Stock option\",\n",
    "        \"A\": \"Index option\",\n",
    "        \"7\": \"Others\",\n",
    "        \"F\": \"Others\",\n",
    "        \"%\": \"Others\",\n",
    "        \" \": \"Others\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Moneyness p. 38\n",
    "bins_myn = [-1, 0.7, 0.9, 1.1, 1.3, np.inf]\n",
    "myn_labels = [\n",
    "    \"<= 0.7\",\n",
    "    \"(0.7-0.9]\",\n",
    "    \"(0.9-1.1]\",\n",
    "    \"(1.1-1.3]\",\n",
    "    \"> 1.3\",\n",
    "]\n",
    "X_print[\"myn_binned\"] = pd.cut(X_print[\"myn\"], bins_myn, labels=myn_labels)\n",
    "\n",
    "# mid p. 31 + extra category for unknowns\n",
    "ask = X_print[\"ask_ex\"]\n",
    "bid = X_print[\"bid_ex\"]\n",
    "trade_price = X_print[\"TRADE_PRICE\"]\n",
    "\n",
    "# require ask >= bid\n",
    "mid = np.where(ask >= bid, (ask + bid) * 0.5, np.nan)\n",
    "\n",
    "prox_quotes = np.where(\n",
    "    trade_price == mid,\n",
    "    0,  # at mid\n",
    "    np.where(\n",
    "        (bid < trade_price) & (trade_price < ask),\n",
    "        1,  # inside\n",
    "        np.where(\n",
    "            (trade_price == bid) | (ask == trade_price),\n",
    "            2,  # at quotes\n",
    "            np.where((trade_price < bid) | (ask < trade_price), 3, 4),\n",
    "        ),\n",
    "    ),\n",
    ")  # outside + unclassifiable\n",
    "\n",
    "bins_prox = [-np.inf, 0, 1, 2, 3, 4]\n",
    "prox_labels = [\n",
    "    \"at mid\",\n",
    "    \"inside\",\n",
    "    \"at quotes\",\n",
    "    \"outside\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "X_print[\"prox_q_binned\"] = pd.cut(prox_quotes, bins_prox, labels=prox_labels)\n",
    "X_print[\"mid\"] = mid\n",
    "\n",
    "# clean up empty buckets, as it causes empty grouping in result set generation\n",
    "X_print[\"year_binned\"] = X_print[\"year_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"myn_binned\"] = X_print[\"myn_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"ttm_binned\"] = X_print[\"ttm_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"prox_q_binned\"] = X_print[\"prox_q_binned\"].cat.remove_unused_categories()\n",
    "\n",
    "X_print[\"all\"] = \"all\"\n",
    "\n",
    "X_print.drop(\n",
    "    columns=[\n",
    "        \"EXPIRATION\",\n",
    "        \"QUOTE_DATETIME\",\n",
    "        \"TRADE_SIZE\",\n",
    "        \"ttm\",\n",
    "        \"myn\",\n",
    "        \"year\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_print = pd.concat([X_print, results_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterions = [\"set\", \"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIXME: Find better approach\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "for criterion in tqdm(criterions):\n",
    "    results = []\n",
    "    for classifier in classifiers:\n",
    "        res = (\n",
    "            X_print.groupby([criterion])[[\"buy_sell\", classifier]]\n",
    "            .apply(\n",
    "                lambda x: accuracy_score(x[\"buy_sell\"].astype(\"int8\"), x[classifier])\n",
    "            )\n",
    "            .mul(100)\n",
    "            .rename(classifier)\n",
    "        )\n",
    "        #         acc_tot = accuracy_score(\n",
    "        #             X_print[\"buy_sell\"].astype(\"int8\"), X_print[classifier]\n",
    "        #         )\n",
    "\n",
    "        #         res.loc[\"all\"] = acc_tot * 100\n",
    "\n",
    "        res.index.name = LUT_INDEX.get(criterion)\n",
    "        results.append(res)\n",
    "\n",
    "    # save aggregated results\n",
    "    result_df = pd.concat(results, axis=1).T\n",
    "    result_df.style.pipe(\n",
    "        set_tex_style,\n",
    "        caption=(f\"long-tbd\", \"short-tbd\"),\n",
    "        label=f\"{KEY.lower()}-{criterion.lower()}\",\n",
    "    )\n",
    "\n",
    "    # store all result sets for later use\n",
    "    result_dfs.append(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# master = pd.concat(result_dfs, axis=1, keys=list(LUT_INDEX.values())).T\n",
    "master = pd.concat(result_dfs, axis=1, keys=[\"subset\", \"all\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master.T.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(\"master-long\", \"master-short\"),\n",
    "    label=f\"{KEY}-master\",\n",
    "    bold_axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Spread ðŸ’´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "ask = X_print[\"ask_ex\"]\n",
    "bid = X_print[\"bid_ex\"]\n",
    "mid = X_print[\"mid\"]\n",
    "\n",
    "# calculate true rel effective spread but not aggregated, convert to %\n",
    "es_true = effective_spread(X_print[\"buy_sell\"], X_print[\"TRADE_PRICE\"], mid, mode=\"none\")\n",
    "eps_true = np.empty(es_true.shape)\n",
    "np.divide(es_true, mid, out=eps_true, where=mid != 0)\n",
    "\n",
    "nom_true = effective_spread(X_print[\"buy_sell\"], X_print[\"TRADE_PRICE\"], mid, mode=\"nominal\")\n",
    "rel_true = effective_spread(X_print[\"buy_sell\"], X_print[\"TRADE_PRICE\"], mid, mode=\"relative\")\n",
    "\n",
    "# require ask > bid\n",
    "rel_quoted = np.nanmean((ask - bid) / mid)\n",
    "nom_quoted = np.nanmean(np.where(ask >= bid, (ask - bid), np.nan))\n",
    "\n",
    "for classifier in tqdm(classifiers):\n",
    "    nom_pred = effective_spread(X_print[classifier], X_print[\"TRADE_PRICE\"], mid, mode=\"nominal\")\n",
    "    rel_pred = effective_spread(X_print[classifier], X_print[\"TRADE_PRICE\"], mid, mode=\"relative\")\n",
    "\n",
    "    # calculate pred rel effective spread but not aggregated convert to %\n",
    "    es_pred = effective_spread(X_print[classifier], X_print[\"TRADE_PRICE\"], mid, mode=\"none\")\n",
    "    eps_pred = np.empty(es_pred.shape)\n",
    "    np.divide(es_pred, mid, out=eps_pred, where=mid != 0)\n",
    "\n",
    "    wilcoxon_res  = wilcoxon(eps_pred, eps_true, nan_policy=\"omit\", zero_method=\"zsplit\")\n",
    "\n",
    "    res = pd.Series(\n",
    "            {\n",
    "                \"nom_pred\": nom_pred * 100,\n",
    "                \"rel_pred\": rel_pred * 100,\n",
    "                \"statistic\":wilcoxon_res.statistic,\n",
    "                \"pvalue\":wilcoxon_res.pvalue,\n",
    "            }, name=classifier\n",
    "        )\n",
    "    results.append(res)\n",
    "\n",
    "true_eff = pd.Series({\"nom_pred\":nom_true * 100, \"rel_pred\": rel_true * 100, \"statistic\":np.NaN, \"pvalue\":np.NaN}, name=\"true_eff\")\n",
    "true_quoted = pd.Series({\"nom_pred\":nom_quoted * 100, \"rel_pred\": rel_quoted * 100, \"statistic\":np.NaN, \"pvalue\":np.NaN}, name=\"true_quoted\")\n",
    "\n",
    "results.append(true_eff)\n",
    "results.append(true_quoted)\n",
    "\n",
    "results = pd.concat(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.T.style.format(\"{:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.style.to_latex(\n",
    "    f\"../reports/Content/{KEY}-eff-spread.tex\",\n",
    "    siunitx=True,\n",
    "    position_float=\"centering\",\n",
    "    hrules=True,\n",
    "    clines=\"skip-last;data\",\n",
    "    label=f\"tab:eff-{KEY}\",\n",
    "    caption=(f\"long-eff-{KEY}\", f\"short-eff-{KEY}\"),\n",
    "    convert_css=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffs ðŸ”„ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classical baselines\n",
    "\n",
    "base = master[\n",
    "    [\n",
    "        (\"classical\", \"quote(best)->quote(ex)\"),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->quote(ex)->depth(best)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->quote(ex)->depth(best)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "    ]\n",
    "]\n",
    "\n",
    "# my ml models\n",
    "revised = master[\n",
    "    [(MODELS[0], f\"{MODELS[0]}(classical)\"), (MODELS[0], f\"{MODELS[0]}(classical-size)\"), (MODELS[0], f\"{MODELS[0]}(ml)\")]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(revised: pd.DataFrame, base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate print layout like in Grauer et al.\n",
    "\n",
    "    https://tex.stackexchange.com/questions/430283/table-with-numbers-in-parentheses-in-siunitx/430290#430290\n",
    "\n",
    "    # see p. https://texdoc.org/serve/siunitx/0\n",
    "    \"\"\"\n",
    "    # first, second layer of colum index\n",
    "    c_1 = revised.columns.get_level_values(1)\n",
    "    c_2 = [\"nom\"]\n",
    "    midx = pd.MultiIndex.from_product([c_1, c_2])\n",
    "\n",
    "    # copy data from revised add as (column, \"nom\")\n",
    "    combo = pd.DataFrame(revised.values, index=revised.index, columns=midx)\n",
    "\n",
    "    for i, mul_col in enumerate(combo.columns):\n",
    "\n",
    "        combo[(mul_col[0], \"pm\")] = (combo[mul_col] - base.iloc[:, i]).round(2)\n",
    "        combo.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = combine_results(revised, base)\n",
    "\n",
    "diff.style.to_latex(\n",
    "    f\"../reports/Content/diff-{KEY}.tex\",\n",
    "    siunitx=True,\n",
    "    position_float=\"centering\",\n",
    "    hrules=True,\n",
    "    clines=\"skip-last;data\",\n",
    "    label=f\"tab:diff-{KEY}\",\n",
    "    caption=(f\"long-diff-{KEY}\", f\"short-diff-{KEY}\"),\n",
    "    convert_css=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
