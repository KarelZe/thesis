{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WXF7w4VyVgG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from otc.metrics.metrics import effective_spread\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set here globally\n",
    "exchange = \"cboe\"\n",
    "models = [\"gbm\", \"classical\"] # [\"gbm\", \"classical\"]\n",
    "subset = \"test\" # \"all\"\n",
    "strategy = \"supervised\"  # \"transfer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = f\"{exchange}_{strategy}_{subset}\"\n",
    "dataset = f\"fbv/thesis/{exchange}_{strategy}_raw:latest\"\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# load unscaled data\n",
    "artifact = run.use_artifact(dataset)  # type: ignore\n",
    "data_dir = artifact.download()\n",
    "\n",
    "# load results\n",
    "result_dirs = []\n",
    "for model in models:\n",
    "    results = f\"fbv/thesis/{exchange}_{model}_{strategy}_{subset}:latest\"\n",
    "    artifact = run.use_artifact(results)  # type: ignore\n",
    "    result_dir = artifact.download()\n",
    "    result_dirs.append(result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE"
   },
   "outputs": [],
   "source": [
    "# p. 35-38\n",
    "columns = [\n",
    "    \"buy_sell\",\n",
    "    \"EXPIRATION\",\n",
    "    \"QUOTE_DATETIME\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"TRADE_PRICE\",\n",
    "    \"ask_ex\",\n",
    "    \"bid_ex\",\n",
    "    \"myn\",\n",
    "    \"OPTION_TYPE\",\n",
    "    \"issue_type\",\n",
    "]\n",
    "\n",
    "\n",
    "if subset == \"all\":\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    val = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    eval_data = pd.concat([train, val, test])\n",
    "    del train, val, test\n",
    "\n",
    "elif subset == \"test\":\n",
    "    eval_data = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, model in tqdm(enumerate(models)):\n",
    "    result = pd.read_parquet(Path(result_dirs[i], \"results\"), engine=\"fastparquet\")\n",
    "    result.columns = pd.MultiIndex.from_product([[model], result.columns])\n",
    "    results.append(result)\n",
    "\n",
    "results_data = pd.concat(results, axis=1, names=models)\n",
    "\n",
    "assert len(eval_data) == len(results_data)\n",
    "\n",
    "X_print = eval_data\n",
    "\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: select a subset of results for testing.\n",
    "results_data = results_data[\n",
    "    [\n",
    "        (\"gbm\", \"gbm(classical)\"),\n",
    "        (\"gbm\", \"gbm(classical-size)\"),\n",
    "        (\"gbm\", \"gbm(ml)\"),\n",
    "        (\"classical\", \"tick(ex)\"),\n",
    "        (\"classical\", \"quote(ex)\"),\n",
    "        (\"classical\", \"lr(ex)\"),\n",
    "        (\"classical\", \"emo(ex)\"),\n",
    "        (\"classical\", \"clnv(ex)\"),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3vzAVSc_DfD"
   },
   "source": [
    "### Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3evMG-KVA2eX"
   },
   "outputs": [],
   "source": [
    "# prepare columns for printing\n",
    "X_print[\"ttm\"] = (\n",
    "    X_print[\"EXPIRATION\"].dt.to_period(\"M\")\n",
    "    - X_print[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
    ").apply(lambda x: x.n)\n",
    "\n",
    "X_print[\"year\"] = X_print[\"QUOTE_DATETIME\"].dt.year\n",
    "\n",
    "bins_tradesize = [-1, 1, 3, 5, 11, np.inf]\n",
    "trade_size_labels = [\"(0,1]\", \"(1,3]\", \"(3,5]\", \"(5,11]\", \">11\"]\n",
    "X_print[\"TRADE_SIZE_binned\"] = pd.cut(\n",
    "    X_print[\"TRADE_SIZE\"], bins_tradesize, labels=trade_size_labels\n",
    ")\n",
    "\n",
    "# p. 38\n",
    "bins_years = [2004, 2007, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "year_labels = [\n",
    "    \"2005-2007\",\n",
    "    \"2008-2010\",\n",
    "    \"2011\",\n",
    "    \"2012\",\n",
    "    \"2013\",\n",
    "    \"2014\",\n",
    "    \"2015\",\n",
    "    \"2016\",\n",
    "    \"2017\",\n",
    "]\n",
    "X_print[\"year_binned\"] = pd.cut(X_print[\"year\"], bins_years, labels=year_labels)\n",
    "\n",
    "# p. 37\n",
    "bins_ttm = [-1, 1, 2, 3, 6, 12, np.inf]\n",
    "ttm_labels = [\n",
    "    \"<= 1\",\n",
    "    \"(1-2]\",\n",
    "    \"(2-3]\",\n",
    "    \"(3-6]\",\n",
    "    \"(6-12]\",\n",
    "    \"> 12\",\n",
    "]\n",
    "X_print[\"ttm_binned\"] = pd.cut(X_print[\"ttm\"], bins_ttm, labels=ttm_labels)\n",
    "\n",
    "# Security type\n",
    "# see 3.0a-mb-explanatory-data-analysis.ipynb\n",
    "X_print[\"issue_type\"] = X_print[\"issue_type\"].map(\n",
    "    {\n",
    "        \"0\": \"Stock option\",\n",
    "        \"A\": \"Index option\",\n",
    "        \"7\": \"Others\",\n",
    "        \"F\": \"Others\",\n",
    "        \"%\": \"Others\",\n",
    "        \" \": \"Others\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Moneyness p. 38\n",
    "bins_myn = [-1, 0.7, 0.9, 1.1, 1.3, np.inf]\n",
    "myn_labels = [\n",
    "    \"<= 0.7\",\n",
    "    \"(0.7-0.9]\",\n",
    "    \"(0.9-1.1]\",\n",
    "    \"(1.1-1.3]\",\n",
    "    \"> 1.3\",\n",
    "]\n",
    "X_print[\"myn_binned\"] = pd.cut(X_print[\"myn\"], bins_myn, labels=myn_labels)\n",
    "\n",
    "# mid p. 31 + extra category for unknowns\n",
    "ask = X_print[\"ask_ex\"]\n",
    "bid = X_print[\"bid_ex\"]\n",
    "trade_price = X_print[\"TRADE_PRICE\"]\n",
    "\n",
    "mid = np.where(ask >= bid, (ask + bid) * 0.5, np.nan)\n",
    "half_spread = np.where(ask >= bid, (ask - bid) * 0.5, np.nan)\n",
    "\n",
    "prox_quotes = np.where(\n",
    "    trade_price == mid,\n",
    "    0,  # at mid\n",
    "    np.where(\n",
    "        ((mid - half_spread) < trade_price) & (trade_price < (mid + half_spread)),\n",
    "        1,  # inside\n",
    "        np.where(\n",
    "            (trade_price == ask) | (bid == trade_price),\n",
    "            2,  # at quotes\n",
    "            np.where(\n",
    "                (trade_price < (mid - half_spread))\n",
    "                | ((mid + half_spread) > trade_price),\n",
    "                3,\n",
    "                4,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")  # outside + unclassifiable\n",
    "\n",
    "bins_prox = [-np.inf, 0, 1, 2, 3, 4]\n",
    "prox_labels = [\n",
    "    \"at mid\",\n",
    "    \"inside\",\n",
    "    \"at quotes\",\n",
    "    \"outside\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "X_print[\"prox_q_binned\"] = pd.cut(prox_quotes, bins_prox, labels=prox_labels)\n",
    "X_print[\"mid\"] = mid\n",
    "\n",
    "# clean up empty buckets, as it causes empty grouping in result set generation\n",
    "X_print[\"year_binned\"] = X_print[\"year_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"myn_binned\"] = X_print[\"myn_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"ttm_binned\"] = X_print[\"ttm_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"prox_q_binned\"] = X_print[\"prox_q_binned\"].cat.remove_unused_categories()\n",
    "\n",
    "X_print.drop(\n",
    "    columns=[\n",
    "        \"EXPIRATION\",\n",
    "        \"QUOTE_DATETIME\",\n",
    "        \"TRADE_SIZE\",\n",
    "        \"ttm\",\n",
    "        \"myn\",\n",
    "        \"ask_ex\",\n",
    "        \"bid_ex\",\n",
    "        \"year\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_print = pd.concat([X_print, results_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT = {\n",
    "    \"Trade_Size(ex)->Quote(Best)->Depth(Best)->Quote(Ex)->Depth(Ex)->Rev_Tick(All)\": \"\\gls{GBM}\",\n",
    "    \"(Ex)\": \" (Ex)\",\n",
    "    \"(Best)\": \" (Best)\",\n",
    "    \"(Classical)\": \" (Classical)\",\n",
    "    \"(Classical-Size)\": \" (Classical, Size)\",\n",
    "    \"Rev_\": \"Rev. \",\n",
    "    \"Trade_Size\": \"Trade Size\",\n",
    "    \"Depth\": \"Depth\",\n",
    "    \"->\": \" $\\\\to$ \",\n",
    "    \"Lr\": \"\\gls{LR}\",\n",
    "    \"Emo\": \"\\gls{EMO}\",\n",
    "    \"Clnv\": \"\\gls{CLNV}\",\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    # \"(\": \"(\",  # put interval start in math env\n",
    "    # \"]\": \"]\",  # put interval end in math env\n",
    "    \"_\": \"$\\_\",\n",
    "    \"Gbm\": \"\\gls{GBM}\",\n",
    "}\n",
    "\n",
    "LUT_INDEX = {\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    \"issue_type\": \"Security Type\",\n",
    "    \"TRADE_SIZE_binned\": \"Trade Size\",\n",
    "    \"year_binned\": \"Year\",\n",
    "    \"ttm_binned\": \"Time to Maturity\",\n",
    "    \"myn_binned\": \"Moneyness\",\n",
    "    \"prox_q_binned\": \"Proximity to Quote\",\n",
    "}\n",
    "\n",
    "\n",
    "def cell_str(x):\n",
    "    x = x.title()\n",
    "    for orig, sub in LUT.items():\n",
    "        x = x.replace(orig, sub)\n",
    "    # title-case everything\n",
    "    return x\n",
    "\n",
    "\n",
    "def highlight_max(s, props=\"\"):\n",
    "    return np.where(s == np.nanmax(s.values), props, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tex_style(styler, caption, label, bold_axis=1):\n",
    "    res = styler.set_caption(caption)\n",
    "    res = (res.apply(\n",
    "            highlight_max, props=\"font-weight:bold;\", axis=bold_axis\n",
    "        )\n",
    "        .format(precision=4, decimal=\".\", thousands=\",\", escape=False, hyperlinks=None)\n",
    "        .format_index(cell_str, axis=0)\n",
    "        .format_index(cell_str, axis=1)\n",
    "        # .hide(axis=\"index\", level=0)\n",
    "        .to_latex(\n",
    "            f\"{label}.tex\",\n",
    "            siunitx=True,\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            clines=\"skip-last;data\",\n",
    "            label=\"tab:\" + label,\n",
    "            caption=caption,\n",
    "            convert_css=True,\n",
    "        )\n",
    "    )\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = results_data.columns.tolist()\n",
    "criterions = list(LUT_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Find better approach\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "for criterion in tqdm(criterions):\n",
    "    results = []\n",
    "    for classifier in tqdm(classifiers):\n",
    "        acc_tot = accuracy_score(\n",
    "            X_print[\"buy_sell\"].astype(\"int8\"), X_print[classifier]\n",
    "        )\n",
    "\n",
    "        res = (\n",
    "            X_print.groupby([criterion])[[\"buy_sell\", classifier]]\n",
    "            .apply(\n",
    "                lambda x: accuracy_score(x[\"buy_sell\"].astype(\"int8\"), x[classifier])\n",
    "            )\n",
    "            .mul(100)\n",
    "            .rename(classifier)\n",
    "        )\n",
    "        res.loc[\"all\"] = acc_tot * 100\n",
    "\n",
    "        res.index.name = LUT_INDEX.get(criterion)\n",
    "        results.append(res)\n",
    "\n",
    "    # save aggregated results\n",
    "    result_df = pd.concat(results, axis=1).T\n",
    "    result_df.style.pipe(\n",
    "        set_tex_style,\n",
    "        caption=(f\"long-tbd\", \"short-tbd\"),\n",
    "        label=f\"{key.lower()}-{criterion.lower()}\",\n",
    "    )\n",
    "\n",
    "    # store all result sets for later use\n",
    "    result_dfs.append(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.concat(result_dfs, axis=1, keys=list(LUT_INDEX.values())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.style.pipe(\n",
    "    set_tex_style, caption=(\"master-long\", \"master-short\"), label=f\"{key}-master\", bold_axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Spread 🚧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_dfs = []\n",
    "\n",
    "\n",
    "def stats(x, classifier):\n",
    "\n",
    "    nom = effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"nominal\")\n",
    "    rel = (\n",
    "        effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"relative\")\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    # eff_spread_pred = effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"none\")\n",
    "    # eff_spread_true = effective_spread(x[\"buy_sell\"], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"none\")\n",
    "    # wilcoxon_res  = wilcoxon(eff_spread_pred, eff_spread_true, nan_policy=\"omit\", zero_method=\"zsplit\")\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"nominal\": nom,\n",
    "            \"rel\": rel,\n",
    "            # 'statistic':wilcoxon_res.statistic,\n",
    "            # 'pvalue':wilcoxon_res.pvalue\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "for criterion in tqdm(criterions):\n",
    "    results = []\n",
    "\n",
    "    for classifier in tqdm(classifiers):\n",
    "        res = X_print.groupby([criterion])[\n",
    "            [\"TRADE_PRICE\", \"mid\", classifier, \"buy_sell\"]\n",
    "        ].apply(stats, classifier)\n",
    "        results.append(res)\n",
    "\n",
    "    # save aggregated results\n",
    "    result_df = pd.concat(results, axis=1, keys=classifiers).T\n",
    "    result_df.style.pipe(\n",
    "        set_tex_style,\n",
    "        caption=(f\"long-tbd\", \"short-tbd\"),\n",
    "        label=f\"{key.lower()}-{criterion.lower()}-eff-spread\",\n",
    "    )\n",
    "\n",
    "    # store all result sets for later use\n",
    "    eff_dfs.append(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread = pd.concat(eff_dfs, axis=1, keys=LUT_INDEX.values()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(\"master-short\", \"master-long\"),\n",
    "    label=f\"{key}-master-eff-spread\",\n",
    "    bold_axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in Parenthesis 🅾️\n",
    "\n",
    "```latex\n",
    "# https://tex.stackexchange.com/questions/430283/table-with-numbers-in-parentheses-in-siunitx/430290#430290\n",
    "\\begin{table}\n",
    "    \\centering\n",
    "    \\caption{test of combination with change}\n",
    "    \\label{tab:combo}\n",
    "    \\begin{tabular}{lSSSSSSSS}\n",
    "        \\toprule\n",
    "        {} & \\multicolumn{2}{l}{Index option} & \\multicolumn{2}{l}{Others} & \\multicolumn{2}{l}{Stock options} & \\multicolumn{2}{l}{all} \\\\\n",
    "        \\midrule\n",
    "        classical-size & 1.0 & \\parl-56.42\\parr & 2.0 & \\parl-74.35\\parr & -73.5 & \\parl-143.93\\parr & 5.0 & \\parl-67.33\\parr \\\\\n",
    "        \\bottomrule\n",
    "        \\end{tabular}\n",
    "\\end{table}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = master[[(\"classical\",\"quote(ex)\"),(\"classical\", \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\"), (\"classical\", \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\")]]\n",
    "revised = master[[(\"gbm\",\"gbm(classical)\"),(\"gbm\",\"gbm(classical-size)\"), (\"gbm\", \"gbm(ml)\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_results(revised: pd.DataFrame, base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate print layout like in Grauer et al.\n",
    "\n",
    "    https://tex.stackexchange.com/questions/430283/table-with-numbers-in-parentheses-in-siunitx/430290#430290\n",
    "\n",
    "    # see p. https://texdoc.org/serve/siunitx/0\n",
    "    \"\"\"\n",
    "    # first, second layer of colum index\n",
    "    c_1 = revised.columns.get_level_values(1)\n",
    "    c_2 = [\"nom\"]\n",
    "    midx = pd.MultiIndex.from_product([c_1, c_2])\n",
    "\n",
    "    # copy data from revised add as (column, \"nom\")\n",
    "    combo = pd.DataFrame(revised.values, index=revised.index, columns=midx)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i, mul_col in enumerate(combo.columns):\n",
    "\n",
    "        combo[(mul_col[0], \"pm\")] = (\n",
    "            \"\\parl\" + (combo[mul_col] - base.iloc[:,i]).round(2).astype(str) + \"\\parr\"\n",
    "        )\n",
    "        # print(combo.shape)\n",
    "        # # define custom brackets that are not parsed by sunitx\n",
    "        # combo.iloc[:,[(mul_col[0], \"pm\")]] = \n",
    "        # # sort to group together columns\n",
    "        # combo.sort_index(axis=1, inplace=True)\n",
    "        # cols.append(diff)\n",
    "        combo.sort_index(axis=1, inplace=True)\n",
    "        \n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = combine_results(revised, base)\n",
    "\n",
    "diff.style.to_latex(\n",
    "            f\"diff-{key}.tex\",\n",
    "            siunitx=True,\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            clines=\"skip-last;data\",\n",
    "            label=f\"tab:diff-{key}\",\n",
    "            caption=(f\"long-diff-{key}\", f\"short-diff-{key}\"),\n",
    "            convert_css=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
