{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WXF7w4VyVgG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "\n",
    "import wandb\n",
    "from otc.metrics.metrics import effective_spread\n",
    "from scipy.stats import wilcoxon\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set here globally\n",
    "EXCHANGE = \"ise\"\n",
    "MODELS = [\"gbm\", \"classical\"]  # [\"gbm\", \"classical\"]\n",
    "SUBSET = \"test\"  # \"all\"\n",
    "STRATEGY = \"supervised\"  # \"transfer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KEY = f\"{EXCHANGE}_{STRATEGY}_{SUBSET}\"\n",
    "DATASET = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_raw:latest\"\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# load unscaled data\n",
    "artifact = run.use_artifact(DATASET)  # type: ignore\n",
    "data_dir = artifact.download()\n",
    "\n",
    "# load results\n",
    "result_dirs = []\n",
    "for model in MODELS:\n",
    "    results = f\"fbv/thesis/{EXCHANGE}_{model}_{STRATEGY}_{SUBSET}:latest\"\n",
    "    artifact = run.use_artifact(results)  # type: ignore\n",
    "    result_dir = artifact.download()\n",
    "    result_dirs.append(result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p. 35-38\n",
    "COLUMNS = [\n",
    "    \"buy_sell\",\n",
    "    \"EXPIRATION\",\n",
    "    \"QUOTE_DATETIME\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"TRADE_PRICE\",\n",
    "    \"ask_ex\",\n",
    "    \"bid_ex\",\n",
    "    \"myn\",\n",
    "    \"OPTION_TYPE\",\n",
    "    \"issue_type\",\n",
    "]\n",
    "\n",
    "\n",
    "if SUBSET == \"all\":\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    val = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "    eval_data = pd.concat([train, val, test])\n",
    "    del train, val, test\n",
    "\n",
    "elif SUBSET == \"test\":\n",
    "    eval_data = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set\"), engine=\"fastparquet\", columns=COLUMNS\n",
    "    )\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, model in tqdm(enumerate(MODELS)):\n",
    "    result = pd.read_parquet(Path(result_dirs[i], \"results\"), engine=\"fastparquet\")\n",
    "    result.columns = pd.MultiIndex.from_product([[model], result.columns])\n",
    "    results.append(result)\n",
    "\n",
    "results_data = pd.concat(results, axis=1, names=MODELS)\n",
    "\n",
    "assert len(eval_data) == len(results_data)\n",
    "\n",
    "X_print = eval_data\n",
    "\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIXME: select a subset of results for testing.\n",
    "results_data = results_data[\n",
    "    [\n",
    "        (\"gbm\", \"gbm(classical)\"),\n",
    "        (\"gbm\", \"gbm(classical-retraining)\"),\n",
    "        (\"gbm\", \"gbm(classical-size-retraining)\"),\n",
    "        (\"gbm\", \"gbm(classical-size)\"),\n",
    "        (\"gbm\", \"gbm(ml)\"),\n",
    "        (\"gbm\", \"gbm(ml-retraining)\"),\n",
    "        (\"gbm\", \"gbm(semi-classical)\"),\n",
    "        # (\"gbm\",'gbm(semi-classical-retraining)'),\n",
    "        (\"classical\", \"tick(ex)\"),\n",
    "        (\"classical\", \"quote(ex)\"),\n",
    "        (\"classical\", \"lr(ex)\"),\n",
    "        (\"classical\", \"emo(ex)\"),\n",
    "        (\"classical\", \"clnv(ex)\"),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LUT = {\n",
    "    \"Trade_Size(ex)->Quote(Best)->Depth(Best)->Quote(Ex)->Depth(Ex)->Rev_Tick(All)\": \"\\gls{GBM}\",\n",
    "    \"(Ex)\": \" (Ex)\",\n",
    "    \"(Best)\": \" (Best)\",\n",
    "    \"(Classical)\": \" (Classical)\",\n",
    "    \"(Classical-Size)\": \" (Classical, Size)\",\n",
    "    \"Rev_\": \"Rev. \",\n",
    "    \"Trade_Size\": \"Trade Size\",\n",
    "    \"Depth\": \"Depth\",\n",
    "    \"->\": \" $\\\\to$ \",\n",
    "    \"Lr\": \"\\gls{LR}\",\n",
    "    \"Emo\": \"\\gls{EMO}\",\n",
    "    \"Clnv\": \"\\gls{CLNV}\",\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    \"_\": \"$\\_\",\n",
    "    \"Gbm\": \"\\gls{GBM}\",\n",
    "}\n",
    "\n",
    "LUT_INDEX = {\n",
    "    \"OPTION_TYPE\": \"Option Type\",\n",
    "    \"issue_type\": \"Security Type\",\n",
    "    \"TRADE_SIZE_binned\": \"Trade Size\",\n",
    "    \"year_binned\": \"Year\",\n",
    "    \"ttm_binned\": \"Time to Maturity\",\n",
    "    \"myn_binned\": \"Moneyness\",\n",
    "    \"prox_q_binned\": \"Location to Quote\",\n",
    "    \"all\": \"All trades\",\n",
    "}\n",
    "\n",
    "\n",
    "def cell_str(x):\n",
    "    x = x.title()\n",
    "    for orig, sub in LUT.items():\n",
    "        x = x.replace(orig, sub)\n",
    "    # title-case everything\n",
    "    return x\n",
    "\n",
    "\n",
    "def highlight_max(s, props=\"\"):\n",
    "    return np.where(s == np.nanmax(s.values), props, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_tex_style(styler, caption, label, bold_axis=1):\n",
    "    res = styler.set_caption(caption)\n",
    "\n",
    "    res = (\n",
    "        res.apply(highlight_max, props=\"font-weight:bold;\", axis=bold_axis)\n",
    "        .format(precision=4, decimal=\".\", thousands=\",\", escape=False, hyperlinks=None)\n",
    "        .format_index(cell_str, axis=0)\n",
    "        .format_index(cell_str, axis=1)\n",
    "        .to_latex(\n",
    "            f\"{label}.tex\",\n",
    "            siunitx=True,\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            clines=\"skip-last;data\",\n",
    "            label=\"tab:\" + label,\n",
    "            caption=caption,\n",
    "            convert_css=True,\n",
    "        )\n",
    "    )\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = results_data.columns.tolist()\n",
    "criterions = list(LUT_INDEX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unclassified by method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclassified = (\n",
    "    (results_data[results_data == 0.0].count(axis=0) / len(results_data.index))\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name=\"unclassified\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclassified.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(f\"{KEY}-unclassified-long\", \"{key}-unclassified-short\"),\n",
    "    label=f\"{KEY.lower()}-unclassfied\",\n",
    "    bold_axis=0,\n",
    ")\n",
    "unclassified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in unclassified\n",
    "\n",
    "Unclassified are `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# replace 0 -> nan -> [-1,1]\n",
    "results_data.replace(0, np.nan)\n",
    "filler = pd.DataFrame(\n",
    "    rng.choice(a=[-1, 1], size=results_data.shape),\n",
    "    index=results_data.index,\n",
    "    columns=results_data.columns,\n",
    ")\n",
    "results_data.fillna(filler, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3vzAVSc_DfD"
   },
   "source": [
    "### Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3evMG-KVA2eX"
   },
   "outputs": [],
   "source": [
    "# prepare columns for printing\n",
    "X_print[\"ttm\"] = (\n",
    "    X_print[\"EXPIRATION\"].dt.to_period(\"M\")\n",
    "    - X_print[\"QUOTE_DATETIME\"].dt.to_period(\"M\")\n",
    ").apply(lambda x: x.n)\n",
    "\n",
    "X_print[\"year\"] = X_print[\"QUOTE_DATETIME\"].dt.year\n",
    "\n",
    "bins_tradesize = [-1, 1, 3, 5, 11, np.inf]\n",
    "trade_size_labels = [\"(0,1]\", \"(1,3]\", \"(3,5]\", \"(5,11]\", \">11\"]\n",
    "X_print[\"TRADE_SIZE_binned\"] = pd.cut(\n",
    "    X_print[\"TRADE_SIZE\"], bins_tradesize, labels=trade_size_labels\n",
    ")\n",
    "\n",
    "# p. 38\n",
    "bins_years = [2004, 2007, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "year_labels = [\n",
    "    \"2005-2007\",\n",
    "    \"2008-2010\",\n",
    "    \"2011\",\n",
    "    \"2012\",\n",
    "    \"2013\",\n",
    "    \"2014\",\n",
    "    \"2015\",\n",
    "    \"2016\",\n",
    "    \"2017\",\n",
    "]\n",
    "X_print[\"year_binned\"] = pd.cut(X_print[\"year\"], bins_years, labels=year_labels)\n",
    "\n",
    "# p. 37\n",
    "bins_ttm = [-1, 1, 2, 3, 6, 12, np.inf]\n",
    "ttm_labels = [\n",
    "    \"<= 1\",\n",
    "    \"(1-2]\",\n",
    "    \"(2-3]\",\n",
    "    \"(3-6]\",\n",
    "    \"(6-12]\",\n",
    "    \"> 12\",\n",
    "]\n",
    "X_print[\"ttm_binned\"] = pd.cut(X_print[\"ttm\"], bins_ttm, labels=ttm_labels)\n",
    "\n",
    "# Security type\n",
    "# see 3.0a-mb-explanatory-data-analysis.ipynb\n",
    "X_print[\"issue_type\"] = X_print[\"issue_type\"].map(\n",
    "    {\n",
    "        \"0\": \"Stock option\",\n",
    "        \"A\": \"Index option\",\n",
    "        \"7\": \"Others\",\n",
    "        \"F\": \"Others\",\n",
    "        \"%\": \"Others\",\n",
    "        \" \": \"Others\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Moneyness p. 38\n",
    "bins_myn = [-1, 0.7, 0.9, 1.1, 1.3, np.inf]\n",
    "myn_labels = [\n",
    "    \"<= 0.7 c\",\n",
    "    \"(0.7-0.9]\",\n",
    "    \"(0.9-1.1]\",\n",
    "    \"(1.1-1.3]\",\n",
    "    \"> 1.3\",\n",
    "]\n",
    "X_print[\"myn_binned\"] = pd.cut(X_print[\"myn\"], bins_myn, labels=myn_labels)\n",
    "\n",
    "# mid p. 31 + extra category for unknowns\n",
    "ask = X_print[\"ask_ex\"]\n",
    "bid = X_print[\"bid_ex\"]\n",
    "trade_price = X_print[\"TRADE_PRICE\"]\n",
    "\n",
    "mid = np.where(ask >= bid, (ask + bid) * 0.5, np.nan)\n",
    "\n",
    "prox_quotes = np.where(\n",
    "    trade_price == mid,\n",
    "    0,  # at mid\n",
    "    np.where(\n",
    "        (ask < trade_price) & (trade_price < bid),\n",
    "        1,  # inside\n",
    "        np.where(\n",
    "            (trade_price == bid) | (ask == trade_price),\n",
    "            2,  # at quotes\n",
    "            np.where((trade_price < bid) | (ask > trade_price), 3, 4),\n",
    "        ),\n",
    "    ),\n",
    ")  # outside + unclassifiable\n",
    "\n",
    "bins_prox = [-np.inf, 0, 1, 2, 3, 4]\n",
    "prox_labels = [\n",
    "    \"at mid\",\n",
    "    \"inside\",\n",
    "    \"at quotes\",\n",
    "    \"outside\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "X_print[\"prox_q_binned\"] = pd.cut(prox_quotes, bins_prox, labels=prox_labels)\n",
    "X_print[\"mid\"] = mid\n",
    "\n",
    "# clean up empty buckets, as it causes empty grouping in result set generation\n",
    "X_print[\"year_binned\"] = X_print[\"year_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"myn_binned\"] = X_print[\"myn_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"ttm_binned\"] = X_print[\"ttm_binned\"].cat.remove_unused_categories()\n",
    "X_print[\"prox_q_binned\"] = X_print[\"prox_q_binned\"].cat.remove_unused_categories()\n",
    "\n",
    "X_print[\"all\"] = \"all\"\n",
    "\n",
    "X_print.drop(\n",
    "    columns=[\n",
    "        \"EXPIRATION\",\n",
    "        \"QUOTE_DATETIME\",\n",
    "        \"TRADE_SIZE\",\n",
    "        \"ttm\",\n",
    "        \"myn\",\n",
    "        \"ask_ex\",\n",
    "        \"bid_ex\",\n",
    "        \"year\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_print = pd.concat([X_print, results_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_print.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Find better approach\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "for criterion in tqdm(criterions):\n",
    "    results = []\n",
    "    for classifier in tqdm(classifiers):\n",
    "        res = (\n",
    "            X_print.groupby([criterion])[[\"buy_sell\", classifier]]\n",
    "            .apply(\n",
    "                lambda x: accuracy_score(x[\"buy_sell\"].astype(\"int8\"), x[classifier])\n",
    "            )\n",
    "            .mul(100)\n",
    "            .rename(classifier)\n",
    "        )\n",
    "        #         acc_tot = accuracy_score(\n",
    "        #             X_print[\"buy_sell\"].astype(\"int8\"), X_print[classifier]\n",
    "        #         )\n",
    "\n",
    "        #         res.loc[\"all\"] = acc_tot * 100\n",
    "\n",
    "        res.index.name = LUT_INDEX.get(criterion)\n",
    "        results.append(res)\n",
    "\n",
    "    # save aggregated results\n",
    "    result_df = pd.concat(results, axis=1).T\n",
    "    result_df.style.pipe(\n",
    "        set_tex_style,\n",
    "        caption=(f\"long-tbd\", \"short-tbd\"),\n",
    "        label=f\"{KEY.lower()}-{criterion.lower()}\",\n",
    "    )\n",
    "\n",
    "    # store all result sets for later use\n",
    "    result_dfs.append(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.concat(result_dfs, axis=1, keys=list(LUT_INDEX.values())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(\"master-long\", \"master-short\"),\n",
    "    label=f\"{KEY}-master\",\n",
    "    bold_axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Spread 🚧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_dfs = []\n",
    "\n",
    "\n",
    "def stats(x, classifier):\n",
    "\n",
    "    nom = effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"nominal\")\n",
    "    rel = (\n",
    "        effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"relative\")\n",
    "        * 100\n",
    "    )\n",
    "\n",
    "    # eff_spread_pred = effective_spread(x[classifier], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"none\")\n",
    "    # eff_spread_true = effective_spread(x[\"buy_sell\"], x[\"TRADE_PRICE\"], x[\"mid\"], mode=\"none\")\n",
    "    # wilcoxon_res  = wilcoxon(eff_spread_pred, eff_spread_true, nan_policy=\"omit\", zero_method=\"zsplit\")\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"nominal\": nom,\n",
    "            \"rel\": rel,\n",
    "            # 'statistic':wilcoxon_res.statistic,\n",
    "            # 'pvalue':wilcoxon_res.pvalue\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "for criterion in tqdm(criterions):\n",
    "    results = []\n",
    "\n",
    "    for classifier in tqdm(classifiers):\n",
    "        res = X_print.groupby([criterion])[\n",
    "            [\"TRADE_PRICE\", \"mid\", classifier, \"buy_sell\"]\n",
    "        ].apply(stats, classifier)\n",
    "        results.append(res)\n",
    "\n",
    "    # save aggregated results\n",
    "    result_df = pd.concat(results, axis=1, keys=classifiers).T\n",
    "    result_df.style.pipe(\n",
    "        set_tex_style,\n",
    "        caption=(f\"long-tbd\", \"short-tbd\"),\n",
    "        label=f\"{KEY.lower()}-{criterion.lower()}-eff-spread\",\n",
    "    )\n",
    "\n",
    "    # store all result sets for later use\n",
    "    eff_dfs.append(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread = pd.concat(eff_dfs, axis=1, keys=LUT_INDEX.values()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_eff_spread.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(\"master-short\", \"master-long\"),\n",
    "    label=f\"{KEY}-master-eff-spread\",\n",
    "    bold_axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in Parenthesis 🅾️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = master[\n",
    "    [\n",
    "        (\"classical\", \"quote(ex)\"),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "        (\n",
    "            \"classical\",\n",
    "            \"trade_size(ex)->quote(best)->depth(best)->quote(ex)->depth(ex)->rev_tick(all)\",\n",
    "        ),\n",
    "    ]\n",
    "]\n",
    "revised = master[\n",
    "    [(\"gbm\", \"gbm(classical)\"), (\"gbm\", \"gbm(classical-size)\"), (\"gbm\", \"gbm(ml)\")]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(revised: pd.DataFrame, base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate print layout like in Grauer et al.\n",
    "\n",
    "    https://tex.stackexchange.com/questions/430283/table-with-numbers-in-parentheses-in-siunitx/430290#430290\n",
    "\n",
    "    # see p. https://texdoc.org/serve/siunitx/0\n",
    "    \"\"\"\n",
    "    # first, second layer of colum index\n",
    "    c_1 = revised.columns.get_level_values(1)\n",
    "    c_2 = [\"nom\"]\n",
    "    midx = pd.MultiIndex.from_product([c_1, c_2])\n",
    "\n",
    "    # copy data from revised add as (column, \"nom\")\n",
    "    combo = pd.DataFrame(revised.values, index=revised.index, columns=midx)\n",
    "\n",
    "    for i, mul_col in enumerate(combo.columns):\n",
    "\n",
    "        combo[(mul_col[0], \"pm\")] = (combo[mul_col] - base.iloc[:, i]).round(2)\n",
    "        combo.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    return combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = combine_results(revised, base)\n",
    "\n",
    "diff.style.to_latex(\n",
    "    f\"diff-{KEY}.tex\",\n",
    "    siunitx=True,\n",
    "    position_float=\"centering\",\n",
    "    hrules=True,\n",
    "    clines=\"skip-last;data\",\n",
    "    label=f\"tab:diff-{KEY}\",\n",
    "    caption=(f\"long-diff-{KEY}\", f\"short-diff-{KEY}\"),\n",
    "    convert_css=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8ea8b642289b706932f10b33ee389827410dbaef0ce2c5bf73615e8d3267d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
