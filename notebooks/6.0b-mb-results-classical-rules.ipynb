{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from otc.features.build_features import features_classical_size\n",
    "from otc.models.classical_classifier import ClassicalClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set here globally\n",
    "seed = 42\n",
    "\n",
    "exchange = \"ise\" # \"cboe\"\n",
    "models = \"classical\"\n",
    "subset = \"val\" # \"test\" # \"all\" # \"test\"\n",
    "strategy =  \"supervised\" # \"transfer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key used for files and artefacts\n",
    "key = f\"{exchange}_{models}_{strategy}_{subset}\"\n",
    "\n",
    "dataset = f\"fbv/thesis/{exchange}_{strategy}_none:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "# load unscaled data\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    *features_classical_size,\n",
    "    \"buy_sell\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset == \"all\":\n",
    "    train = pd.read_parquet(\n",
    "        Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    val = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    test = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "    data = pd.concat([train, val, test])\n",
    "    del train, val, test\n",
    "\n",
    "elif subset == \"val\":\n",
    "    data = pd.read_parquet(\n",
    "        Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\", columns=columns\n",
    "    )    \n",
    "    \n",
    "elif subset == \"test\":\n",
    "    data = pd.read_parquet(\n",
    "        Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\", columns=columns\n",
    "    )\n",
    "\n",
    "y_test = data[\"buy_sell\"].astype(\"int8\")\n",
    "X_test = data.drop(columns=\"buy_sell\")\n",
    "\n",
    "del data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [ #classical\n",
    "    [(\"tick\", \"all\")],\n",
    "    [(\"tick\", \"ex\")],\n",
    "    [(\"tick\", \"all\"), (\"tick\", \"ex\")], \n",
    "    [(\"tick\", \"ex\"), (\"tick\", \"all\")], \n",
    "    [(\"rev_tick\", \"all\")],\n",
    "    [(\"rev_tick\", \"ex\")],\n",
    "    [(\"rev_tick\", \"all\"), (\"rev_tick\", \"ex\")], \n",
    "    [(\"rev_tick\", \"ex\"), (\"rev_tick\", \"all\")], \n",
    "    [(\"quote\", \"best\")],\n",
    "    [(\"quote\", \"ex\")],\n",
    "    [(\"quote\", \"best\"), (\"quote\", \"ex\")],  # murjajev\n",
    "    [(\"quote\", \"ex\"), (\"quote\", \"best\")], \n",
    "    [(\"lr\", \"ex\")],\n",
    "    [(\"lr\", \"best\")],\n",
    "    [(\"lr\", \"ex\"), (\"lr\", \"best\")],\n",
    "    [(\"lr\", \"best\"), (\"lr\", \"ex\")],\n",
    "    [(\"rev_lr\", \"ex\")],\n",
    "    [(\"rev_lr\", \"best\")],\n",
    "    [(\"rev_lr\", \"ex\"), (\"rev_lr\", \"best\")],\n",
    "    [(\"rev_lr\", \"best\"), (\"rev_lr\", \"ex\")],    \n",
    "    [(\"emo\", \"ex\")],\n",
    "    [(\"emo\", \"best\")],\n",
    "    [(\"emo\", \"ex\"), (\"emo\", \"best\")],\n",
    "    [(\"emo\", \"best\"), (\"emo\", \"ex\")],       \n",
    "    [(\"rev_emo\", \"ex\")],\n",
    "    [(\"rev_emo\", \"best\")],\n",
    "    [(\"rev_emo\", \"ex\"), (\"rev_emo\", \"best\")],\n",
    "    [(\"rev_emo\", \"best\"), (\"rev_emo\", \"ex\")],   \n",
    "    [(\"clnv\", \"ex\")],\n",
    "    [(\"clnv\", \"best\")],\n",
    "    [(\"clnv\", \"ex\"), (\"clnv\", \"best\")],\n",
    "    [(\"clnv\", \"best\"), (\"clnv\", \"ex\")],   \n",
    "    [(\"rev_clnv\", \"ex\")],\n",
    "    [(\"rev_clnv\", \"best\")],\n",
    "    [(\"rev_clnv\", \"ex\"), (\"rev_clnv\", \"best\")],\n",
    "    [(\"rev_clnv\", \"best\"), (\"rev_clnv\", \"ex\")],\n",
    "    [ # advanced rules\n",
    "        (\"trade_size\", \"ex\"),\n",
    "        (\"quote\", \"best\"),\n",
    "        (\"quote\", \"ex\"),\n",
    "    ], \n",
    "    [(\"trade_size\", \"ex\"), (\"rev_lr\", \"best\")],    \n",
    "    [\n",
    "        (\"trade_size\", \"ex\"),\n",
    "        (\"quote\", \"best\"),\n",
    "        (\"quote\", \"ex\"),\n",
    "        (\"depth\", \"best\"),\n",
    "        (\"depth\", \"ex\"),\n",
    "        (\"rev_tick\", \"all\"),\n",
    "    ],  # p. 13 grauer\n",
    "]\n",
    "\n",
    "# generate names for array\n",
    "names = []\n",
    "for r in tqdm(rules):\n",
    "    name = \"->\".join(\"%s(%s)\" % tup for tup in r)\n",
    "    names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for rule in tqdm(rules):\n",
    "    clf = ClassicalClassifier(layers=rule, random_state=seed, strategy=\"random\")\n",
    "    # fit is only used to set sklearn attributes, no leakage\n",
    "    clf.fit(X=X_test.head(5), y=y_test.head(5))\n",
    "    result = clf.predict(X_test).astype(int)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(dict(zip(names, results)), index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "output_path = (\n",
    "    f\"gs://thesis-bucket-option-trade-classification/data/results/{key}.parquet\"\n",
    ")\n",
    "results.to_parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Log the artifact to save it as an output of this run\n",
    "result_set = wandb.Artifact(name=key, type=\"results\")\n",
    "result_set.add_reference(output_path, name=\"results\")\n",
    "run.log_artifact(result_set)\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of benchmarkðŸ§®\n",
    "run on `subset = val`, `exchange = ise`, and `strategy = random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for name in tqdm(names):\n",
    "    scores.append((name,accuracy_score(y_test, results[name])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)\n",
    "scores_df = scores.sort_values(by=1, ascending=False).set_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LUT = {\n",
    "    \"Rev_Tick\": \"\\\\operatorname{rtick}\",\n",
    "    \"Rev_Lr\": \"\\\\operatorname{rlr}\",\n",
    "    \"Rev_Emo\": \"\\\\operatorname{remo}\",\n",
    "    \"Rev_Clnv\": \"\\\\operatorname{rclnv}\",\n",
    "    \"Tick\": \"\\operatorname{tick}\",\n",
    "    \"Quote\": \"\\operatorname{quote}\",\n",
    "    \"(Ex)\": \"_{\\\\text{ex}}\",\n",
    "    \"(Best)\": \"_{\\\\text{nbbo}}\",\n",
    "    \"(All)\": \"_{\\\\text{all}}\",\n",
    "    \"Depth\": \"\\\\operatorname{depth}\",\n",
    "    \"Trade_Size\": \"\\operatorname{tsize}\",\n",
    "    \"Lr\": \"\\\\operatorname{lr}\",\n",
    "    \"Emo\": \"\\\\operatorname{emo}\",\n",
    "    \"Clnv\": \"\\\\operatorname{clnv}\",\n",
    "    \"->\": \" \\\\to \",\n",
    "}\n",
    "\n",
    "\n",
    "def cell_str(x):\n",
    "    x = x.title()\n",
    "    for orig, sub in LUT.items():\n",
    "        x = x.replace(orig, sub)\n",
    "    # title-case everything\n",
    "    return \"$\"+x+\"$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_tex_style(styler, caption, label, bold_axis=1):\n",
    "    res = styler.set_caption(caption)\n",
    "\n",
    "    res = (\n",
    "        res\n",
    "        .format(precision=4, decimal=\".\", thousands=\",\", escape=False, hyperlinks=None)\n",
    "        .format_index(cell_str, axis=0)\n",
    "        .to_latex(\n",
    "            f\"../reports/Content/{label}.tex\",\n",
    "            siunitx=True,\n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            clines=\"skip-last;data\",\n",
    "            label=\"tab:\" + label,\n",
    "            caption=caption,\n",
    "        )\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_df.style.pipe(\n",
    "    set_tex_style,\n",
    "    caption=(f\"long-hyperparam-classical-{key}\", f\"short-hyperparam-classical-{key}\"),\n",
    "    label=f\"tab:hyperparam-classical-{key}\",\n",
    "    bold_axis=0,\n",
    ")\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtwo",
   "language": "python",
   "name": "torchtwo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
