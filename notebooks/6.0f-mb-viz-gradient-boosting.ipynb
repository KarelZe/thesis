{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from otc.features.build_features import (\n",
    "    features_categorical,\n",
    "    features_classical,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set globally here\n",
    "EXCHANGE = \"ise\"  # \"cboe\"\n",
    "STRATEGY = \"supervised\"  # \"transfer\"\n",
    "SUBSET = \"test\"  # \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# key used for files and artefacts\n",
    "key = f\"{EXCHANGE}_gbm_{STRATEGY}_{SUBSET}_viz\"\n",
    "dataset = f\"fbv/thesis/{EXCHANGE}_{STRATEGY}_log_standardized_clipped:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_7CKpqcONOy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set project name. Required to access files and artefacts\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "ah1dofx3TdDj",
    "outputId": "0bd418dd-6b5d-4fa8-9142-89b22d255e2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\")\n",
    "y_train = train[\"buy_sell\"]\n",
    "X_train = train.drop(columns=\"buy_sell\")\n",
    "timestamp_train = np.linspace(0, 1, len(y_train))\n",
    "weights_exp_train = np.geomspace(0.001, 1, num=len(y_train))\n",
    "\n",
    "cat_features_sub = [\n",
    "    tup[0] for tup in features_categorical if tup[0] in features_classical\n",
    "]\n",
    "\n",
    "train_pool_uni = Pool(\n",
    "    data=X_train.loc[:, features_classical],\n",
    "    label=y_train,\n",
    "    cat_features=cat_features_sub,\n",
    "    timestamp=timestamp_train,\n",
    ")\n",
    "\n",
    "train_pool_exp = Pool(\n",
    "    data=X_train.loc[:, features_classical],\n",
    "    label=y_train,\n",
    "    cat_features=cat_features_sub,\n",
    "    timestamp=timestamp_train,\n",
    "    weight=weights_exp_train,\n",
    ")\n",
    "\n",
    "val = pd.read_parquet(Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\")\n",
    "y_val = val[\"buy_sell\"]\n",
    "X_val = val.drop(columns=\"buy_sell\")\n",
    "timestamp_val = np.linspace(0, 1, len(y_val))\n",
    "\n",
    "val_pool_uni = Pool(\n",
    "    data=X_val.loc[:, features_classical],\n",
    "    label=y_val,\n",
    "    cat_features=cat_features_sub,\n",
    "    timestamp=timestamp_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Of Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs_shared = {\n",
    "    \"logging_level\": \"Silent\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"random_seed\": 42,\n",
    "    \"eval_metric\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "settings = [\n",
    "    {\"iterations\": 5},\n",
    "    {\"iterations\": 100},\n",
    "    {\"iterations\": 1000},\n",
    "    {\"iterations\": 2000},\n",
    "]\n",
    "[setting.update(kwargs_shared) for setting in settings]\n",
    "\n",
    "results = []\n",
    "\n",
    "for setting in tqdm(settings):\n",
    "    clf = CatBoostClassifier(**setting)\n",
    "    clf.fit(train_pool_uni, eval_set=val_pool_uni)\n",
    "\n",
    "    proba_predictions = clf.predict_proba(val_pool_uni)\n",
    "    positive_class_prob = proba_predictions[:, 1]\n",
    "    y_val_mapped = (y_val + 1) // 2\n",
    "\n",
    "    result = -np.log(positive_class_prob) * y_val_mapped - np.log(\n",
    "        1 - positive_class_prob\n",
    "    ) * (1 - y_val_mapped)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = pd.concat(results, axis=1, keys=[\"iter_5\", \"iter_100\", \"iter_1000\", \"iter_2000\"])\n",
    "key = f\"{EXCHANGE}_gbm_{STRATEGY}_{SUBSET}_viz_dist_loss\"\n",
    "\n",
    "output_path = f\"gs://thesis-bucket-option-trade-classification/data/results/{key}-viz-dist-loss.parquet\"\n",
    "dfs.columns = [\"_\".join(col).rstrip(\"_\") for col in dfs.columns.values]\n",
    "dfs.to_parquet(output_path)\n",
    "\n",
    "# Log the artifact to save it as an output of this run\n",
    "result_set = wandb.Artifact(name=key, type=\"results\")\n",
    "result_set.add_reference(output_path, name=\"results\")\n",
    "run.log_artifact(result_set)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMIOV1jA_ImH"
   },
   "source": [
    "## CatBoost üêà‚Äç‚¨õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_depth = {\"depth\": 12}\n",
    "\n",
    "\n",
    "kwargs_earl_stopping = {\n",
    "    \"early_stopping_rounds\": 100,\n",
    "}\n",
    "\n",
    "kwargs_growth_strategy = {\n",
    "    \"grow_policy\": \"Lossguide\",\n",
    "}\n",
    "\n",
    "\n",
    "kwargs_border_count = {\n",
    "    \"border_count\": 254,\n",
    "}\n",
    "\n",
    "kwargs_shared = {\n",
    "    \"iterations\": 2000,\n",
    "    \"logging_level\": \"Silent\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"random_seed\": 42,\n",
    "    \"eval_metric\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "\n",
    "# complete config\n",
    "settings = [\n",
    "    {},\n",
    "    kwargs_depth,\n",
    "    kwargs_earl_stopping,\n",
    "    kwargs_border_count,\n",
    "    kwargs_growth_strategy,\n",
    "    {},\n",
    "]\n",
    "[setting.update(kwargs_shared) for setting in settings]\n",
    "# set pools\n",
    "pools = [\n",
    "    train_pool_uni,\n",
    "    train_pool_uni,\n",
    "    train_pool_uni,\n",
    "    train_pool_uni,\n",
    "    train_pool_uni,\n",
    "    train_pool_exp,\n",
    "]\n",
    "identifier = [\n",
    "    \"default\",\n",
    "    \"depth\",\n",
    "    \"early_stopping\",\n",
    "    \"border_count\",\n",
    "    \"grow_policy\",\n",
    "    \"exp_weighting\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i, setting in enumerate(tqdm(settings)):\n",
    "    clf = CatBoostClassifier(**setting)\n",
    "    clf.fit(pools[i], eval_set=val_pool_uni)\n",
    "    result = clf.get_evals_result()\n",
    "    results.append({identifier[i]: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for result in results:\n",
    "    key = list(result.keys())[0]\n",
    "\n",
    "    learn_acc = result[key][\"learn\"][\"Accuracy\"]\n",
    "    learn_log = result[key][\"learn\"][\"Logloss\"]\n",
    "    val_acc = result[key][\"validation\"][\"Accuracy\"]\n",
    "    val_log = result[key][\"validation\"][\"Logloss\"]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"learn_acc\": learn_acc,\n",
    "            \"learn_log\": learn_log,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_log\": val_log,\n",
    "        }\n",
    "    )\n",
    "    df.name = key\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs, axis=1, keys=identifier)\n",
    "\n",
    "output_path = f\"gs://thesis-bucket-option-trade-classification/data/results/{key}-viz-losses.parquet\"\n",
    "dfs.columns = [\"_\".join(col).rstrip(\"_\") for col in dfs.columns.values]\n",
    "dfs.to_parquet(output_path)\n",
    "\n",
    "# Log the artifact to save it as an output of this run\n",
    "result_set = wandb.Artifact(name=key, type=\"results\")\n",
    "result_set.add_reference(output_path, name=\"results\")\n",
    "run.log_artifact(result_set)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
