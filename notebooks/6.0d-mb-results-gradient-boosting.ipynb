{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set globally here\n",
    "exchange = \"ise\"  # \"cboe\"\n",
    "strategy = \"supervised\"  # \"transfer\"\n",
    "subset = \"test\"  # \"test\"\n",
    "\n",
    "retrain = True\n",
    "\n",
    "# ise, supervised\n",
    "models = [\n",
    "    (\"classical\", \"17malsep_CatBoostClassifier_default.cbm:v7\"),\n",
    "    (\"classical-size\", \"3laathab_CatBoostClassifier_default.cbm:v7\"),\n",
    "    (\"ml\", \"2a9iqsn0_CatBoostClassifier_default.cbm:v4\"),\n",
    "    (\"semi-classical\", \"3dtuffae_CatBoostClassifier_default.cbm:v7\"),\n",
    "    (\"semi-classical-size\", \"2vnqg1sj_CatBoostClassifier_default.cbm:v8\"),\n",
    "]\n",
    "\n",
    "# cboe, supervised, semi-sueprvised\n",
    "# models = [\n",
    "#     (\"classical\", \"30sl6vqf_CatBoostClassifier_default.cbm:v5\"),\n",
    "#     (\"classical-size\", \"2w28suql_CatBoostClassifier_default.cbm:v7\"),\n",
    "#     (\"ml\", \"2zglfgfb_CatBoostClassifier_default.cbm:v4\"),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key used for files and artefacts\n",
    "key = f\"{exchange}_gbm_{strategy}_{subset}\"\n",
    "dataset = f\"fbv/thesis/{exchange}_{strategy}_log_standardized:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFMHPh-nTcSI"
   },
   "outputs": [],
   "source": [
    "features_option = [\n",
    "    \"STRK_PRC\",\n",
    "    \"ttm\",\n",
    "    \"option_type\",\n",
    "    \"issue_type\",\n",
    "    \"root\",\n",
    "    \"myn\",\n",
    "    \"day_vol\",\n",
    "]\n",
    "\n",
    "# https://github.com/KarelZe/thesis/blob/main/notebooks/\n",
    "# 3.0a-mb-explanatory_data_analysis.ipynb\n",
    "features_categorical = [\n",
    "    (\"root\", 8667),\n",
    "    (\"option_type\", 2),\n",
    "    (\"issue_type\", 6),\n",
    "]\n",
    "\n",
    "features_classical = [\n",
    "    \"TRADE_PRICE\",\n",
    "    \"bid_ex\",\n",
    "    \"ask_ex\",\n",
    "    \"BEST_ASK\",\n",
    "    \"BEST_BID\",\n",
    "    \"price_ex_lag\",\n",
    "    \"price_ex_lead\",\n",
    "    \"price_all_lag\",\n",
    "    \"price_all_lead\",\n",
    "    \"chg_ex_lead\",\n",
    "    \"chg_ex_lag\",\n",
    "    \"chg_all_lead\",\n",
    "    \"chg_all_lag\",\n",
    "    \"prox_ex\",\n",
    "    \"prox_best\",\n",
    "]\n",
    "\n",
    "features_size = [\n",
    "    \"bid_ask_size_ratio_ex\",\n",
    "    \"rel_bid_size_ex\",\n",
    "    \"rel_ask_size_ex\",\n",
    "    \"TRADE_SIZE\",\n",
    "    \"bid_size_ex\",\n",
    "    \"ask_size_ex\",\n",
    "    \"depth_ex\",\n",
    "]\n",
    "\n",
    "features_classical_size = [\n",
    "    *features_classical,\n",
    "    *features_size,\n",
    "]\n",
    "\n",
    "features_ml = [*features_classical_size, *features_option]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_7CKpqcONOy"
   },
   "outputs": [],
   "source": [
    "os.environ[\"GCLOUD_PROJECT\"] = \"flowing-mantis-239216\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "ah1dofx3TdDj",
    "outputId": "0bd418dd-6b5d-4fa8-9142-89b22d255e2f"
   },
   "outputs": [],
   "source": [
    "# see https://wandb.ai/fbv/thesis/runs/kwlaw02g/overview?workspace=user-karelze\n",
    "run = wandb.init(project=\"thesis\", entity=\"fbv\")\n",
    "\n",
    "artifact = run.use_artifact(dataset)\n",
    "data_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmXtH-PEqyQE"
   },
   "outputs": [],
   "source": [
    "if subset == \"all\":\n",
    "    train = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\")\n",
    "    val = pd.read_parquet(Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\")\n",
    "    test = pd.read_parquet(Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\")\n",
    "    data = pd.concat([train, val, test])\n",
    "\n",
    "elif subset == \"test\":\n",
    "    data = pd.read_parquet(Path(data_dir, \"test_set.parquet\"), engine=\"fastparquet\")\n",
    "\n",
    "y_test = data[\"buy_sell\"]\n",
    "X_test = data.drop(columns=\"buy_sell\")\n",
    "timestamp_test = np.linspace(0, 1, len(y_test))\n",
    "\n",
    "\n",
    "if retrain:\n",
    "    train = pd.read_parquet(Path(data_dir, \"train_set.parquet\"), engine=\"fastparquet\")\n",
    "    val = pd.read_parquet(Path(data_dir, \"val_set.parquet\"), engine=\"fastparquet\")\n",
    "    retrain_data = pd.concat([train, val])\n",
    "    y_retrain = retrain_data[\"buy_sell\"]\n",
    "    X_retrain = retrain_data.drop(columns=\"buy_sell\")\n",
    "\n",
    "    weight_retrain = np.geomspace(0.001, 1, num=len(y_retrain))\n",
    "    timestamp_retrain = np.linspace(0, 1, len(y_retrain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMIOV1jA_ImH"
   },
   "source": [
    "## CatBoost Baseline üêà‚Äç‚¨õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "feature_map = {\n",
    "    \"classical\": features_classical,\n",
    "    \"classical-size\": features_classical_size,\n",
    "    \"ml\": features_ml,\n",
    "    \"semi-classical\": features_classical,\n",
    "    \"semi-classical-size\": features_classical_size,\n",
    "    \"semi-ml\": features_ml,\n",
    "}\n",
    "\n",
    "for feature_str, model in tqdm(models):\n",
    "\n",
    "    model_name = model.split(\"/\")[-1].split(\":\")[0]\n",
    "\n",
    "    artifact = run.use_artifact(model)\n",
    "    model_dir = artifact.download()\n",
    "\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(fname=Path(model_dir, model_name))\n",
    "\n",
    "    fs = feature_map.get(feature_str)\n",
    "    # filter categorical features that are in subset and get cardinality\n",
    "    cat_features_sub = [tup[0] for tup in features_categorical if tup[0] in fs]\n",
    "\n",
    "    test_pool = Pool(\n",
    "        data=X_test.loc[:, fs],\n",
    "        label=y_test,\n",
    "        cat_features=cat_features_sub,\n",
    "        timestamp=timestamp_test,\n",
    "    )\n",
    "    result = pd.Series(\n",
    "        data=model.predict(test_pool),\n",
    "        index=X_test.index,\n",
    "        name=f\"gbm({feature_str})\",\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "    # retrain on training and validation set\n",
    "    if retrain and not feature_str.startswith(\"semi\")::\n",
    "        retrain_pool = Pool(\n",
    "            data=X_retrain.loc[:, fs],\n",
    "            label=y_retrain,\n",
    "            cat_features=cat_features_sub,\n",
    "            weight=weight_retrain,\n",
    "            timestamp=timestamp_retrain,\n",
    "        )\n",
    "\n",
    "        model.fit(retrain_pool, verbose=False)\n",
    "        result = pd.Series(\n",
    "            data=model.predict(test_pool),\n",
    "            index=X_test.index,\n",
    "            name=f\"gbm({feature_str}-retraining)\",\n",
    "        )\n",
    "        results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(results, axis=1)\n",
    "output_path = (\n",
    "    f\"gs://thesis-bucket-option-trade-classification/data/results/{key}.parquet\"\n",
    ")\n",
    "results.to_parquet(output_path)\n",
    "\n",
    "# Log the artifact to save it as an output of this run\n",
    "result_set = wandb.Artifact(name=key, type=\"results\")\n",
    "result_set.add_reference(output_path, name=\"results\")\n",
    "run.log_artifact(result_set)\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
