{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFtjnsNO8jt9f3T0X8Y3eP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarelZe/thesis/blob/speedy-transformer/05_tab_transformer_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dK3j1SlAQH5r"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of a TabTransformer.\n",
        "Based on paper:\n",
        "https://arxiv.org/abs/2012.06678\n",
        "Implementation adapted from: https://github.com/lucidrains/tab-transformer-pytorch\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Any, Callable, cast\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import einsum, nn\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class GeGLU(nn.Module):\n",
        "    r\"\"\"\n",
        "    Implementation of the GeGLU activation function.\n",
        "    Given by:\n",
        "    $\\operatorname{GeGLU}(x, W, V, b, c)=\\operatorname{GELU}(x W+b) \\otimes(x V+c)$\n",
        "    Proposed in https://arxiv.org/pdf/2002.05202v1.pdf.\n",
        "    Args:\n",
        "        nn (torch.Tensor): module\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of GeGlU activation.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-1] % 2 == 0\n",
        "        x, gates = x.chunk(2, dim=-1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "\n",
        "class ReGLU(nn.Module):\n",
        "    r\"\"\"\n",
        "    Implementation of the GeGLU activation function.\n",
        "    Given by:\n",
        "    Proposed in https://arxiv.org/pdf/2002.05202v1.pdf.\n",
        "    Args:\n",
        "        nn (torch.Tensor): module\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of GeGlU activation.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-1] % 2 == 0\n",
        "        x, gates = x.chunk(2, dim=-1)\n",
        "        return x * F.relu(gates)\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of residual connections.\n",
        "    Args:\n",
        "        nn (nn.Module): module\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fn: nn.Module):\n",
        "        \"\"\"\n",
        "        Residual connection.\n",
        "        Args:\n",
        "            fn (nn.Module): network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of residual connections.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        out = self.fn(x, **kwargs)\n",
        "        if isinstance(out, tuple):\n",
        "            out, _ = out\n",
        "        return out + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of pre-normalization.\n",
        "    Args:\n",
        "        nn (nn.module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, fn: nn.Module):\n",
        "        \"\"\"\n",
        "        Pre-normalization.\n",
        "        Consists of layer for layer normalization followed by another network.\n",
        "        Args:\n",
        "            dim (int): Number of dimensions of normalized shape.\n",
        "            fn (nn.Module): network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of pre-normalization layers.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch implementation of feed forward network.\n",
        "    Args:\n",
        "        nn (nn.module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, mult: int = 4, dropout: float = 0.0):\n",
        "        \"\"\"\n",
        "        Feed forward network.\n",
        "        Network consists of input layer, GEGLU activation, dropout layer,\n",
        "        and output layer.\n",
        "        Args:\n",
        "            dim (int): dimension of input and output layer.\n",
        "            mult (int, optional): Scaling factor for output dimension of input layer or\n",
        "            input dimension of output layer. Defaults to 4.\n",
        "            dropout (float, optional): Degree of dropout. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GeGLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim * mult, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs: Any) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of feed forward network.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch implementation of attention.\n",
        "    Args:\n",
        "        nn (nn.Module): module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dim: int, n_heads: int = 8, dim_head: int = 16, dropout: float = 0.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Attention.\n",
        "        Args:\n",
        "            dim (int): Number of dimensions.\n",
        "            n_heads (int, optional): Number of attention heads. Defaults to 8.\n",
        "            dim_head (int, optional): Dimension of attention heads. Defaults to 16.\n",
        "            dropout (float, optional): Degree of dropout. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * n_heads\n",
        "        self.n_heads = n_heads\n",
        "        self.scale = dim_head**-0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Forward pass of attention module.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, Dict[str, torch.Tensor]]: Tuple with tokens and\n",
        "            attention_stats\n",
        "        \"\"\"\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        b, n, _ = q.shape\n",
        "        # reshape and permute: b n (h d) -> b h n d\n",
        "        q, k, v = map(\n",
        "            lambda t: t.reshape(b, n, self.n_heads, -1).permute(0, 2, 1, 3), (q, k, v)\n",
        "        )\n",
        "        attention_logits = einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
        "        attention_probs = attention_logits.softmax(dim=-1)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        out = einsum(\"b h i j, b h j d -> b h i d\", attention_probs, v)\n",
        "        # reshape and permute: b h i j, b h j d -> b h i d\n",
        "        out = out.permute(0, 2, 1, 3).reshape(b, n, -1)\n",
        "\n",
        "        return self.to_out(out), {\n",
        "            \"attention_logits\": attention_logits,\n",
        "            \"attention_probs\": attention_probs,\n",
        "        }\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer.\n",
        "    Based on paper:\n",
        "    https://arxiv.org/abs/1706.03762\n",
        "    Args:\n",
        "        nn (nn.Module): Module with transformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens: int,\n",
        "        dim: int,\n",
        "        depth: int,\n",
        "        heads: int,\n",
        "        dim_head: int,\n",
        "        attn_dropout: float,\n",
        "        ff_dropout: float,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Classical transformer.\n",
        "        Args:\n",
        "            num_tokens (int): Number of tokens i. e., unique classes + special tokens.\n",
        "            dim (int): Number of dimensions.\n",
        "            depth (int): Depth of encoder / decoder.\n",
        "            heads (int): Number of attention heads.\n",
        "            dim_head (int): Dimensions of attention heads.\n",
        "            attn_dropout (float): Degree of dropout in attention.\n",
        "            ff_dropout (float): Degree of dropout in feed-forward network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Embedding(num_tokens, dim)  # (Embed the categorical features.)\n",
        "        self.blocks = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.blocks.append(\n",
        "                nn.ModuleDict(\n",
        "                    {\n",
        "                        \"attention\": Residual(\n",
        "                            PreNorm(\n",
        "                                dim,\n",
        "                                Attention(\n",
        "                                    dim,\n",
        "                                    n_heads=heads,\n",
        "                                    dim_head=dim_head,\n",
        "                                    dropout=attn_dropout,\n",
        "                                ),\n",
        "                            )\n",
        "                        ),\n",
        "                        \"ffn\": Residual(\n",
        "                            PreNorm(dim, FeedForward(dim, dropout=ff_dropout))\n",
        "                        ),\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of transformer.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        x = self.embeds(x)\n",
        "\n",
        "        for layer in self.blocks:\n",
        "            layer = cast(nn.ModuleDict, layer)\n",
        "            x = layer[\"attention\"](x)\n",
        "            x = layer[\"ffn\"](x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch model of a vanilla multi-layer perceptron.\n",
        "    Args:\n",
        "        nn (nn.Module): module with implementation of MLP.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dims: list[int], act: Callable[..., nn.Module]):\n",
        "        \"\"\"\n",
        "        Multilayer perceptron.\n",
        "        Depth of network is given by `len(dims)`. Capacity is given by entries\n",
        "        of `dim`. Activation function is used after each linear layer. There is\n",
        "        no activation function for the final linear layer, as it is sometimes part\n",
        "        of the loss function already e. g., `nn.BCEWithLogitsLoss()`.\n",
        "        Args:\n",
        "            dims (List[int]): List with dimensions of layers.\n",
        "            act (Callable[..., nn.Module]): Activation function of each linear\n",
        "            layer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
        "        layers = []\n",
        "        for dim_in, dim_out in dims_pairs:\n",
        "            linear = nn.Linear(dim_in, dim_out)\n",
        "            layers.append(linear)\n",
        "            layers.append(act())\n",
        "\n",
        "        # drop last layer, as a sigmoid layer is included from BCELogitLoss\n",
        "        del layers[-1]\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagate tensor through MLP.\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor.\n",
        "        Returns:\n",
        "            torch.Tensor: output tensor.\n",
        "        \"\"\"\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "class TabTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch model of TabTransformer.\n",
        "    Based on paper:\n",
        "    https://arxiv.org/abs/2012.06678\n",
        "    Args:\n",
        "        nn (nn.Module): Module with implementation of TabTransformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        cat_cardinalities: tuple[int, ...] | tuple[()],\n",
        "        num_continuous: int,\n",
        "        dim: int = 32,\n",
        "        depth: int = 4,\n",
        "        heads: int = 8,\n",
        "        dim_head: int = 16,\n",
        "        dim_out: int = 1,\n",
        "        mlp_hidden_mults: tuple[(int, int)] = (4, 2),\n",
        "        mlp_act: Callable[..., nn.Module] = nn.ReLU,\n",
        "        num_special_tokens: int = 9,\n",
        "        continuous_mean_std: torch.Tensor | None = None,\n",
        "        attn_dropout: float = 0.0,\n",
        "        ff_dropout: float = 0.0,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        TabTransformer.\n",
        "        Originally introduced in https://arxiv.org/abs/2012.06678.\n",
        "        Args:\n",
        "            cat_cardinalities ([List[int] | Tuple[()]): List with number of categories\n",
        "            for each categorical feature. If no categorical variables are present,\n",
        "            use empty tuple. For categorical variables e. g., option type ('C' or 'P'),\n",
        "            the list would be `[1]`.\n",
        "            num_continuous (int): Number of continous features.\n",
        "            dim (int, optional): Dimensionality of transformer. Defaults to 32.\n",
        "            depth (int, optional): Depth of encoder / decoder of transformer.\n",
        "            Defaults to 4.\n",
        "            heads (int, optional): Number of attention heads. Defaults to 8.\n",
        "            dim_head (int, optional): Dimensionality of attention head. Defaults to 16.\n",
        "            dim_out (int, optional): Dimension of output layer of MLP. Set to one for\n",
        "            binary classification. Defaults to 1.\n",
        "            mlp_hidden_mults (Tuple[(int, int)], optional): multipliers for dimensions\n",
        "            of hidden layer in MLP. Defaults to (4, 2).\n",
        "            mlp_act (Callable[..., nn.Module], optional): Activation function used\n",
        "            in MLP. Defaults to nn.ReLU().\n",
        "            num_special_tokens (int, optional): Number of special tokens in transformer.\n",
        "            Defaults to 2.\n",
        "            continuous_mean_std (torch.Tensor | None): List with mean and\n",
        "            std deviation of each continous feature. Shape eq. `[num_continous x 2]`.\n",
        "            Defaults to None.\n",
        "            attn_dropout (float, optional): Degree of attention dropout used in\n",
        "            transformer. Defaults to 0.0.\n",
        "            ff_dropout (float, optional): Dropout in feed forward net. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert all(\n",
        "            map(lambda n: n > 0, cat_cardinalities)\n",
        "        ), \"number of each category must be positive\"\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(cat_cardinalities)\n",
        "        self.cardinality_categories = sum(cat_cardinalities)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.cardinality_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position\n",
        "        #  in the categories embedding table\n",
        "\n",
        "        categories_offset = F.pad(\n",
        "            torch.tensor(list(cat_cardinalities)), (1, 0), value=num_special_tokens\n",
        "        )  # Prepend num_special_tokens.\n",
        "        print(\"categories_offset\")\n",
        "        print(categories_offset)\n",
        "        categories_offset = categories_offset.cumsum(dim=-1)[:-1]\n",
        "        self.register_buffer(\"categories_offset\", categories_offset)\n",
        "        print(\"categories_offset (cum sum)\")\n",
        "        print(categories_offset)\n",
        "\n",
        "        # continuous\n",
        "\n",
        "        if continuous_mean_std is not None:\n",
        "            assert continuous_mean_std.shape == (num_continuous, 2,), (\n",
        "                f\"continuous_mean_std must have a shape of ({num_continuous}, 2)\"\n",
        "                f\"where the last dimension contains the mean and variance respectively\"\n",
        "            )\n",
        "        self.register_buffer(\"continuous_mean_std\", continuous_mean_std)\n",
        "\n",
        "        self.norm = nn.LayerNorm(num_continuous)\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        # transformer\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            num_tokens=total_tokens,\n",
        "            dim=dim,\n",
        "            depth=depth,\n",
        "            heads=heads,\n",
        "            dim_head=dim_head,\n",
        "            attn_dropout=attn_dropout,\n",
        "            ff_dropout=ff_dropout,\n",
        "        )\n",
        "\n",
        "        # mlp to logits\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "        j = input_size // 8\n",
        "\n",
        "        hidden_dimensions = list(map(lambda t: j * t, mlp_hidden_mults))\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "\n",
        "        self.mlp = MLP(all_dimensions, act=mlp_act)\n",
        "\n",
        "    def forward(self, x_cat: torch.Tensor | None, x_cont: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of TabTransformer.\n",
        "        Args:\n",
        "            x_cat (torch.Tensor | None): tensor with categorical data.\n",
        "            x_cont (torch.Tensor): tensor with continous data.\n",
        "        Returns:\n",
        "            torch.Tensor: probabilities\n",
        "        \"\"\"\n",
        "        flat_categ: torch.Tensor | None = None\n",
        "\n",
        "        # print(\"x_cat\")\n",
        "        # print(x_cat)\n",
        "\n",
        "        # print(x_cont)\n",
        "\n",
        "        if x_cat is not None:\n",
        "            assert x_cat.shape[-1] == self.num_categories, (\n",
        "                f\"you must pass in {self.num_categories} \"\n",
        "                f\"values for your categories input\"\n",
        "            )\n",
        "            print(\"categories_offset\")\n",
        "            print(self.categories_offset)\n",
        "\n",
        "            print(\"x_cat\")\n",
        "            print(x_cat)\n",
        "\n",
        "            x_cat += self.categories_offset\n",
        "            print(\"x_cat + categories_offset\")\n",
        "            print(x_cat)\n",
        "            x = self.transformer(x_cat)\n",
        "            flat_categ = x.flatten(1)\n",
        "\n",
        "        assert x_cont.shape[1] == self.num_continuous, (\n",
        "            f\"you must pass in {self.num_continuous} \"\n",
        "            f\"values for your continuous input\"\n",
        "        )\n",
        "\n",
        "        if self.continuous_mean_std is not None:\n",
        "            mean, std = self.continuous_mean_std.unbind(dim=-1)  # type: ignore\n",
        "            x_cont = (x_cont - mean) / std\n",
        "\n",
        "        normed_cont = self.norm(x_cont)\n",
        "\n",
        "        # Adaptation to work without categorical data\n",
        "        x = (\n",
        "            torch.cat((flat_categ, normed_cont), dim=-1)\n",
        "            if flat_categ is not None\n",
        "            else normed_cont\n",
        "        )\n",
        "\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features_cont = 5\n",
        "num_features_cat = 3\n",
        "num_unique_cat = tuple([6, 4, 5])\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "x_cat = torch.randint(0, 2, (batch_size, num_features_cat)).to(\n",
        "            device\n",
        "        )\n",
        "x_cont = (\n",
        "            torch.randn(batch_size, num_features_cont).float().to(device)\n",
        "        )\n",
        "expected_outputs = (\n",
        "            torch.randint(0, 1, (batch_size, num_features_cat)).float().to(device)\n",
        "        )\n",
        "\n",
        "net = TabTransformer(\n",
        "            cat_cardinalities=num_unique_cat,\n",
        "            num_continuous=num_features_cont,\n",
        "            dim_out=1,\n",
        "            mlp_act=nn.ReLU,\n",
        "            dim=32,\n",
        "            depth=2,\n",
        "            heads=6,\n",
        "            attn_dropout=0.1,\n",
        "            ff_dropout=0.1,\n",
        "            mlp_hidden_mults=(4, 2),\n",
        ").to(device)\n",
        "\n",
        "net(x_cat, x_cont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHWXGIwjQhZA",
        "outputId": "01dc6d24-78bb-4b0c-eae4-37eb60860e5f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories_offset\n",
            "tensor([9, 6, 4, 5])\n",
            "categories_offset (cum sum)\n",
            "tensor([ 9, 15, 19])\n",
            "categories_offset\n",
            "tensor([ 9, 15, 19])\n",
            "x_cat\n",
            "tensor([[0, 1, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 1, 1],\n",
            "        [0, 1, 0],\n",
            "        [1, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [1, 1, 0],\n",
            "        [0, 1, 1]])\n",
            "x_cat + categories_offset\n",
            "tensor([[ 9, 16, 20],\n",
            "        [ 9, 15, 19],\n",
            "        [ 9, 16, 20],\n",
            "        [ 9, 16, 19],\n",
            "        [10, 15, 20],\n",
            "        [ 9, 15, 20],\n",
            "        [10, 16, 19],\n",
            "        [ 9, 16, 20]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0902],\n",
              "        [-0.0463],\n",
              "        [-0.0528],\n",
              "        [-0.0579],\n",
              "        [-0.0432],\n",
              "        [-0.0020],\n",
              "        [-0.0780],\n",
              "        [-0.0400]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [special tokens,cat cardinality 1, cat cardinality 2 etc.]\n",
        "x_cat = torch.randint(0, 3, (batch_size, num_features_cat)).to(\n",
        "            device\n",
        "        )"
      ],
      "metadata": {
        "id": "vfBW3XIdQ6y3"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ColumnEmbedding(nn.Module):\n",
        "\n",
        "  def __init__(self, cardinalities: list[int], d_token: int, dropout: float = 0.0, bias=False):\n",
        "\n",
        "    super().__init__()\n",
        "  \n",
        "    assert cardinalities, \"cardinalities must be non-empty\"\n",
        "    assert d_token > 0, \"d_token must be positive\"\n",
        "\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    # embeddings for every class in every column\n",
        "    category_offsets = torch.tensor([0] + cardinalities[:-1]).cumsum(0)\n",
        "    self.register_buffer(\"category_offsets\", category_offsets, persistent=False)\n",
        "    self.ie = nn.Embedding(sum(cardinalities), d_token)\n",
        "    \n",
        "    # embeddings for entire column\n",
        "    self.se = nn.Parameter(torch.empty(len(cardinalities), d_token).uniform_(-1, 1)\n",
        "    )\n",
        "\n",
        "    self.bias = (\n",
        "          nn.Parameter(torch.Tensor(len(cardinalities), d_token)._zero()) if bias else None\n",
        "    )\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tensor:\n",
        "    # [num_cat_columns, d_model] (+) [batch_size, num_cat_]\n",
        "    x = self.ie(x + self.category_offsets[None])\n",
        "\n",
        "    # dim [batch_size, num_cat_cols, d_token] + [num_cat_cols, d_token]\n",
        "    # add elemnt-wisely\n",
        "    x = x + self.se\n",
        "    \n",
        "\n",
        "    # add bias term, not part of paper but works in Gorishny\n",
        "    if self.bias is not None:\n",
        "        x = x + self.bias[None]\n",
        "\n",
        "    # add dropout, not part of paper, but could work\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "sv-O9CJccC9z"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_embed = ColumnEmbedding([6,4,5], 3)(x_cat)"
      ],
      "metadata": {
        "id": "YdiWBJ34fAup"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAPha1JBrvHo",
        "outputId": "ee88180b-a32d-4a88-9fed-89e9c83f95d0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2, 1],\n",
              "        [0, 0, 0],\n",
              "        [2, 2, 1],\n",
              "        [0, 0, 2],\n",
              "        [0, 0, 0],\n",
              "        [2, 0, 0],\n",
              "        [2, 2, 2],\n",
              "        [1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9_gDqwxrrRP",
        "outputId": "b4a501e8-b75c-488e-d669-103b4cddfc3a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9568,  0.2226,  0.5660],\n",
              "         [-0.3934, -0.9328,  1.0054],\n",
              "         [ 0.7568, -0.7914, -1.3837]],\n",
              "\n",
              "        [[-0.7228,  0.0340,  0.6935],\n",
              "         [ 0.2731, -1.3477, -0.9526],\n",
              "         [ 0.0608, -0.1256, -0.5442]],\n",
              "\n",
              "        [[-0.9568,  0.2226,  0.5660],\n",
              "         [-0.3934, -0.9328,  1.0054],\n",
              "         [ 0.7568, -0.7914, -1.3837]],\n",
              "\n",
              "        [[-0.7228,  0.0340,  0.6935],\n",
              "         [ 0.2731, -1.3477, -0.9526],\n",
              "         [ 2.1985, -0.4491, -1.1389]],\n",
              "\n",
              "        [[-0.7228,  0.0340,  0.6935],\n",
              "         [ 0.2731, -1.3477, -0.9526],\n",
              "         [ 0.0608, -0.1256, -0.5442]],\n",
              "\n",
              "        [[-0.9568,  0.2226,  0.5660],\n",
              "         [ 0.2731, -1.3477, -0.9526],\n",
              "         [ 0.0608, -0.1256, -0.5442]],\n",
              "\n",
              "        [[-0.9568,  0.2226,  0.5660],\n",
              "         [-0.3934, -0.9328,  1.0054],\n",
              "         [ 2.1985, -0.4491, -1.1389]],\n",
              "\n",
              "        [[ 1.8193, -0.0998,  0.6289],\n",
              "         [ 0.2731, -1.3477, -0.9526],\n",
              "         [ 0.7568, -0.7914, -1.3837]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int,cat_cardinalities, dropout: float = 0.5,):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.col_embedding = ColumnEmbedding(cat_cardinalities, d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout,\n",
        "                                                 batch_first=True, norm_first=False)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "\n",
        "    def forward(self, x_cat: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        x_embed = self.col_embedding(x_cat)\n",
        "        output = self.transformer_encoder(x_embed)\n",
        "        # output = self.decoder(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "qaKZ1lYuaKVI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSUOTvSI1A0S",
        "outputId": "72ab8bd2-193c-475c-d3d9-af2d1db45cf8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = Transformer(ntoken=3,d_model=32,nhead=2,d_hid=4, nlayers=1, cat_cardinalities=[5,5,5])(x_cat)"
      ],
      "metadata": {
        "id": "YQCtg0gR06sr"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHbJ4wV24xI",
        "outputId": "003071a0-7ef4-4100-9e4d-3d1e0026a03b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 8.8864e-01,  9.4383e-02,  5.2546e-01,  7.2947e-01,  1.2627e-01,\n",
              "          -2.4456e-01,  7.6873e-01,  9.9869e-01, -5.6915e-01,  1.2840e+00,\n",
              "           1.5431e+00, -1.8993e-01,  5.8414e-01, -1.9980e-01,  3.8460e-01,\n",
              "          -6.0572e-02, -7.0591e-01,  5.0290e-01, -2.3723e-01, -1.6604e+00,\n",
              "          -9.8042e-01,  1.2650e+00,  1.6362e+00, -2.4667e+00, -1.3068e+00,\n",
              "           5.9329e-01, -1.6280e+00,  1.0104e-01,  4.0894e-01,  5.2002e-02,\n",
              "          -1.9921e+00, -2.4524e-01],\n",
              "         [ 1.1112e+00, -4.7838e-01,  8.2323e-01,  6.4713e-01, -1.1281e+00,\n",
              "           2.1425e+00, -1.7950e-01,  1.2102e+00, -1.9020e-01, -1.4245e+00,\n",
              "          -3.8994e-01, -2.5254e-01,  6.0541e-01,  7.1715e-01,  3.0771e-01,\n",
              "          -4.6271e-01, -8.0492e-02, -8.3950e-01,  5.2788e-01, -2.3134e+00,\n",
              "           7.0031e-01,  5.2626e-01,  1.5085e+00,  7.8332e-01, -4.5750e-01,\n",
              "          -9.0921e-01, -1.5029e+00,  9.3786e-01,  7.1906e-01, -1.6726e+00,\n",
              "          -1.0569e+00,  7.0625e-02],\n",
              "         [ 3.8769e-02, -2.0612e-01, -2.4222e-01, -5.4422e-01,  4.5253e-01,\n",
              "          -1.8477e+00,  8.0377e-01,  1.3464e+00, -3.3188e-01,  2.1423e+00,\n",
              "           1.6048e+00, -5.8434e-01,  2.7083e-01, -3.9238e-01,  4.1122e-01,\n",
              "           8.6300e-01,  2.1966e+00, -1.7239e+00,  1.2893e-01, -5.5793e-01,\n",
              "          -2.1287e-01, -1.3612e-01,  3.0629e-01,  9.6745e-01, -1.5407e+00,\n",
              "          -1.5756e+00, -8.0419e-01, -4.1728e-01,  2.6392e-01, -1.2486e+00,\n",
              "           4.8399e-01,  8.5283e-02]],\n",
              "\n",
              "        [[ 2.0160e-01,  9.7119e-01,  3.8938e-01, -1.1119e+00,  8.9568e-01,\n",
              "           2.3844e+00,  4.4202e-01,  7.0711e-01, -5.9026e-01, -1.0424e+00,\n",
              "           1.3855e+00,  7.5760e-01, -9.5753e-01,  6.4267e-01, -8.6011e-01,\n",
              "          -7.1424e-01, -1.0750e+00, -9.1404e-01,  2.1987e+00,  1.3729e-01,\n",
              "           1.0634e+00, -1.3271e+00, -5.1467e-01, -1.5245e-01, -7.4754e-01,\n",
              "          -1.2349e+00,  1.1656e-01, -3.0854e-01, -1.3736e+00, -7.3226e-01,\n",
              "           1.1103e+00,  2.5305e-01],\n",
              "         [-7.7886e-02,  1.0648e-01,  1.2437e+00,  1.1696e-01,  2.8891e+00,\n",
              "           2.4372e-01,  8.7483e-01,  2.5833e-01, -5.9703e-01,  1.0208e+00,\n",
              "          -7.2800e-01,  1.0267e+00, -1.5828e-01,  5.1639e-01,  8.4048e-01,\n",
              "           1.2917e-01, -7.5603e-01, -2.0772e-01, -1.0850e+00, -1.9757e+00,\n",
              "           1.3880e+00,  4.2681e-01,  2.1377e-01,  7.7366e-01, -2.5738e-01,\n",
              "          -7.7574e-01, -1.3253e+00, -9.1572e-01, -1.4735e+00, -1.7949e+00,\n",
              "           2.3003e-01, -1.7077e-01],\n",
              "         [-6.6759e-01, -1.7468e+00, -3.4320e-01, -2.2477e+00, -1.3487e+00,\n",
              "          -1.1613e+00, -3.6685e-01,  1.2341e+00, -9.4027e-01,  1.3046e+00,\n",
              "           5.9564e-01,  7.7668e-02, -2.7078e-02, -3.0975e-01,  9.3866e-01,\n",
              "           1.0146e+00,  3.0957e-01,  1.2545e+00,  7.5327e-01, -7.3340e-01,\n",
              "          -7.1431e-01, -8.5825e-01,  1.1888e+00, -8.6089e-02, -4.2106e-02,\n",
              "           2.2040e-01, -6.2877e-01, -6.6149e-01,  2.4821e-01, -3.2684e-02,\n",
              "           1.7553e+00,  2.0209e+00]],\n",
              "\n",
              "        [[ 1.6863e+00,  5.9508e-01,  1.2387e+00, -3.8659e-01,  4.7035e-01,\n",
              "          -1.3432e-01,  3.5945e-03,  1.4352e+00, -1.1937e+00, -7.9170e-02,\n",
              "          -3.2960e-01, -2.4341e-01, -4.4190e-02,  9.7314e-01,  3.3125e-01,\n",
              "           9.4698e-02, -3.1216e-01,  8.0228e-01, -3.3838e-01, -9.6363e-01,\n",
              "          -8.8565e-01,  1.4382e+00,  1.8107e+00, -2.9466e+00, -1.3578e+00,\n",
              "           1.7152e-01, -9.2543e-01, -1.7331e-01,  7.3809e-01,  1.4676e-01,\n",
              "          -1.4867e+00, -1.3517e-01],\n",
              "         [-1.5465e-01,  5.7758e-01,  1.1087e-01, -9.7701e-01, -9.1657e-01,\n",
              "           1.3115e+00,  9.5531e-01,  1.1788e+00, -1.3937e+00, -8.1756e-01,\n",
              "           6.1168e-01, -3.3555e-01,  5.9357e-01, -7.7216e-01,  1.2078e+00,\n",
              "           1.9054e-01, -3.2059e-03,  2.6387e-01,  8.5919e-01, -8.4907e-02,\n",
              "           9.4431e-01,  7.1878e-01,  2.1210e+00,  1.8880e-01, -1.0672e-01,\n",
              "          -1.1413e+00, -2.7473e+00,  2.4001e-02,  2.7468e-01,  1.7310e-01,\n",
              "          -1.9129e+00, -9.4183e-01],\n",
              "         [ 1.5123e-01,  1.6057e-01,  2.8373e-01,  1.5440e+00,  2.6109e-01,\n",
              "          -8.0638e-01,  1.0793e+00,  4.5650e-02, -1.3819e+00,  1.3717e+00,\n",
              "           1.5956e+00,  1.7593e-01, -2.4454e-02,  7.3811e-02,  4.1651e-01,\n",
              "           5.6528e-01,  1.7481e+00, -3.1060e-01,  9.7692e-02,  1.7714e+00,\n",
              "          -1.9174e-01, -9.0345e-01,  2.6379e-01,  8.3357e-01, -1.6363e+00,\n",
              "          -1.4987e+00, -6.8600e-01, -1.6013e+00, -1.7128e-01, -2.0162e+00,\n",
              "          -4.7907e-01, -7.3152e-01]],\n",
              "\n",
              "        [[ 7.2187e-01,  4.1242e-01, -7.4066e-02, -1.3775e-01,  1.9056e-01,\n",
              "           2.5169e+00, -8.1465e-01,  1.4972e-01, -1.2246e+00, -4.5358e-01,\n",
              "           4.8777e-01,  6.0865e-01, -1.2388e+00,  1.9535e-01, -1.9264e-01,\n",
              "          -2.4898e-01, -2.6560e+00, -1.1000e-01,  2.7902e+00,  7.0612e-01,\n",
              "           7.3847e-01, -4.3582e-02,  5.8828e-01, -2.5561e-01, -6.5530e-02,\n",
              "          -7.9713e-01, -4.6099e-01, -6.7121e-01, -9.1668e-01, -8.5913e-01,\n",
              "           9.3537e-02,  1.0210e+00],\n",
              "         [-3.6716e-01, -3.7627e-01,  1.1758e+00,  3.3181e-01,  1.9049e+00,\n",
              "           1.5539e+00,  8.9271e-01, -1.8473e+00,  7.2595e-01, -6.9557e-01,\n",
              "          -6.5699e-01,  9.2847e-01, -2.5179e-01, -1.3008e-01,  1.5773e+00,\n",
              "          -9.0402e-01, -7.9859e-01, -4.2437e-01, -2.1634e+00, -2.8853e-02,\n",
              "           1.3857e+00,  2.2623e-01, -8.0459e-01,  5.3706e-01, -5.6342e-01,\n",
              "          -1.1638e+00, -1.8002e+00,  7.7578e-01,  5.4926e-01,  1.6216e-01,\n",
              "           5.8231e-02,  1.9104e-01],\n",
              "         [-1.1378e+00, -1.0876e+00,  6.3065e-01,  4.7270e-01,  7.5650e-01,\n",
              "          -3.1274e-01,  8.2480e-01,  7.7300e-01, -2.0484e+00,  2.0936e+00,\n",
              "          -2.1820e-01, -1.2449e-02, -1.6931e+00,  1.4629e-01,  6.4145e-01,\n",
              "          -4.3763e-02, -1.4519e+00, -4.4774e-01,  2.2215e+00,  4.9131e-01,\n",
              "          -4.8409e-01, -8.8474e-01,  1.1768e+00,  8.3760e-01, -2.8407e-01,\n",
              "           1.3986e+00, -1.1210e+00, -4.3684e-01,  3.1014e-01, -8.4149e-01,\n",
              "          -3.7107e-01,  1.0214e-01]],\n",
              "\n",
              "        [[-3.3991e-01, -2.6631e-02, -1.9271e-01, -5.4124e-01,  5.3123e-01,\n",
              "           2.3697e+00,  1.0247e-01, -3.7093e-01, -1.2002e+00, -1.2799e+00,\n",
              "           8.0137e-01,  2.2932e+00, -1.0635e+00,  2.5755e-01, -7.8135e-02,\n",
              "          -4.3539e-01, -9.7325e-01,  3.5014e-01,  2.1696e+00,  9.9032e-01,\n",
              "           6.3872e-01, -7.0166e-01, -3.4952e-01, -3.6925e-01, -1.9657e-01,\n",
              "          -1.5152e+00, -7.9061e-01, -5.2016e-01, -4.3095e-01, -1.2123e+00,\n",
              "           7.5660e-01,  1.3271e+00],\n",
              "         [-6.4349e-01, -3.9796e-01,  1.3938e+00, -3.6137e-01,  2.2105e+00,\n",
              "           1.1809e+00,  3.7055e-01, -1.1822e+00,  1.3988e+00, -2.1204e+00,\n",
              "          -6.5011e-01,  1.1970e-01, -3.9750e-01, -3.3517e-03,  1.4930e+00,\n",
              "          -2.9213e-01, -6.3601e-01,  4.1861e-01, -1.5243e+00,  6.1277e-02,\n",
              "           1.2148e+00,  1.1235e+00, -3.5410e-01,  3.1813e-02,  1.3629e-01,\n",
              "          -1.3441e+00, -1.7504e+00, -7.5230e-03,  9.6906e-01, -6.5786e-02,\n",
              "          -6.9348e-01,  3.0167e-01],\n",
              "         [ 1.0280e-01, -1.6059e+00, -5.4704e-01, -1.7941e+00, -1.5558e+00,\n",
              "          -9.0902e-01, -2.5363e-01,  1.0044e+00, -3.4289e-01,  5.3042e-01,\n",
              "          -1.6551e-01,  9.7519e-01, -3.9075e-01, -1.6483e+00,  7.8543e-01,\n",
              "           1.8630e+00,  6.3966e-01,  4.6629e-01,  5.5254e-01, -6.8320e-01,\n",
              "          -7.5397e-01, -8.9420e-01,  1.2253e+00,  8.1812e-02, -3.6697e-01,\n",
              "           3.4607e-01, -4.7143e-01, -4.9802e-01, -3.3723e-01,  7.6054e-01,\n",
              "           1.9175e+00,  1.9670e+00]],\n",
              "\n",
              "        [[ 1.2988e+00, -9.9816e-02,  1.2515e+00, -9.0630e-01,  5.4642e-01,\n",
              "           1.8234e-04,  1.0193e+00,  6.7364e-01,  1.2766e-01, -1.5133e-02,\n",
              "           1.1064e-01, -2.3994e-03, -1.5023e-01,  1.0273e+00,  4.7915e-01,\n",
              "           1.5711e-01,  6.9479e-02, -1.1633e+00,  5.0702e-01, -9.1578e-01,\n",
              "          -2.2414e-01,  1.6625e+00,  1.8457e+00, -3.2314e+00, -1.2331e+00,\n",
              "          -1.0430e-01, -8.5347e-01, -1.9594e-01,  4.8114e-01,  2.9592e-01,\n",
              "          -1.2922e+00, -1.1660e+00],\n",
              "         [-7.4992e-01, -7.0890e-01,  1.2124e+00, -1.6826e+00,  1.4671e+00,\n",
              "           7.6426e-01,  2.2108e-01, -2.3562e+00,  4.3519e-01, -2.3809e-02,\n",
              "          -5.2294e-01, -5.2798e-01, -3.4315e-01, -1.3295e-01,  2.4260e+00,\n",
              "          -2.2689e-01, -8.3952e-01,  1.7482e+00,  3.5059e-02, -1.1420e+00,\n",
              "           7.0528e-01,  4.9818e-01, -5.5051e-02,  4.0308e-01,  4.2961e-01,\n",
              "          -1.0608e+00, -1.2544e+00,  5.6164e-01,  5.8970e-01, -1.0127e+00,\n",
              "           9.4539e-01,  1.9767e-01],\n",
              "         [-1.3604e-01, -2.3128e+00,  1.2046e-01, -1.4867e+00, -1.3016e+00,\n",
              "          -8.6674e-01, -1.1386e+00,  1.7507e+00, -6.4006e-01,  6.4674e-01,\n",
              "           6.2179e-01,  1.1184e+00, -2.4599e-01, -2.0480e-01,  7.5462e-01,\n",
              "           1.1471e+00,  5.9117e-01, -2.8266e-01,  1.3078e+00, -1.7791e+00,\n",
              "          -5.2552e-01, -7.6680e-01,  1.0143e+00, -1.3449e-01, -4.6588e-01,\n",
              "           4.2544e-01, -4.0171e-01, -4.6373e-01,  3.1319e-01,  1.8780e-01,\n",
              "           1.4173e+00,  1.7364e+00]],\n",
              "\n",
              "        [[ 1.4027e+00,  9.8428e-01,  7.5048e-01,  2.9866e-01,  3.5481e-01,\n",
              "           9.9005e-02,  7.9198e-01,  7.2253e-01, -1.5025e+00,  2.7808e-01,\n",
              "           9.1482e-01, -4.4172e-02,  8.6923e-01,  9.5080e-01,  2.6147e-01,\n",
              "          -1.5233e-01, -1.1399e+00, -9.8611e-01,  3.1380e-01, -9.6724e-01,\n",
              "          -1.1945e+00,  8.1990e-01,  1.9819e+00, -1.9142e+00, -5.4678e-01,\n",
              "           9.5662e-01, -1.8997e+00, -3.3587e-01,  3.5140e-01,  1.5791e-01,\n",
              "          -1.9207e+00, -6.5632e-01],\n",
              "         [ 4.1075e-01,  9.6024e-01, -9.0557e-03,  1.6934e+00, -1.3997e+00,\n",
              "           1.7523e+00,  1.4210e+00, -1.0140e-02, -1.8082e-01,  9.4622e-02,\n",
              "           6.0366e-01,  2.1518e-01,  8.4422e-01, -3.1862e-01,  1.7473e-01,\n",
              "          -5.0270e-01,  5.6769e-01, -1.5323e+00,  9.3381e-01, -5.9216e-01,\n",
              "           8.7103e-01,  3.1065e-01,  6.1420e-02,  1.8595e-01, -1.8434e-01,\n",
              "          -2.8404e+00, -1.7313e+00,  2.1741e-02, -1.7984e+00, -2.1491e-01,\n",
              "           4.5473e-01, -2.6220e-01],\n",
              "         [-1.9148e+00, -6.2577e-01, -1.0419e+00, -6.1809e-01,  3.1956e-01,\n",
              "          -5.2739e-01,  1.4742e+00,  1.8584e+00, -1.9632e+00,  5.0707e-01,\n",
              "           2.9235e-01, -6.0345e-01, -8.1535e-01,  1.9312e-01,  1.7486e+00,\n",
              "           9.7216e-01, -3.6906e-01, -7.4055e-01,  9.6255e-01, -8.5812e-01,\n",
              "           4.8256e-01, -3.8135e-01,  1.5870e+00, -4.9883e-02, -7.3142e-01,\n",
              "           1.6146e+00, -7.2923e-01, -5.7211e-01,  1.6397e-01, -5.6267e-01,\n",
              "           1.2320e+00, -3.0383e-01]],\n",
              "\n",
              "        [[ 6.3943e-01, -8.6849e-02,  3.3896e-01,  4.4220e-01, -3.4362e-01,\n",
              "           7.9687e-01, -7.0095e-01,  2.7830e+00, -3.8445e-01, -8.6407e-01,\n",
              "           2.6060e+00,  1.5051e-01,  1.1405e+00, -4.8991e-01, -5.5440e-01,\n",
              "          -1.1450e+00,  1.3933e+00, -1.2315e-01, -7.8497e-01, -1.3161e+00,\n",
              "          -3.3635e-02, -7.8819e-01,  1.1414e-01, -7.5801e-02,  1.1496e-01,\n",
              "          -1.1556e+00, -1.1784e+00,  2.0287e-01, -1.4402e-01, -1.1333e+00,\n",
              "          -7.6339e-01,  1.3431e+00],\n",
              "         [ 9.1076e-01, -2.8894e-01,  1.8617e+00,  1.0701e+00,  2.1034e+00,\n",
              "           1.0003e+00,  8.4215e-01, -3.3282e-01,  6.7049e-02, -4.0693e-02,\n",
              "           7.4298e-01,  1.5210e-01, -4.6197e-01, -1.5257e+00,  1.4070e+00,\n",
              "           7.2207e-02,  4.9561e-02,  3.0297e-01, -1.3048e+00, -1.3450e+00,\n",
              "           1.5219e+00, -1.0583e+00,  5.7995e-02,  1.2815e-01, -3.3280e-02,\n",
              "          -2.1173e+00, -8.5007e-01, -3.4298e-01, -6.9984e-01, -5.8088e-01,\n",
              "          -1.3801e+00,  7.2307e-02],\n",
              "         [ 6.9152e-01, -6.5130e-02,  6.6887e-01,  4.1858e-01,  2.9582e-01,\n",
              "          -7.2981e-01,  8.8993e-01,  1.8127e+00, -9.9428e-01,  1.1247e+00,\n",
              "           1.4600e+00,  4.0217e-01, -1.9646e-01, -7.0730e-02,  7.2047e-01,\n",
              "           1.1268e+00,  1.3502e+00, -8.6917e-01, -4.9421e-01,  1.7060e+00,\n",
              "          -1.1312e+00, -3.6772e-01,  6.1102e-01,  8.9885e-02, -8.3820e-01,\n",
              "          -2.1400e+00, -1.4255e+00, -1.7538e+00, -3.9840e-02, -6.3277e-01,\n",
              "          -1.1132e+00, -5.0648e-01]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.flatten(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn4d28P-2nds",
        "outputId": "d0d86b07-3b3b-4515-b180-47336e080783"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.8864e-01,  9.4383e-02,  5.2546e-01,  7.2947e-01,  1.2627e-01,\n",
              "         -2.4456e-01,  7.6873e-01,  9.9869e-01, -5.6915e-01,  1.2840e+00,\n",
              "          1.5431e+00, -1.8993e-01,  5.8414e-01, -1.9980e-01,  3.8460e-01,\n",
              "         -6.0572e-02, -7.0591e-01,  5.0290e-01, -2.3723e-01, -1.6604e+00,\n",
              "         -9.8042e-01,  1.2650e+00,  1.6362e+00, -2.4667e+00, -1.3068e+00,\n",
              "          5.9329e-01, -1.6280e+00,  1.0104e-01,  4.0894e-01,  5.2002e-02,\n",
              "         -1.9921e+00, -2.4524e-01,  1.1112e+00, -4.7838e-01,  8.2323e-01,\n",
              "          6.4713e-01, -1.1281e+00,  2.1425e+00, -1.7950e-01,  1.2102e+00,\n",
              "         -1.9020e-01, -1.4245e+00, -3.8994e-01, -2.5254e-01,  6.0541e-01,\n",
              "          7.1715e-01,  3.0771e-01, -4.6271e-01, -8.0492e-02, -8.3950e-01,\n",
              "          5.2788e-01, -2.3134e+00,  7.0031e-01,  5.2626e-01,  1.5085e+00,\n",
              "          7.8332e-01, -4.5750e-01, -9.0921e-01, -1.5029e+00,  9.3786e-01,\n",
              "          7.1906e-01, -1.6726e+00, -1.0569e+00,  7.0625e-02,  3.8769e-02,\n",
              "         -2.0612e-01, -2.4222e-01, -5.4422e-01,  4.5253e-01, -1.8477e+00,\n",
              "          8.0377e-01,  1.3464e+00, -3.3188e-01,  2.1423e+00,  1.6048e+00,\n",
              "         -5.8434e-01,  2.7083e-01, -3.9238e-01,  4.1122e-01,  8.6300e-01,\n",
              "          2.1966e+00, -1.7239e+00,  1.2893e-01, -5.5793e-01, -2.1287e-01,\n",
              "         -1.3612e-01,  3.0629e-01,  9.6745e-01, -1.5407e+00, -1.5756e+00,\n",
              "         -8.0419e-01, -4.1728e-01,  2.6392e-01, -1.2486e+00,  4.8399e-01,\n",
              "          8.5283e-02],\n",
              "        [ 2.0160e-01,  9.7119e-01,  3.8938e-01, -1.1119e+00,  8.9568e-01,\n",
              "          2.3844e+00,  4.4202e-01,  7.0711e-01, -5.9026e-01, -1.0424e+00,\n",
              "          1.3855e+00,  7.5760e-01, -9.5753e-01,  6.4267e-01, -8.6011e-01,\n",
              "         -7.1424e-01, -1.0750e+00, -9.1404e-01,  2.1987e+00,  1.3729e-01,\n",
              "          1.0634e+00, -1.3271e+00, -5.1467e-01, -1.5245e-01, -7.4754e-01,\n",
              "         -1.2349e+00,  1.1656e-01, -3.0854e-01, -1.3736e+00, -7.3226e-01,\n",
              "          1.1103e+00,  2.5305e-01, -7.7886e-02,  1.0648e-01,  1.2437e+00,\n",
              "          1.1696e-01,  2.8891e+00,  2.4372e-01,  8.7483e-01,  2.5833e-01,\n",
              "         -5.9703e-01,  1.0208e+00, -7.2800e-01,  1.0267e+00, -1.5828e-01,\n",
              "          5.1639e-01,  8.4048e-01,  1.2917e-01, -7.5603e-01, -2.0772e-01,\n",
              "         -1.0850e+00, -1.9757e+00,  1.3880e+00,  4.2681e-01,  2.1377e-01,\n",
              "          7.7366e-01, -2.5738e-01, -7.7574e-01, -1.3253e+00, -9.1572e-01,\n",
              "         -1.4735e+00, -1.7949e+00,  2.3003e-01, -1.7077e-01, -6.6759e-01,\n",
              "         -1.7468e+00, -3.4320e-01, -2.2477e+00, -1.3487e+00, -1.1613e+00,\n",
              "         -3.6685e-01,  1.2341e+00, -9.4027e-01,  1.3046e+00,  5.9564e-01,\n",
              "          7.7668e-02, -2.7078e-02, -3.0975e-01,  9.3866e-01,  1.0146e+00,\n",
              "          3.0957e-01,  1.2545e+00,  7.5327e-01, -7.3340e-01, -7.1431e-01,\n",
              "         -8.5825e-01,  1.1888e+00, -8.6089e-02, -4.2106e-02,  2.2040e-01,\n",
              "         -6.2877e-01, -6.6149e-01,  2.4821e-01, -3.2684e-02,  1.7553e+00,\n",
              "          2.0209e+00],\n",
              "        [ 1.6863e+00,  5.9508e-01,  1.2387e+00, -3.8659e-01,  4.7035e-01,\n",
              "         -1.3432e-01,  3.5945e-03,  1.4352e+00, -1.1937e+00, -7.9170e-02,\n",
              "         -3.2960e-01, -2.4341e-01, -4.4190e-02,  9.7314e-01,  3.3125e-01,\n",
              "          9.4698e-02, -3.1216e-01,  8.0228e-01, -3.3838e-01, -9.6363e-01,\n",
              "         -8.8565e-01,  1.4382e+00,  1.8107e+00, -2.9466e+00, -1.3578e+00,\n",
              "          1.7152e-01, -9.2543e-01, -1.7331e-01,  7.3809e-01,  1.4676e-01,\n",
              "         -1.4867e+00, -1.3517e-01, -1.5465e-01,  5.7758e-01,  1.1087e-01,\n",
              "         -9.7701e-01, -9.1657e-01,  1.3115e+00,  9.5531e-01,  1.1788e+00,\n",
              "         -1.3937e+00, -8.1756e-01,  6.1168e-01, -3.3555e-01,  5.9357e-01,\n",
              "         -7.7216e-01,  1.2078e+00,  1.9054e-01, -3.2059e-03,  2.6387e-01,\n",
              "          8.5919e-01, -8.4907e-02,  9.4431e-01,  7.1878e-01,  2.1210e+00,\n",
              "          1.8880e-01, -1.0672e-01, -1.1413e+00, -2.7473e+00,  2.4001e-02,\n",
              "          2.7468e-01,  1.7310e-01, -1.9129e+00, -9.4183e-01,  1.5123e-01,\n",
              "          1.6057e-01,  2.8373e-01,  1.5440e+00,  2.6109e-01, -8.0638e-01,\n",
              "          1.0793e+00,  4.5650e-02, -1.3819e+00,  1.3717e+00,  1.5956e+00,\n",
              "          1.7593e-01, -2.4454e-02,  7.3811e-02,  4.1651e-01,  5.6528e-01,\n",
              "          1.7481e+00, -3.1060e-01,  9.7692e-02,  1.7714e+00, -1.9174e-01,\n",
              "         -9.0345e-01,  2.6379e-01,  8.3357e-01, -1.6363e+00, -1.4987e+00,\n",
              "         -6.8600e-01, -1.6013e+00, -1.7128e-01, -2.0162e+00, -4.7907e-01,\n",
              "         -7.3152e-01],\n",
              "        [ 7.2187e-01,  4.1242e-01, -7.4066e-02, -1.3775e-01,  1.9056e-01,\n",
              "          2.5169e+00, -8.1465e-01,  1.4972e-01, -1.2246e+00, -4.5358e-01,\n",
              "          4.8777e-01,  6.0865e-01, -1.2388e+00,  1.9535e-01, -1.9264e-01,\n",
              "         -2.4898e-01, -2.6560e+00, -1.1000e-01,  2.7902e+00,  7.0612e-01,\n",
              "          7.3847e-01, -4.3582e-02,  5.8828e-01, -2.5561e-01, -6.5530e-02,\n",
              "         -7.9713e-01, -4.6099e-01, -6.7121e-01, -9.1668e-01, -8.5913e-01,\n",
              "          9.3537e-02,  1.0210e+00, -3.6716e-01, -3.7627e-01,  1.1758e+00,\n",
              "          3.3181e-01,  1.9049e+00,  1.5539e+00,  8.9271e-01, -1.8473e+00,\n",
              "          7.2595e-01, -6.9557e-01, -6.5699e-01,  9.2847e-01, -2.5179e-01,\n",
              "         -1.3008e-01,  1.5773e+00, -9.0402e-01, -7.9859e-01, -4.2437e-01,\n",
              "         -2.1634e+00, -2.8853e-02,  1.3857e+00,  2.2623e-01, -8.0459e-01,\n",
              "          5.3706e-01, -5.6342e-01, -1.1638e+00, -1.8002e+00,  7.7578e-01,\n",
              "          5.4926e-01,  1.6216e-01,  5.8231e-02,  1.9104e-01, -1.1378e+00,\n",
              "         -1.0876e+00,  6.3065e-01,  4.7270e-01,  7.5650e-01, -3.1274e-01,\n",
              "          8.2480e-01,  7.7300e-01, -2.0484e+00,  2.0936e+00, -2.1820e-01,\n",
              "         -1.2449e-02, -1.6931e+00,  1.4629e-01,  6.4145e-01, -4.3763e-02,\n",
              "         -1.4519e+00, -4.4774e-01,  2.2215e+00,  4.9131e-01, -4.8409e-01,\n",
              "         -8.8474e-01,  1.1768e+00,  8.3760e-01, -2.8407e-01,  1.3986e+00,\n",
              "         -1.1210e+00, -4.3684e-01,  3.1014e-01, -8.4149e-01, -3.7107e-01,\n",
              "          1.0214e-01],\n",
              "        [-3.3991e-01, -2.6631e-02, -1.9271e-01, -5.4124e-01,  5.3123e-01,\n",
              "          2.3697e+00,  1.0247e-01, -3.7093e-01, -1.2002e+00, -1.2799e+00,\n",
              "          8.0137e-01,  2.2932e+00, -1.0635e+00,  2.5755e-01, -7.8135e-02,\n",
              "         -4.3539e-01, -9.7325e-01,  3.5014e-01,  2.1696e+00,  9.9032e-01,\n",
              "          6.3872e-01, -7.0166e-01, -3.4952e-01, -3.6925e-01, -1.9657e-01,\n",
              "         -1.5152e+00, -7.9061e-01, -5.2016e-01, -4.3095e-01, -1.2123e+00,\n",
              "          7.5660e-01,  1.3271e+00, -6.4349e-01, -3.9796e-01,  1.3938e+00,\n",
              "         -3.6137e-01,  2.2105e+00,  1.1809e+00,  3.7055e-01, -1.1822e+00,\n",
              "          1.3988e+00, -2.1204e+00, -6.5011e-01,  1.1970e-01, -3.9750e-01,\n",
              "         -3.3517e-03,  1.4930e+00, -2.9213e-01, -6.3601e-01,  4.1861e-01,\n",
              "         -1.5243e+00,  6.1277e-02,  1.2148e+00,  1.1235e+00, -3.5410e-01,\n",
              "          3.1813e-02,  1.3629e-01, -1.3441e+00, -1.7504e+00, -7.5230e-03,\n",
              "          9.6906e-01, -6.5786e-02, -6.9348e-01,  3.0167e-01,  1.0280e-01,\n",
              "         -1.6059e+00, -5.4704e-01, -1.7941e+00, -1.5558e+00, -9.0902e-01,\n",
              "         -2.5363e-01,  1.0044e+00, -3.4289e-01,  5.3042e-01, -1.6551e-01,\n",
              "          9.7519e-01, -3.9075e-01, -1.6483e+00,  7.8543e-01,  1.8630e+00,\n",
              "          6.3966e-01,  4.6629e-01,  5.5254e-01, -6.8320e-01, -7.5397e-01,\n",
              "         -8.9420e-01,  1.2253e+00,  8.1812e-02, -3.6697e-01,  3.4607e-01,\n",
              "         -4.7143e-01, -4.9802e-01, -3.3723e-01,  7.6054e-01,  1.9175e+00,\n",
              "          1.9670e+00],\n",
              "        [ 1.2988e+00, -9.9816e-02,  1.2515e+00, -9.0630e-01,  5.4642e-01,\n",
              "          1.8234e-04,  1.0193e+00,  6.7364e-01,  1.2766e-01, -1.5133e-02,\n",
              "          1.1064e-01, -2.3994e-03, -1.5023e-01,  1.0273e+00,  4.7915e-01,\n",
              "          1.5711e-01,  6.9479e-02, -1.1633e+00,  5.0702e-01, -9.1578e-01,\n",
              "         -2.2414e-01,  1.6625e+00,  1.8457e+00, -3.2314e+00, -1.2331e+00,\n",
              "         -1.0430e-01, -8.5347e-01, -1.9594e-01,  4.8114e-01,  2.9592e-01,\n",
              "         -1.2922e+00, -1.1660e+00, -7.4992e-01, -7.0890e-01,  1.2124e+00,\n",
              "         -1.6826e+00,  1.4671e+00,  7.6426e-01,  2.2108e-01, -2.3562e+00,\n",
              "          4.3519e-01, -2.3809e-02, -5.2294e-01, -5.2798e-01, -3.4315e-01,\n",
              "         -1.3295e-01,  2.4260e+00, -2.2689e-01, -8.3952e-01,  1.7482e+00,\n",
              "          3.5059e-02, -1.1420e+00,  7.0528e-01,  4.9818e-01, -5.5051e-02,\n",
              "          4.0308e-01,  4.2961e-01, -1.0608e+00, -1.2544e+00,  5.6164e-01,\n",
              "          5.8970e-01, -1.0127e+00,  9.4539e-01,  1.9767e-01, -1.3604e-01,\n",
              "         -2.3128e+00,  1.2046e-01, -1.4867e+00, -1.3016e+00, -8.6674e-01,\n",
              "         -1.1386e+00,  1.7507e+00, -6.4006e-01,  6.4674e-01,  6.2179e-01,\n",
              "          1.1184e+00, -2.4599e-01, -2.0480e-01,  7.5462e-01,  1.1471e+00,\n",
              "          5.9117e-01, -2.8266e-01,  1.3078e+00, -1.7791e+00, -5.2552e-01,\n",
              "         -7.6680e-01,  1.0143e+00, -1.3449e-01, -4.6588e-01,  4.2544e-01,\n",
              "         -4.0171e-01, -4.6373e-01,  3.1319e-01,  1.8780e-01,  1.4173e+00,\n",
              "          1.7364e+00],\n",
              "        [ 1.4027e+00,  9.8428e-01,  7.5048e-01,  2.9866e-01,  3.5481e-01,\n",
              "          9.9005e-02,  7.9198e-01,  7.2253e-01, -1.5025e+00,  2.7808e-01,\n",
              "          9.1482e-01, -4.4172e-02,  8.6923e-01,  9.5080e-01,  2.6147e-01,\n",
              "         -1.5233e-01, -1.1399e+00, -9.8611e-01,  3.1380e-01, -9.6724e-01,\n",
              "         -1.1945e+00,  8.1990e-01,  1.9819e+00, -1.9142e+00, -5.4678e-01,\n",
              "          9.5662e-01, -1.8997e+00, -3.3587e-01,  3.5140e-01,  1.5791e-01,\n",
              "         -1.9207e+00, -6.5632e-01,  4.1075e-01,  9.6024e-01, -9.0557e-03,\n",
              "          1.6934e+00, -1.3997e+00,  1.7523e+00,  1.4210e+00, -1.0140e-02,\n",
              "         -1.8082e-01,  9.4622e-02,  6.0366e-01,  2.1518e-01,  8.4422e-01,\n",
              "         -3.1862e-01,  1.7473e-01, -5.0270e-01,  5.6769e-01, -1.5323e+00,\n",
              "          9.3381e-01, -5.9216e-01,  8.7103e-01,  3.1065e-01,  6.1420e-02,\n",
              "          1.8595e-01, -1.8434e-01, -2.8404e+00, -1.7313e+00,  2.1741e-02,\n",
              "         -1.7984e+00, -2.1491e-01,  4.5473e-01, -2.6220e-01, -1.9148e+00,\n",
              "         -6.2577e-01, -1.0419e+00, -6.1809e-01,  3.1956e-01, -5.2739e-01,\n",
              "          1.4742e+00,  1.8584e+00, -1.9632e+00,  5.0707e-01,  2.9235e-01,\n",
              "         -6.0345e-01, -8.1535e-01,  1.9312e-01,  1.7486e+00,  9.7216e-01,\n",
              "         -3.6906e-01, -7.4055e-01,  9.6255e-01, -8.5812e-01,  4.8256e-01,\n",
              "         -3.8135e-01,  1.5870e+00, -4.9883e-02, -7.3142e-01,  1.6146e+00,\n",
              "         -7.2923e-01, -5.7211e-01,  1.6397e-01, -5.6267e-01,  1.2320e+00,\n",
              "         -3.0383e-01],\n",
              "        [ 6.3943e-01, -8.6849e-02,  3.3896e-01,  4.4220e-01, -3.4362e-01,\n",
              "          7.9687e-01, -7.0095e-01,  2.7830e+00, -3.8445e-01, -8.6407e-01,\n",
              "          2.6060e+00,  1.5051e-01,  1.1405e+00, -4.8991e-01, -5.5440e-01,\n",
              "         -1.1450e+00,  1.3933e+00, -1.2315e-01, -7.8497e-01, -1.3161e+00,\n",
              "         -3.3635e-02, -7.8819e-01,  1.1414e-01, -7.5801e-02,  1.1496e-01,\n",
              "         -1.1556e+00, -1.1784e+00,  2.0287e-01, -1.4402e-01, -1.1333e+00,\n",
              "         -7.6339e-01,  1.3431e+00,  9.1076e-01, -2.8894e-01,  1.8617e+00,\n",
              "          1.0701e+00,  2.1034e+00,  1.0003e+00,  8.4215e-01, -3.3282e-01,\n",
              "          6.7049e-02, -4.0693e-02,  7.4298e-01,  1.5210e-01, -4.6197e-01,\n",
              "         -1.5257e+00,  1.4070e+00,  7.2207e-02,  4.9561e-02,  3.0297e-01,\n",
              "         -1.3048e+00, -1.3450e+00,  1.5219e+00, -1.0583e+00,  5.7995e-02,\n",
              "          1.2815e-01, -3.3280e-02, -2.1173e+00, -8.5007e-01, -3.4298e-01,\n",
              "         -6.9984e-01, -5.8088e-01, -1.3801e+00,  7.2307e-02,  6.9152e-01,\n",
              "         -6.5130e-02,  6.6887e-01,  4.1858e-01,  2.9582e-01, -7.2981e-01,\n",
              "          8.8993e-01,  1.8127e+00, -9.9428e-01,  1.1247e+00,  1.4600e+00,\n",
              "          4.0217e-01, -1.9646e-01, -7.0730e-02,  7.2047e-01,  1.1268e+00,\n",
              "          1.3502e+00, -8.6917e-01, -4.9421e-01,  1.7060e+00, -1.1312e+00,\n",
              "         -3.6772e-01,  6.1102e-01,  8.9885e-02, -8.3820e-01, -2.1400e+00,\n",
              "         -1.4255e+00, -1.7538e+00, -3.9840e-02, -6.3277e-01, -1.1132e+00,\n",
              "         -5.0648e-01]], grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TabTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch model of TabTransformer.\n",
        "    Based on paper:\n",
        "    https://arxiv.org/abs/2012.06678\n",
        "    Args:\n",
        "        nn (nn.Module): Module with implementation of TabTransformer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        cat_cardinalities: tuple[int, ...] | tuple[()],\n",
        "        num_continuous: int,\n",
        "        dim: int = 32,\n",
        "        depth: int = 4,\n",
        "        heads: int = 8,\n",
        "        dim_head: int = 16,\n",
        "        dim_out: int = 1,\n",
        "        mlp_hidden_mults: tuple[(int, int)] = (4, 2),\n",
        "        mlp_act: Callable[..., nn.Module] = nn.ReLU,\n",
        "        num_special_tokens: int = 9,\n",
        "        continuous_mean_std: torch.Tensor | None = None,\n",
        "        attn_dropout: float = 0.0,\n",
        "        ff_dropout: float = 0.0,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        TabTransformer.\n",
        "        Originally introduced in https://arxiv.org/abs/2012.06678.\n",
        "        Args:\n",
        "            cat_cardinalities ([List[int] | Tuple[()]): List with number of categories\n",
        "            for each categorical feature. If no categorical variables are present,\n",
        "            use empty tuple. For categorical variables e. g., option type ('C' or 'P'),\n",
        "            the list would be `[1]`.\n",
        "            num_continuous (int): Number of continous features.\n",
        "            dim (int, optional): Dimensionality of transformer. Defaults to 32.\n",
        "            depth (int, optional): Depth of encoder / decoder of transformer.\n",
        "            Defaults to 4.\n",
        "            heads (int, optional): Number of attention heads. Defaults to 8.\n",
        "            dim_head (int, optional): Dimensionality of attention head. Defaults to 16.\n",
        "            dim_out (int, optional): Dimension of output layer of MLP. Set to one for\n",
        "            binary classification. Defaults to 1.\n",
        "            mlp_hidden_mults (Tuple[(int, int)], optional): multipliers for dimensions\n",
        "            of hidden layer in MLP. Defaults to (4, 2).\n",
        "            mlp_act (Callable[..., nn.Module], optional): Activation function used\n",
        "            in MLP. Defaults to nn.ReLU().\n",
        "            num_special_tokens (int, optional): Number of special tokens in transformer.\n",
        "            Defaults to 2.\n",
        "            continuous_mean_std (torch.Tensor | None): List with mean and\n",
        "            std deviation of each continous feature. Shape eq. `[num_continous x 2]`.\n",
        "            Defaults to None.\n",
        "            attn_dropout (float, optional): Degree of attention dropout used in\n",
        "            transformer. Defaults to 0.0.\n",
        "            ff_dropout (float, optional): Dropout in feed forward net. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert all(\n",
        "            map(lambda n: n > 0, cat_cardinalities)\n",
        "        ), \"number of each category must be positive\"\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(cat_cardinalities)\n",
        "        self.cardinality_categories = sum(cat_cardinalities)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.cardinality_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position\n",
        "        #  in the categories embedding table\n",
        "\n",
        "        categories_offset = F.pad(\n",
        "            torch.tensor(list(cat_cardinalities)), (1, 0), value=num_special_tokens\n",
        "        )  # Prepend num_special_tokens.\n",
        "        print(\"categories_offset\")\n",
        "        print(categories_offset)\n",
        "        categories_offset = categories_offset.cumsum(dim=-1)[:-1]\n",
        "        self.register_buffer(\"categories_offset\", categories_offset)\n",
        "        print(\"categories_offset (cum sum)\")\n",
        "        print(categories_offset)\n",
        "\n",
        "        # continuous\n",
        "\n",
        "        if continuous_mean_std is not None:\n",
        "            assert continuous_mean_std.shape == (num_continuous, 2,), (\n",
        "                f\"continuous_mean_std must have a shape of ({num_continuous}, 2)\"\n",
        "                f\"where the last dimension contains the mean and variance respectively\"\n",
        "            )\n",
        "        self.register_buffer(\"continuous_mean_std\", continuous_mean_std)\n",
        "\n",
        "        self.norm = nn.LayerNorm(num_continuous)\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        # transformer\n",
        "        self.transformer = Transformer(ntoken=total_tokens,d_model=dim, nhead=heads,d_hid=dim * 4, nlayers=depth,)\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            num_tokens=total_tokens,\n",
        "            dim=dim,\n",
        "            depth=depth,\n",
        "            heads=heads,\n",
        "            dim_head=dim_head,\n",
        "            attn_dropout=attn_dropout,\n",
        "            ff_dropout=ff_dropout,\n",
        "        )\n",
        "\n",
        "        # mlp to logits\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "        j = input_size // 8\n",
        "\n",
        "        hidden_dimensions = list(map(lambda t: j * t, mlp_hidden_mults))\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "\n",
        "        self.mlp = MLP(all_dimensions, act=mlp_act)\n",
        "\n",
        "    def forward(self, x_cat: torch.Tensor | None, x_cont: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of TabTransformer.\n",
        "        Args:\n",
        "            x_cat (torch.Tensor | None): tensor with categorical data.\n",
        "            x_cont (torch.Tensor): tensor with continous data.\n",
        "        Returns:\n",
        "            torch.Tensor: probabilities\n",
        "        \"\"\"\n",
        "        flat_categ: torch.Tensor | None = None\n",
        "\n",
        "        # print(\"x_cat\")\n",
        "        # print(x_cat)\n",
        "\n",
        "        # print(x_cont)\n",
        "\n",
        "        if x_cat is not None:\n",
        "            assert x_cat.shape[-1] == self.num_categories, (\n",
        "                f\"you must pass in {self.num_categories} \"\n",
        "                f\"values for your categories input\"\n",
        "            )\n",
        "            x = self.transformer(x_cat)\n",
        "            flat_categ = x.flatten(1)\n",
        "\n",
        "        assert x_cont.shape[1] == self.num_continuous, (\n",
        "            f\"you must pass in {self.num_continuous} \"\n",
        "            f\"values for your continuous input\"\n",
        "        )\n",
        "\n",
        "        if self.continuous_mean_std is not None:\n",
        "            mean, std = self.continuous_mean_std.unbind(dim=-1)  # type: ignore\n",
        "            x_cont = (x_cont - mean) / std\n",
        "\n",
        "        normed_cont = self.norm(x_cont)\n",
        "\n",
        "        # Adaptation to work without categorical data\n",
        "        x = (\n",
        "            torch.cat((flat_categ, normed_cont), dim=-1)\n",
        "            if flat_categ is not None\n",
        "            else normed_cont\n",
        "        )\n",
        "\n",
        "        return self.mlp(x)"
      ],
      "metadata": {
        "id": "LRpJhNIAvEvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}